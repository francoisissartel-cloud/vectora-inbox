#!/usr/bin/env python3
"""
Script de dÃ©ploiement des amÃ©liorations sur AWS.
DÃ©ploie les configurations mises Ã  jour selon le plan d'amÃ©lioration.
"""

import json
import yaml
import boto3
import logging
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AWSDeploymentManager:
    """Gestionnaire de dÃ©ploiement AWS pour les amÃ©liorations."""
    
    def __init__(self, project_root: str, env: str = "dev"):
        self.project_root = Path(project_root)
        self.canonical_path = self.project_root / "canonical"
        self.env = env
        
        # Configuration AWS
        self.s3_client = boto3.client('s3')
        self.config_bucket = f"vectora-inbox-config-{env}"
        
    def backup_current_configuration(self) -> str:
        """Sauvegarde la configuration actuelle avant dÃ©ploiement."""
        logger.info("=== SAUVEGARDE CONFIGURATION ACTUELLE ===")
        
        backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_prefix = f"backups/pre_improvements_{backup_timestamp}/"
        
        try:
            # Lister tous les objets dans le bucket de configuration
            response = self.s3_client.list_objects_v2(Bucket=self.config_bucket)
            
            if 'Contents' in response:
                for obj in response['Contents']:
                    key = obj['Key']
                    if not key.startswith('backups/'):
                        # Copier vers le dossier de backup
                        copy_source = {'Bucket': self.config_bucket, 'Key': key}
                        backup_key = backup_prefix + key
                        
                        self.s3_client.copy_object(
                            CopySource=copy_source,
                            Bucket=self.config_bucket,
                            Key=backup_key
                        )
                        logger.debug(f"SauvegardÃ©: {key} -> {backup_key}")
                
                logger.info(f"Configuration sauvegardÃ©e avec le prÃ©fixe: {backup_prefix}")
                return backup_prefix
            else:
                logger.warning("Aucune configuration existante trouvÃ©e")
                return backup_prefix
                
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {str(e)}")
            raise
    
    def deploy_canonical_configurations(self) -> Dict[str, bool]:
        """DÃ©ploie les configurations canonical mises Ã  jour."""
        logger.info("=== DÃ‰PLOIEMENT CONFIGURATIONS CANONICAL ===")
        
        deployment_results = {}
        
        # Fichiers Ã  dÃ©ployer avec leurs chemins S3
        files_to_deploy = {
            'scopes/technology_scopes.yaml': 'canonical/scopes/technology_scopes.yaml',
            'scopes/trademark_scopes.yaml': 'canonical/scopes/trademark_scopes.yaml',
            'scopes/exclusion_scopes.yaml': 'canonical/scopes/exclusion_scopes.yaml',
            'scoring/scoring_rules.yaml': 'canonical/scoring/scoring_rules.yaml',
            'ingestion/ingestion_profiles.yaml': 'canonical/ingestion/ingestion_profiles.yaml',
            'matching/domain_matching_rules.yaml': 'canonical/matching/domain_matching_rules.yaml'
        }
        
        for local_path, s3_key in files_to_deploy.items():
            try:
                local_file_path = self.canonical_path / local_path
                
                if local_file_path.exists():
                    # Lire et valider le fichier YAML
                    with open(local_file_path, 'r', encoding='utf-8') as f:
                        yaml_content = yaml.safe_load(f)
                    
                    # Uploader vers S3
                    with open(local_file_path, 'rb') as f:
                        self.s3_client.put_object(
                            Bucket=self.config_bucket,
                            Key=s3_key,
                            Body=f,
                            ContentType='application/x-yaml'
                        )
                    
                    deployment_results[s3_key] = True
                    logger.info(f"âœ… DÃ©ployÃ©: {local_path} -> s3://{self.config_bucket}/{s3_key}")
                else:
                    deployment_results[s3_key] = False
                    logger.error(f"âŒ Fichier manquant: {local_file_path}")
                    
            except Exception as e:
                deployment_results[s3_key] = False
                logger.error(f"âŒ Erreur dÃ©ploiement {local_path}: {str(e)}")
        
        success_count = sum(1 for success in deployment_results.values() if success)
        total_count = len(deployment_results)
        
        logger.info(f"DÃ©ploiement canonical terminÃ©: {success_count}/{total_count} fichiers dÃ©ployÃ©s")
        return deployment_results
    
    def deploy_lambda_code(self) -> Dict[str, bool]:
        """DÃ©ploie le code Lambda mis Ã  jour."""
        logger.info("=== DÃ‰PLOIEMENT CODE LAMBDA ===")
        
        deployment_results = {}
        
        # Fichiers Lambda Ã  dÃ©ployer
        lambda_files = {
            'src/vectora_core/matching/matcher.py': 'lambda-code/vectora_core/matching/matcher.py',
            'src/vectora_core/scoring/scorer.py': 'lambda-code/vectora_core/scoring/scorer.py'
        }
        
        for local_path, s3_key in lambda_files.items():
            try:
                local_file_path = self.project_root / local_path
                
                if local_file_path.exists():
                    with open(local_file_path, 'rb') as f:
                        self.s3_client.put_object(
                            Bucket=self.config_bucket,
                            Key=s3_key,
                            Body=f,
                            ContentType='text/x-python'
                        )
                    
                    deployment_results[s3_key] = True
                    logger.info(f"âœ… DÃ©ployÃ©: {local_path} -> s3://{self.config_bucket}/{s3_key}")
                else:
                    deployment_results[s3_key] = False
                    logger.error(f"âŒ Fichier manquant: {local_file_path}")
                    
            except Exception as e:
                deployment_results[s3_key] = False
                logger.error(f"âŒ Erreur dÃ©ploiement {local_path}: {str(e)}")
        
        success_count = sum(1 for success in deployment_results.values() if success)
        total_count = len(deployment_results)
        
        logger.info(f"DÃ©ploiement Lambda terminÃ©: {success_count}/{total_count} fichiers dÃ©ployÃ©s")
        return deployment_results
    
    def create_deployment_metadata(self, backup_prefix: str, canonical_results: Dict[str, bool], lambda_results: Dict[str, bool]) -> Dict[str, Any]:
        """CrÃ©e les mÃ©tadonnÃ©es de dÃ©ploiement."""
        logger.info("=== CRÃ‰ATION MÃ‰TADONNÃ‰ES DÃ‰PLOIEMENT ===")
        
        metadata = {
            'deployment_info': {
                'timestamp': datetime.now().isoformat(),
                'environment': self.env,
                'improvement_version': 'phase_1_to_4_complete',
                'backup_location': backup_prefix,
                'deployed_by': 'improvement_deployment_script'
            },
            'improvements_summary': {
                'phase_1_corrections_critiques': {
                    'technology_scopes_enriched': True,
                    'uzedy_trademark_verified': True,
                    'anti_lai_exclusions_added': True,
                    'scoring_adjustments_applied': True
                },
                'phase_2_ingestion_selective': {
                    'corporate_profiles_updated': True,
                    'press_profiles_enhanced': True,
                    'exclusion_scopes_expanded': True
                },
                'phase_3_matching_contextuel': {
                    'contextual_matching_implemented': True,
                    'pattern_matching_added': True,
                    'company_type_logic_added': True
                },
                'phase_4_scoring_contextuel': {
                    'contextual_scoring_implemented': True,
                    'context_multipliers_added': True,
                    'penalties_implemented': True,
                    'recency_bonuses_added': True
                }
            },
            'deployment_results': {
                'canonical_configurations': canonical_results,
                'lambda_code': lambda_results,
                'overall_success': all(canonical_results.values()) and all(lambda_results.values())
            },
            'expected_improvements': {
                'nanexa_moderna_pharmashell_included': 'Items Nanexa/Moderna PharmaShellÂ® maintenant inclus',
                'uzedy_regulatory_included': 'Items UZEDY regulatory maintenant inclus',
                'medincel_malaria_grants_included': 'Items MedinCell malaria grants maintenant inclus',
                'hr_noise_reduced': 'Bruit HR DelSiTech maintenant exclu',
                'finance_noise_reduced': 'Bruit finance MedinCell maintenant exclu',
                'oral_routes_excluded': 'Routes orales maintenant exclues',
                'technology_brands_detected': 'PharmaShellÂ®, SiliaShellÂ®, BEPOÂ® maintenant dÃ©tectÃ©s'
            },
            'monitoring_recommendations': [
                'Surveiller les premiÃ¨res newsletters gÃ©nÃ©rÃ©es',
                'Comparer avec les newsletters prÃ©cÃ©dentes',
                'VÃ©rifier que les signaux LAI majeurs sont bien capturÃ©s',
                'Confirmer la rÃ©duction du bruit HR/Finance',
                'Valider l\'exclusion des routes orales'
            ]
        }
        
        # Uploader les mÃ©tadonnÃ©es vers S3
        metadata_key = f"deployments/improvements_{datetime.now().strftime('%Y%m%d_%H%M%S')}_metadata.json"
        
        try:
            self.s3_client.put_object(
                Bucket=self.config_bucket,
                Key=metadata_key,
                Body=json.dumps(metadata, indent=2, ensure_ascii=False),
                ContentType='application/json'
            )
            
            logger.info(f"âœ… MÃ©tadonnÃ©es sauvegardÃ©es: s3://{self.config_bucket}/{metadata_key}")
            metadata['metadata_location'] = f"s3://{self.config_bucket}/{metadata_key}"
            
        except Exception as e:
            logger.error(f"âŒ Erreur sauvegarde mÃ©tadonnÃ©es: {str(e)}")
        
        return metadata
    
    def validate_deployment(self) -> Dict[str, Any]:
        """Valide le dÃ©ploiement en vÃ©rifiant les fichiers sur S3."""
        logger.info("=== VALIDATION DÃ‰PLOIEMENT ===")
        
        validation_results = {}
        
        # Fichiers critiques Ã  vÃ©rifier
        critical_files = [
            'canonical/scopes/technology_scopes.yaml',
            'canonical/scopes/exclusion_scopes.yaml',
            'canonical/scoring/scoring_rules.yaml',
            'canonical/ingestion/ingestion_profiles.yaml',
            'canonical/matching/domain_matching_rules.yaml'
        ]
        
        for file_key in critical_files:
            try:
                response = self.s3_client.head_object(Bucket=self.config_bucket, Key=file_key)
                validation_results[file_key] = {
                    'exists': True,
                    'last_modified': response['LastModified'].isoformat(),
                    'size': response['ContentLength']
                }
                logger.info(f"âœ… ValidÃ©: {file_key}")
                
            except Exception as e:
                validation_results[file_key] = {
                    'exists': False,
                    'error': str(e)
                }
                logger.error(f"âŒ Ã‰chec validation: {file_key} - {str(e)}")
        
        # VÃ©rifier le contenu d'un fichier critique
        try:
            response = self.s3_client.get_object(
                Bucket=self.config_bucket, 
                Key='canonical/scopes/technology_scopes.yaml'
            )
            content = response['Body'].read().decode('utf-8')
            yaml_content = yaml.safe_load(content)
            
            # VÃ©rifier que les amÃ©liorations sont prÃ©sentes
            lai_keywords = yaml_content.get('lai_keywords', {})
            tech_terms = lai_keywords.get('technology_terms_high_precision', [])\n            \n            improvements_present = {\n                'pharmashell_present': 'PharmaShellÂ®' in tech_terms,\n                'siliashell_present': 'SiliaShellÂ®' in tech_terms,\n                'bepo_present': 'BEPOÂ®' in tech_terms,\n                'lai_acronym_present': 'LAI' in tech_terms\n            }\n            \n            validation_results['improvements_verification'] = improvements_present\n            \n            if all(improvements_present.values()):\n                logger.info(\"âœ… Toutes les amÃ©liorations technology_scopes sont prÃ©sentes\")\n            else:\n                logger.warning(f\"âš ï¸ Certaines amÃ©liorations manquent: {improvements_present}\")\n                \n        except Exception as e:\n            logger.error(f\"âŒ Erreur validation contenu: {str(e)}\")\n            validation_results['content_validation_error'] = str(e)\n        \n        return validation_results\n    \n    def generate_deployment_report(self) -> Dict[str, Any]:\n        \"\"\"GÃ©nÃ¨re un rapport complet de dÃ©ploiement.\"\"\"\n        logger.info(\"=== GÃ‰NÃ‰RATION RAPPORT DÃ‰PLOIEMENT ===\")\n        \n        try:\n            # 1. Sauvegarde\n            backup_prefix = self.backup_current_configuration()\n            \n            # 2. DÃ©ploiement configurations\n            canonical_results = self.deploy_canonical_configurations()\n            \n            # 3. DÃ©ploiement code Lambda\n            lambda_results = self.deploy_lambda_code()\n            \n            # 4. CrÃ©ation mÃ©tadonnÃ©es\n            metadata = self.create_deployment_metadata(backup_prefix, canonical_results, lambda_results)\n            \n            # 5. Validation\n            validation_results = self.validate_deployment()\n            \n            # 6. Rapport final\n            deployment_report = {\n                'deployment_status': 'SUCCESS' if metadata['deployment_results']['overall_success'] else 'PARTIAL_FAILURE',\n                'timestamp': datetime.now().isoformat(),\n                'environment': self.env,\n                'backup_location': backup_prefix,\n                'deployment_results': {\n                    'canonical_configurations': canonical_results,\n                    'lambda_code': lambda_results\n                },\n                'validation_results': validation_results,\n                'metadata': metadata,\n                'next_steps': self._generate_next_steps(metadata['deployment_results']['overall_success'])\n            }\n            \n            return deployment_report\n            \n        except Exception as e:\n            logger.error(f\"Erreur lors du dÃ©ploiement: {str(e)}\")\n            return {\n                'deployment_status': 'FAILURE',\n                'timestamp': datetime.now().isoformat(),\n                'error': str(e),\n                'next_steps': [\n                    'VÃ©rifier les logs d\\'erreur',\n                    'Corriger les problÃ¨mes identifiÃ©s',\n                    'Relancer le dÃ©ploiement',\n                    'Contacter l\\'Ã©quipe technique si nÃ©cessaire'\n                ]\n            }\n    \n    def _generate_next_steps(self, deployment_success: bool) -> List[str]:\n        \"\"\"GÃ©nÃ¨re les prochaines Ã©tapes selon le rÃ©sultat du dÃ©ploiement.\"\"\"\n        if deployment_success:\n            return [\n                'âœ… DÃ©ploiement rÃ©ussi - Configurations mises Ã  jour sur AWS',\n                'ğŸ”„ ExÃ©cuter un test complet avec le client lai_weekly_v2',\n                'ğŸ“Š GÃ©nÃ©rer une newsletter et comparer avec les prÃ©cÃ©dentes',\n                'ğŸ‘€ Surveiller les mÃ©triques de qualitÃ© (signaux LAI vs bruit)',\n                'ğŸ“ˆ Mesurer l\\'amÃ©lioration du taux de prÃ©cision',\n                'ğŸ¯ Valider que les cas critiques (Nanexa/Moderna, UZEDY) sont inclus',\n                'ğŸš« Confirmer l\\'exclusion du bruit (HR DelSiTech, Finance MedinCell)',\n                'ğŸ“ Documenter les rÃ©sultats et ajuster si nÃ©cessaire'\n            ]\n        else:\n            return [\n                'âŒ DÃ©ploiement partiel ou Ã©chouÃ©',\n                'ğŸ” Analyser les logs d\\'erreur dÃ©taillÃ©s',\n                'ğŸ”§ Corriger les fichiers ou configurations problÃ©matiques',\n                'ğŸ”„ Relancer le dÃ©ploiement des Ã©lÃ©ments Ã©chouÃ©s',\n                'âš ï¸ Ne pas exÃ©cuter de tests tant que le dÃ©ploiement n\\'est pas complet',\n                'ğŸ“ Contacter l\\'Ã©quipe technique si les problÃ¨mes persistent'\n            ]\n\n\ndef main():\n    \"\"\"Point d'entrÃ©e principal.\"\"\"\n    project_root = Path(__file__).parent\n    \n    # ParamÃ¨tres de dÃ©ploiement\n    env = \"dev\"  # Peut Ãªtre modifiÃ© pour \"prod\"\n    \n    logger.info(f\"DÃ©marrage dÃ©ploiement amÃ©liorations sur AWS (env: {env})\")\n    \n    # CrÃ©er le gestionnaire de dÃ©ploiement\n    deployment_manager = AWSDeploymentManager(str(project_root), env)\n    \n    # GÃ©nÃ©rer le rapport de dÃ©ploiement\n    deployment_report = deployment_manager.generate_deployment_report()\n    \n    # Sauvegarder le rapport localement\n    report_path = project_root / f\"aws_deployment_report_{env}.json\"\n    with open(report_path, 'w', encoding='utf-8') as f:\n        json.dump(deployment_report, f, indent=2, ensure_ascii=False)\n    \n    logger.info(f\"Rapport de dÃ©ploiement sauvegardÃ©: {report_path}\")\n    \n    # Afficher le rÃ©sumÃ©\n    status = deployment_report['deployment_status']\n    logger.info(f\"\\n=== RÃ‰SUMÃ‰ DÃ‰PLOIEMENT ===\\nStatus: {status}\")\n    \n    if status == 'SUCCESS':\n        logger.info(\"ğŸ‰ DÃ©ploiement rÃ©ussi ! Les amÃ©liorations sont maintenant actives sur AWS.\")\n    elif status == 'PARTIAL_FAILURE':\n        logger.warning(\"âš ï¸ DÃ©ploiement partiel. Certains Ã©lÃ©ments ont Ã©chouÃ©.\")\n    else:\n        logger.error(\"âŒ DÃ©ploiement Ã©chouÃ©. VÃ©rifier les logs d'erreur.\")\n    \n    # Afficher les prochaines Ã©tapes\n    logger.info(\"\\n=== PROCHAINES Ã‰TAPES ===\\n\")\n    for step in deployment_report['next_steps']:\n        logger.info(step)\n    \n    # Code de sortie\n    if status == 'SUCCESS':\n        return 0\n    elif status == 'PARTIAL_FAILURE':\n        return 1\n    else:\n        return 2\n\n\nif __name__ == \"__main__\":\n    exit(main())"
<parameter name="explanation">CrÃ©ation du script de dÃ©ploiement AWS pour finaliser l'implÃ©mentation des amÃ©liorations