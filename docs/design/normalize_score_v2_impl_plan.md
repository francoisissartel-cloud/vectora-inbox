
# Plan d'impl√©mentation : Lambda normalize-score-matching-v2

## Phase 0 ‚Äì Pr√©ambule & rappel des contraintes

### R√©sum√© du contrat m√©tier normalize_score_v2

- **R√¥le** : Normalisation intelligente des items bruts ing√©r√©s + scoring de pertinence pour pr√©parer la g√©n√©ration de newsletter
- **Inputs** : Items ing√©r√©s depuis S3 `ingested/` (outputs de ingest V2)
- **Outputs** : Items normalis√©s + scor√©s dans S3 `curated/` pour consommation par newsletter V2
- **Traitement** : Normalisation Bedrock (entit√©s, classification) + matching aux domaines + scoring selon r√®gles m√©tier
- **Contrainte cl√©** : Traiter UNIQUEMENT le dernier run d'ingestion par client, pas tout l'historique

### R√®gles d'hygi√®ne V4 applicables

- **Architecture 3 Lambdas V2** : Handler minimal dans `/src_v2/lambdas/normalize_score/`, logique dans `vectora_core/normalization/`
- **G√©n√©ricit√© absolue** : Pilotage par `client_config + canonical`, aucune logique hardcod√©e sp√©cifique √† un client
- **Environnement AWS** : R√©gion `eu-west-3`, profil `rag-lai-prod`, Bedrock `us-east-1` par d√©faut
- **D√©pendances** : Lambda Layers uniquement, aucune lib tierce dans `/src_v2/`
- **Imports relatifs** : `from ..shared import`, `from . import` dans vectora_core

### Objectifs principaux

- **Dernier run uniquement** : Strat√©gie robuste pour identifier et traiter le dernier run d'ingestion par client
- **Pr√©paration newsletter** : Structure de sortie optimis√©e pour consommation par Lambda newsletter V2
- **G√©n√©rique** : Aucun couplage dur √† un client sp√©cifique, pilotage par configuration
- **Pas usine √† gaz** : Code simple, testable, maintenable sans sur-architecture

---

## Phase 1 ‚Äì Audit de l'existant

### Analyse structure /src_v2/

**√âtat actuel observ√©** :
- Structure 3 Lambdas V2 valid√©e : `ingest/`, `normalize_score/`, `newsletter/`
- Handler normalize_score existant mais minimal (d√©l√©gation √† vectora_core)
- Modules vectora_core organis√©s : `shared/`, `ingest/`, `normalization/`, `newsletter/`
- Conformit√© r√®gles d'hygi√®ne V4 : aucune violation d√©tect√©e

**Modules vectora_core disponibles** :
- `shared/` : config_loader, s3_io, models, utils (r√©utilisables)
- `normalization/` : structure existante mais √† compl√©ter pour V2

### Analyse Lambda ingest V2 et ses outputs

**Contrat ingest V2 analys√©** :
- **Outputs S3** : `s3://vectora-inbox-data/ingested/{client_id}/{YYYY}/{MM}/{DD}/items.json`
- **Structure items** : item_id, source_key, title, content, url, published_at, ingested_at, metadata
- **Convention runs** : Un run = un dossier par date d'ingestion (YYYY/MM/DD)
- **Dernier run** : Dossier avec la date la plus r√©cente pour un client donn√©

**Shape exacte des items ing√©r√©s** (depuis contrat ingest_v2.md) :
```json
{
  "item_id": "press_corporate__medincell_20250115_001",
  "source_key": "press_corporate__medincell", 
  "title": "MedinCell Announces Partnership...",
  "content": "Full article text...",
  "url": "https://...",
  "published_at": "2025-01-15",
  "ingested_at": "2025-01-15T10:30:00Z",
  "metadata": {"author": "...", "tags": [...], "word_count": 450}
}
```

### Analyse canonical & client_config

**Scopes canonical disponibles** :
- `company_scopes.yaml` : 180+ entreprises LAI (pure_players, hybrid, global)
- `molecule_scopes.yaml` : 90+ mol√©cules par indication
- `technology_scopes.yaml` : 80+ mots-cl√©s LAI
- `trademark_scopes.yaml` : 70+ marques commerciales
- `exclusion_scopes.yaml` : Termes de filtrage du bruit

**Client_config lai_weekly_v3 analys√©** :
- 2 domaines de veille : `tech_lai_ecosystem`, `regulatory_lai`
- R√®gles matching : `trademark_privileges`, `require_entity_signals`
- R√®gles scoring : Bonus pure players (5.0), trademarks (4.0), partnerships (8.0)
- Seuils s√©lection : min_score 12, max_items_total 15

**Prompts Bedrock disponibles** :
- `global_prompts.yaml` : Prompt normalisation LAI avec extraction entit√©s, classification √©v√©nements
- Template avec placeholders : `{{item_text}}`, `{{companies_examples}}`, etc.

### R√©sultat Phase 1

**Entr√©es disponibles identifi√©es** :
- Items ing√©r√©s structur√©s avec m√©tadonn√©es compl√®tes
- Configuration client compl√®te pour matching et scoring
- Scopes canonical exhaustifs pour LAI
- Prompts Bedrock pr√™ts pour normalisation

**Strat√©gie dernier run** :
- Convention S3 : `ingested/{client_id}/{YYYY}/{MM}/{DD}/`
- Identification : Lister les pr√©fixes, trier par date, prendre le plus r√©cent
- Robustesse : Gestion des cas multiples runs m√™me jour via timestamp

---

## Phase 2 ‚Äì Conception fonctionnelle & technique

### Signature du handler

**Handler standardis√©** :
```python
def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    # Event minimal : {"client_id": "lai_weekly"}
    # Event complet : {"client_id": "lai_weekly", "period_days": 7, "force_reprocess": false}
```

**Variables d'environnement requises** :
- `CONFIG_BUCKET` : vectora-inbox-config-dev
- `DATA_BUCKET` : vectora-inbox-data-dev  
- `BEDROCK_MODEL_ID` : eu.anthropic.claude-sonnet-4-5-20250929-v1:0
- `BEDROCK_REGION_NORMALIZATION` : us-east-1 (d√©faut observ√©)

### Strat√©gie identification dernier run

**M√©thode robuste propos√©e** :
1. **Lister les pr√©fixes S3** : `s3://data-bucket/ingested/{client_id}/`
2. **Parser les dates** : Extraire YYYY/MM/DD de chaque pr√©fixe
3. **Trier par date d√©croissante** : Utiliser datetime pour comparaison
4. **Prendre le plus r√©cent** : Premier √©l√©ment apr√®s tri
5. **V√©rifier existence fichier** : `items.json` pr√©sent dans le dossier

**Gestion cas limites** :
- Aucun run trouv√© : Erreur explicite "Aucune donn√©e ing√©r√©e pour ce client"
- Multiples runs m√™me jour : Prendre le dernier par timestamp de modification S3
- Fichier items.json manquant : Erreur explicite avec chemin attendu

### Structure entr√©e/sortie

**S3 Input** : `s3://vectora-inbox-data/ingested/{client_id}/{YYYY}/{MM}/{DD}/items.json`

**S3 Output** : `s3://vectora-inbox-data/curated/{client_id}/{YYYY}/{MM}/{DD}/items.json`

**Shape JSON sortie** (selon contrat normalize_score_v2.md) :
```json
{
  "item_id": "...",
  "source_key": "...", 
  "title": "...",
  "content": "...",
  "url": "...",
  "published_at": "...",
  "normalized_at": "2025-01-15T11:45:00Z",
  
  "normalized_content": {
    "summary": "...",
    "entities": {"companies": [...], "molecules": [...], "technologies": [...], "trademarks": [...]},
    "event_classification": {"primary_type": "partnership", "confidence": 0.92}
  },
  
  "matching_results": {
    "matched_domains": ["tech_lai_ecosystem"],
    "domain_relevance": {"tech_lai_ecosystem": {"score": 0.89, "reasons": [...]}}
  },
  
  "scoring_results": {
    "base_score": 8.5,
    "bonuses": {"pure_player_company": 5.0, "trademark_mention": 4.0},
    "final_score": 20.0
  }
}
```

### D√©coupage du code

**Handler minimal** : `/src_v2/lambdas/normalize_score/handler.py`
- Validation event, lecture env vars, appel `run_normalize_score_for_client()`

**Logique m√©tier** : `vectora_core/normalization/`
- `__init__.py` : Fonction orchestratrice `run_normalize_score_for_client()`
- `normalizer.py` : Appels Bedrock pour extraction entit√©s + classification
- `matcher.py` : Matching items aux domaines de veille client
- `scorer.py` : Calcul scores selon r√®gles m√©tier + bonus/malus
- `bedrock_client.py` : Client Bedrock sp√©cialis√© avec retry et gestion erreurs

**Modules partag√©s r√©utilis√©s** :
- `vectora_core/shared/config_loader.py` : Chargement client_config + canonical
- `vectora_core/shared/s3_io.py` : Lecture/√©criture S3 standardis√©e
- `vectora_core/shared/utils.py` : Utilitaires dates, logging, etc.

### Interactions Bedrock

**Module d√©di√©** : `vectora_core/normalization/bedrock_client.py`
- Classe `BedrockNormalizationClient` avec configuration r√©gion/mod√®le
- M√©thode `normalize_item()` : Appel Bedrock avec prompt canonical
- Gestion retry automatique (3 tentatives)
- Gestion timeouts (30s par appel)
- Logging d√©taill√© des appels et erreurs

---

## Phase 3 ‚Äì Plan d'impl√©mentation dans /src_v2

### Fichiers √† cr√©er/modifier

**Handler Lambda** :
- `src_v2/lambdas/normalize_score/handler.py` : **MODIFIER** (structure existante √† compl√©ter)
- R√¥le : Validation event, lecture env vars, appel fonction orchestratrice
- D√©pendances : `from vectora_core.normalization import run_normalize_score_for_client`

**Modules vectora_core/normalization/** :
- `__init__.py` : **MODIFIER** (ajouter fonction orchestratrice compl√®te)
- `normalizer.py` : **CR√âER** (logique normalisation Bedrock)
- `matcher.py` : **CR√âER** (matching aux domaines de veille)
- `scorer.py` : **CR√âER** (calcul scores selon r√®gles m√©tier)
- `bedrock_client.py` : **CR√âER** (client Bedrock sp√©cialis√©)

**Modules vectora_core/shared/** :
- R√©utilisation modules existants : config_loader, s3_io, utils, models
- Pas de modification pr√©vue (API stable)

**Tests et fixtures** :
- `scripts/test_normalize_score_v2_local.py` : **CR√âER** (tests locaux)
- `tests/fixtures/lai_weekly_ingested_sample.json` : **CR√âER** (donn√©es test)

### Points d'attention r√®gles d'hygi√®ne

**√âviter usine √† gaz** :
- Fonctions pures pour normalisation, matching, scoring
- Pas de cascade de classes inutiles
- Logique m√©tier simple et testable

**G√©n√©ricit√©** :
- Aucun `if client_id == 'lai_weekly'` dans le code
- Toute logique m√©tier pilot√©e par client_config + canonical
- Param√®tres configurables via event ou variables d'environnement

**Imports relatifs corrects** :
```python
# Dans vectora_core/normalization/__init__.py
from ..shared import config_loader, s3_io, utils
from . import normalizer, matcher, scorer, bedrock_client

# Dans vectora_core/normalization/normalizer.py  
from ..shared.models import NormalizedItem
from .bedrock_client import BedrockNormalizationClient
```

---

## Phase 4 ‚Äì Plan de tests locaux

### G√©n√©ration fixtures

**R√©cup√©ration donn√©es r√©elles** :
- Script `scripts/extract_lai_weekly_last_run.py` pour t√©l√©charger dernier run lai_weekly_v3
- Anonymisation si n√©cessaire (URLs, emails)
- Stockage dans `tests/fixtures/lai_weekly_ingested_sample.json`

**Fixtures synth√©tiques** :
- 5-10 items repr√©sentatifs : partnerships, clinical updates, regulatory
- Couverture entit√©s : MedinCell, Camurus, BEPO, Aristada, etc.
- Cas limites : items sans entit√©s LAI, contenu tr√®s court/long

### Script de test local

**Script principal** : `scripts/test_normalize_score_v2_local.py`

**Fonctionnalit√©s** :
- Chargement fixtures locales (pas de S3)
- Mock ou appel r√©el Bedrock (param√®tre `--mock-bedrock`)
- Simulation compl√®te du workflow normalize-score
- G√©n√©ration fichier output local `output/normalized_items.json`
- Validation structure JSON de sortie

**Tests du flux complet** :
1. **Chargement config** : client_config + canonical depuis fichiers locaux
2. **Normalisation** : Appel Bedrock (r√©el ou mock) pour extraction entit√©s
3. **Matching** : Application r√®gles matching aux domaines de veille
4. **Scoring** : Calcul scores avec bonus/malus selon r√®gles m√©tier
5. **Validation** : V√©rification pr√©sence champs obligatoires

### Checks qualit√©

**M√©triques de base** :
- Nombre items trait√©s vs nombre items en entr√©e (100% attendu)
- Pr√©sence champs obligatoires : normalized_content, matching_results, scoring_results
- Distribution scores : min, max, moyenne, m√©diane

**Gestion erreurs Bedrock** :
- Simulation timeout : Mock avec d√©lai > 30s
- Simulation rate limit : Mock avec erreur 429
- Simulation r√©ponse vide : Mock avec JSON invalide
- V√©rification retry automatique (3 tentatives)

**Validation contenu** :
- Entit√©s extraites coh√©rentes avec texte source
- Scores dans plages attendues (0-50 typique)
- Matching domaines conforme aux scopes configur√©s

---

## Phase 5 ‚Äì Plan de m√©triques & audit qualit√©

### M√©triques logu√©es

**Statistiques traitement** :
- `items_input_count` : Nombre items en entr√©e
- `items_normalized_count` : Nombre items normalis√©s avec succ√®s
- `items_matched_count` : Nombre items match√©s √† au moins un domaine
- `items_scored_count` : Nombre items avec score final
- `items_rejected_count` : Nombre items rejet√©s (avec raisons)

**M√©triques Bedrock** :
- `bedrock_calls_total` : Nombre total d'appels Bedrock
- `bedrock_calls_success` : Nombre d'appels r√©ussis
- `bedrock_calls_retry` : Nombre de retry effectu√©s
- `bedrock_calls_failed` : Nombre d'√©checs d√©finitifs
- `bedrock_latency_avg` : Latence moyenne par appel (ms)

**Distribution scores** :
- `scores_min`, `scores_max`, `scores_avg`, `scores_median`
- `scores_distribution` : Histogramme par tranches (0-5, 5-10, 10-15, 15+)
- `high_score_items_count` : Nombre items score > seuil client

### Protocole audit manuel

**√âchantillon repr√©sentatif** :
- 10 items par tranche de score (bas, moyen, √©lev√©)
- 5 items par type d'√©v√©nement (partnership, clinical, regulatory)
- 3 items par source principale (MedinCell, Camurus, FierceBiotech)

**Checklist qualitative** :
1. **Coh√©rence entit√©s** : Entit√©s extraites pr√©sentes dans le texte source ?
2. **Pertinence classification** : Type d'√©v√©nement correct ?
3. **Matching logique** : Domaines match√©s justifi√©s par les entit√©s ?
4. **Scoring coh√©rent** : Score final refl√®te la pertinence per√ßue ?
5. **Bruit filtr√©** : Items non-LAI correctement exclus ?

**M√©triques qualit√©** :
- Taux de coh√©rence entit√©s : % items avec entit√©s justifi√©es
- Taux de classification correcte : % items avec event_type pertinent  
- Taux de matching logique : % items avec domaines justifi√©s
- Taux de faux positifs : % items non-LAI avec score √©lev√©

### Logging et agr√©gation

**CloudWatch Logs** :
- Logs structur√©s JSON avec m√©triques par item
- Niveau INFO pour statistiques globales
- Niveau DEBUG pour d√©tails Bedrock et scoring

**M√©triques CloudWatch** (futur) :
- M√©triques custom pour dashboard : items/min, erreurs Bedrock, scores moyens
- Alarmes sur taux d'erreur > 10% ou latence > 60s

---

## Phase 6 ‚Äì Plan de d√©ploiement AWS (profil rag-lai-prod)

### Analyse m√©thode d√©ploiement actuelle

**M√©thode observ√©e pour ingest V2** :
- CloudFormation stack : `vectora-inbox-s1-runtime-dev`
- Template : `infra/s1-ingest-v2.yaml`
- D√©ploiement via CLI : `aws cloudformation deploy --profile rag-lai-prod --region eu-west-3`
- Code Lambda : Upload S3 puis update-function-code

**Ressources existantes r√©utilisables** :
- Buckets S3 : vectora-inbox-config-dev, vectora-inbox-data-dev
- R√¥les IAM : vectora-inbox-lambda-execution-role-dev
- Lambda Layers : vectora-core-layer, common-deps-layer (si existants)

### Int√©gration normalize-score-v2

**Nouveau template CloudFormation** : `infra/s1-normalize-score-v2.yaml`

**Ressources √† cr√©er** :
```yaml
VectoraInboxNormalizeScoreV2:
  Type: AWS::Lambda::Function
  Properties:
    FunctionName: vectora-inbox-normalize-score-v2-dev
    Runtime: python3.11
    Handler: handler.lambda_handler
    Code:
      S3Bucket: vectora-inbox-lambda-code-dev
      S3Key: normalize-score-v2.zip
    Environment:
      Variables:
        ENV: dev
        CONFIG_BUCKET: vectora-inbox-config-dev
        DATA_BUCKET: vectora-inbox-data-dev
        BEDROCK_MODEL_ID: eu.anthropic.claude-sonnet-4-5-20250929-v1:0
        BEDROCK_REGION_NORMALIZATION: us-east-1
    Layers:
      - !Ref VectoraCoreLayer
      - !Ref CommonDepsLayer
```

**Variables d'environnement** :
- `ENV` : dev (environnement de d√©ploiement)
- `CONFIG_BUCKET` : vectora-inbox-config-dev
- `DATA_BUCKET` : vectora-inbox-data-dev  
- `BEDROCK_MODEL_ID` : eu.anthropic.claude-sonnet-4-5-20250929-v1:0
- `BEDROCK_REGION_NORMALIZATION` : us-east-1

**Permissions IAM requises** :
- S3 : GetObject sur config-bucket, GetObject/PutObject sur data-bucket
- Bedrock : InvokeModel sur mod√®les Claude dans us-east-1
- CloudWatch : CreateLogGroup, CreateLogStream, PutLogEvents

### Commandes de d√©ploiement

**Packaging Lambda** :
```bash
cd src_v2/lambdas/normalize_score
zip -r ../../../normalize-score-v2.zip . -x "*.pyc" "__pycache__/*"
aws s3 cp normalize-score-v2.zip s3://vectora-inbox-lambda-code-dev/ --profile rag-lai-prod --region eu-west-3
```

**D√©ploiement stack** :
```bash
aws cloudformation deploy \
  --template-file infra/s1-normalize-score-v2.yaml \
  --stack-name vectora-inbox-s1-normalize-score-v2-dev \
  --capabilities CAPABILITY_IAM \
  --profile rag-lai-prod \
  --region eu-west-3
```

**Test post-d√©ploiement** :
```bash
aws lambda invoke \
  --function-name vectora-inbox-normalize-score-v2-dev \
  --payload '{"client_id": "lai_weekly"}' \
  --profile rag-lai-prod \
  --region eu-west-3 \
  response.json
```

### Liaison future EventBridge

**Trigger automatique** (√† impl√©menter plus tard) :
- EventBridge rule sur √©v√©nement "Ingestion Completed" de ingest V2
- Target : normalize-score-v2 avec transformation event
- Pattern : `{"source": ["vectora.inbox"], "detail-type": ["Ingestion Completed"]}`

---

## Phase 7 ‚Äì Crit√®res de succ√®s & risques

### Crit√®res de succ√®s

**D√©ploiement** :
- ‚úÖ Lambda d√©ployable sans violation r√®gles d'hygi√®ne V4
- ‚úÖ Aucune d√©pendance tierce dans /src_v2/
- ‚úÖ Handler < 5MB, utilisation layers pour vectora_core
- ‚úÖ Variables d'environnement correctement configur√©es

**Fonctionnel** :
- ‚úÖ Traitement correct dernier run lai_weekly_v3 (identification automatique)
- ‚úÖ Normalisation Bedrock : extraction entit√©s + classification √©v√©nements
- ‚úÖ Matching domaines : application r√®gles client_config
- ‚úÖ Scoring : calcul avec bonus/malus selon canonical
- ‚úÖ Output S3 : structure JSON conforme contrat newsletter V2

**Qualit√©** :
- ‚úÖ Logs et m√©triques suffisants pour √©valuer performance
- ‚úÖ Gestion erreurs Bedrock robuste (retry, timeout)
- ‚úÖ Code maintenable : fonctions pures, tests locaux
- ‚úÖ G√©n√©ricit√© : aucun couplage dur lai_weekly

### Principaux risques

**Identification dernier run** :
- üî¥ **Risque** : Logique fragile si convention S3 change
- üü° **Mitigation** : Tests avec multiples structures, gestion cas limites
- üü¢ **Fallback** : Param√®tre event pour forcer date sp√©cifique

**Co√ªt/latence Bedrock** :
- üî¥ **Risque** : Co√ªt √©lev√© si volume important (100+ items/run)
- üü° **Mitigation** : Monitoring co√ªts, optimisation prompts
- üü¢ **Fallback** : Param√®tre pour limiter nombre items trait√©s

**Complexit√© code** :
- üî¥ **Risque** : Sur-architecture si logique trop complexe
- üü° **Mitigation** : Revue code, privil√©gier simplicit√©
- üü¢ **Fallback** : Refactoring si n√©cessaire en Phase 2

**D√©pendance canonical** :
- üî¥ **Risque** : Couplage fort aux d√©tails scopes LAI
- üü° **Mitigation** : API stable config_loader, tests avec fixtures
- üü¢ **Fallback** : Graceful degradation si scopes manquants

**Performance Bedrock** :
- üî¥ **Risque** : Timeouts fr√©quents ou rate limiting
- üü° **Mitigation** : Retry exponentiel, monitoring latence
- üü¢ **Fallback** : Mode d√©grad√© sans normalisation Bedrock

---

## R√©sum√© ex√©cutif

Ce plan d'impl√©mentation respecte strictement les contraintes V4 et l'architecture 3 Lambdas V2. La strat√©gie d'identification du dernier run est robuste et bas√©e sur les conventions S3 existantes. Le code sera g√©n√©rique, pilot√© par configuration, et maintiendra la simplicit√© requise. Les tests locaux et m√©triques permettront de valider la qualit√© avant d√©ploiement AWS.

**Prochaine √©tape** : Validation de ce plan puis impl√©mentation Phase 3 (cr√©ation des modules vectora_core/normalization/).