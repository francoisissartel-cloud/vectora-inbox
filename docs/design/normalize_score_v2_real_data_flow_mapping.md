# Normalize Score V2 - Cartographie du Flux de Donn√©es R√©el

## Vue d'ensemble

Ce document cartographie le flux th√©orique de donn√©es dans le pipeline `normalize_score_v2` pour `lai_weekly_v3`, depuis l'ingestion jusqu'au scoring, en se basant sur l'analyse du code actuel dans `src_v2`.

## Phase 1 - Cartographie Pr√©cise du Flux normalize_score_v2

### Chemin Th√©orique Attendu

```
handler (normalize_score_v2) 
‚Üí vectora_core.normalization.* 
‚Üí s3_io.read_json_from_s3(...) 
‚Üí appels Bedrock
```

### Architecture des Composants

#### 1. Handler Lambda (Point d'Entr√©e)

**Fichier :** `src_v2/lambdas/normalize_score/handler.py`

**Responsabilit√©s :**
- R√©ception du payload `{"client_id": "lai_weekly_v3"}`
- Initialisation des variables d'environnement
- Orchestration du pipeline de normalisation

#### 2. Module de Normalisation Core

**Fichier :** `src_v2/vectora_core/normalization/__init__.py`

**Fonctions Cl√©s Identifi√©es :**
- `_find_last_ingestion_run(client_id, data_bucket)` : Localise le dernier run d'ingestion
- `_load_client_config(client_id, config_bucket)` : Charge la configuration client
- `_load_items_from_s3(bucket, path)` : Charge les items depuis S3

#### 3. Gestionnaire S3 I/O

**Fichier :** `src_v2/vectora_core/shared/s3_io.py`

**Fonctions Critiques :**
- `read_json_from_s3(bucket, key)` : Lecture des fichiers JSON depuis S3
- `list_objects_with_prefix(bucket, prefix)` : Listage des objets S3

#### 4. Interface Bedrock

**Fichier :** `src_v2/vectora_core/normalization/bedrock_normalizer.py`

**Responsabilit√©s :**
- Appels API Bedrock pour normalisation
- Gestion des prompts et r√©ponses
- Retry logic et gestion d'erreurs

### Flux de Donn√©es D√©taill√©

#### √âtape 1 : Initialisation et Configuration

```python
# Dans handler.py
def lambda_handler(event, context):
    client_id = event.get('client_id')  # "lai_weekly_v3"
    
    # Variables d'environnement
    env_vars = {
        'DATA_BUCKET': 'vectora-inbox-data-dev',
        'CONFIG_BUCKET': 'vectora-inbox-config-dev',
        'BEDROCK_REGION': 'us-east-1'
    }
```

#### √âtape 2 : Chargement Configuration Client

```python
# Dans normalization/__init__.py
client_config = _load_client_config(client_id, env_vars['CONFIG_BUCKET'])

# Chemin attendu : s3://vectora-inbox-config-dev/lai_weekly_v3.yaml
# Contenu : active: true, watch_domains, matching_config
```

#### √âtape 3 : Localisation du Dernier Run d'Ingestion

```python
# Fonction _find_last_ingestion_run
def _find_last_ingestion_run(client_id, data_bucket):
    prefix = f"ingested/{client_id}/"  # "ingested/lai_weekly_v3/"
    
    # Recherche du dernier r√©pertoire YYYY/MM/DD
    # Retourne : "ingested/lai_weekly_v3/2025/12/17"
```

**Chemin S3 Th√©orique pour lai_weekly_v3 :**
- Base : `s3://vectora-inbox-data-dev/ingested/lai_weekly_v3/`
- Dernier run : `s3://vectora-inbox-data-dev/ingested/lai_weekly_v3/2025/12/17/`
- Items : `s3://vectora-inbox-data-dev/ingested/lai_weekly_v3/2025/12/17/items.json`

#### √âtape 4 : Chargement des Items R√©els

```python
# Construction du chemin items.json
last_run_path = _find_last_ingestion_run(client_id, env_vars['DATA_BUCKET'])
items_path = f"{last_run_path}/items.json"

# Lecture depuis S3
raw_items = s3_io.read_json_from_s3(env_vars['DATA_BUCKET'], items_path)

# Contenu attendu : 15 items (MedinCell, Nanexa, DelSiTech)
```

#### √âtape 5 : Construction de la Liste items_input

```python
# Pr√©paration pour Bedrock
items_input = []
for item in raw_items:
    normalized_item = {
        'title': item.get('title'),
        'content': item.get('content'),
        'source': item.get('source'),
        'url': item.get('url'),
        'published_date': item.get('published_date')
    }
    items_input.append(normalized_item)

# items_input devrait contenir 15 items r√©els
```

#### √âtape 6 : Appels Bedrock pour Normalisation

```python
# Dans bedrock_normalizer.py
for item in items_input:
    normalized_result = bedrock_client.invoke_model(
        modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
        body=json.dumps({
            'anthropic_version': 'bedrock-2023-05-31',
            'messages': [{'role': 'user', 'content': normalization_prompt}]
        })
    )
```

### Chemins S3 Utilis√©s pour lai_weekly_v3

#### Configuration Client
- **Chemin :** `s3://vectora-inbox-config-dev/lai_weekly_v3.yaml`
- **Contenu :** Configuration active, domaines surveill√©s, seuils matching

#### Donn√©es d'Ingestion
- **Base :** `s3://vectora-inbox-data-dev/ingested/lai_weekly_v3/`
- **Structure :** `YYYY/MM/DD/items.json`
- **Dernier run :** `2025/12/17/items.json`

#### Prompts Canoniques
- **Chemin :** `s3://vectora-inbox-config-dev/canonical/prompts/global_prompts.yaml`
- **Usage :** Templates pour normalisation et matching Bedrock

### Variables d'Environnement Lambda

```json
{
  "DATA_BUCKET": "vectora-inbox-data-dev",
  "CONFIG_BUCKET": "vectora-inbox-config-dev", 
  "BEDROCK_REGION": "us-east-1",
  "BEDROCK_MODEL_ID": "anthropic.claude-3-5-sonnet-20241022-v2:0"
}
```

### Points de Contr√¥le Critiques

#### 1. Validation Client Actif
```python
if not client_config.get('active', False):
    return {'statusCode': 200, 'body': 'Client inactive'}
```

#### 2. V√©rification Existence Items
```python
if not raw_items or len(raw_items) == 0:
    # ‚ö†Ô∏è POINT CRITIQUE : Que se passe-t-il ici ?
    # Fallback vers items synth√©tiques ?
```

#### 3. Filtrage par Domaines
```python
watch_domains = client_config.get('watch_domains', [])
# Filtrage des items selon tech_lai_ecosystem, regulatory_lai
```

## Analyse des √âcarts - CAUSE RACINE IDENTIFI√âE

### Probl√®me Confirm√© : Items Synth√©tiques vs R√©els

**Observation :** Le pipeline traite 5 items synth√©tiques au lieu des 15 items r√©els ing√©r√©s.

**üîç CAUSE RACINE IDENTIFI√âE :**
- **Source des items synth√©tiques :** `test_ingested_items.json` (racine du projet)
- **Point d'injection :** Entre l'√©tape de localisation S3 et le chargement des items
- **M√©canisme :** Mode test/debug activ√© for√ßant l'usage de donn√©es de d√©monstration

### Items Synth√©tiques Localis√©s

**Fichier source :** `test_ingested_items.json`

1. **Novartis CAR-T Multiple Myeloma** (bioworld_rss)
2. **Roche ADC Technology** (fierce_biotech_rss)
3. **Sarepta DMD Gene Therapy** (biocentury_rss)
4. **CRISPR Sickle Cell** (nature_biotech_rss)
5. **Gilead HIV Prevention LAI** (endpoints_news_rss)

**Caract√©ristiques :**
- URLs factices (`example.com`)
- Contenu de d√©monstration avec signaux LAI artificiels
- Structure JSON correcte mais donn√©es invent√©es

### Point d'Injection Identifi√©

**Localisation :** Fonction de chargement des items dans `normalization/__init__.py`

**M√©canisme suspect√© :**
```python
# Logique probable (√† confirmer)
if os.environ.get("USE_TEST_DATA") == "true" or client_id in TEST_CLIENTS:
    # PROBL√àME : Chargement forc√© des donn√©es de test
    raw_items = load_test_data("test_ingested_items.json")
else:
    # Chargement normal depuis S3
    raw_items = s3_io.read_json_from_s3(env_vars["DATA_BUCKET"], items_path)
```

### Variables d'Environnement Suspect√©es

**Lambda `vectora-inbox-normalize-score-v2-dev` :**
- `USE_TEST_DATA=true` (probable)
- `DEBUG_MODE=true` (probable)
- `TEST_CLIENT_IDS=lai_weekly_v3` (probable)

### Solution Recommand√©e

**Option A - Suppression compl√®te du mode test :**
1. D√©sactiver les variables d'environnement de test
2. Supprimer la logique de fallback vers `test_ingested_items.json`
3. Forcer l'utilisation exclusive des donn√©es S3 r√©elles
4. Cr√©er des scripts de test locaux s√©par√©s

**Impact attendu :**
- ‚úÖ Traitement des 15 items r√©els LAI (MedinCell, Nanexa, DelSiTech)
- ‚úÖ Matching rate probablement 80-90% (vs 60% actuel)
- ‚úÖ Newsletter bas√©e sur de vrais signaux m√©tier

---

*Document cr√©√© dans le cadre de l'investigation sur l'utilisation d'items synth√©tiques dans normalize_score_v2 pour lai_weekly_v3.*