# Comparaison des Approches de Gestion des Prompts Bedrock - Vectora Inbox

**Date**: 2025-12-23  
**Auteur**: Amazon Q Developer  
**Objectif**: Analyser et comparer les diff√©rentes approches pour g√©rer les prompts Bedrock

---

## üéØ CONTEXTE ET OBJECTIFS

### Probl√®me √† R√©soudre

Le syst√®me actuel souffre de **hardcoding LAI** dans les prompts Bedrock, rendant impossible l'adaptation √† d'autres verticales sans modifier le code Python.

### Objectifs M√©tier

1. **G√©n√©ricit√©**: Support multi-verticales (LAI, Gene Therapy, Cell Therapy, etc.)
2. **Simplicit√©**: Ajustements sans modifier le code Python
3. **Puissance**: Pilotage fin du comportement du moteur
4. **Maintenabilit√©**: R√®gles m√©tier centralis√©es et lisibles
5. **Performance**: Temps de r√©ponse acceptable

### Deux Approches Propos√©es

**Approche A**: **Prompts Dynamiques** - Construction en temps r√©el depuis watch_domains + canonical  
**Approche B**: **Prompts Pr√©-construits** - Prompts fig√©s par client dans canonical, avec r√©f√©rences

---

## üìä APPROCHE A: PROMPTS DYNAMIQUES (TEMPS R√âEL)

### Principe

Les prompts sont **construits √† la vol√©e** √† chaque run en analysant:
- `client_config.yaml` (watch_domains)
- `canonical/scopes/*.yaml` (entit√©s, technologies)
- `canonical/prompts/global_prompts.yaml` (templates g√©n√©riques)

### Architecture

```
Runtime (chaque appel Bedrock)
    ‚Üì
1. Charger client_config.yaml
    ‚Üì
2. Analyser watch_domains
    ‚Üì
3. D√©tecter verticale (LAI, Gene Therapy, etc.)
    ‚Üì
4. Extraire exemples depuis canonical_scopes
    ‚Üì
5. Construire description technologies
    ‚Üì
6. Substituer variables dans template g√©n√©rique
    ‚Üì
7. Prompt final ‚Üí Bedrock
```

### Exemple de Flux

**Pour lai_weekly_v5**:

```python
# 1. Charger config
client_config = load_yaml("clients/lai_weekly_v5.yaml")
watch_domains = client_config['watch_domains']
# ‚Üí [{'id': 'tech_lai_ecosystem', 'technology_scope': 'lai_keywords', ...}]

# 2. D√©tecter verticale
technology_scope = watch_domains[0]['technology_scope']  # 'lai_keywords'
vertical = detect_vertical(technology_scope)  # ‚Üí 'LAI'

# 3. Charger scopes
canonical_scopes = load_yaml("canonical/scopes/technology_scopes.yaml")
lai_keywords = canonical_scopes['lai_keywords']
# ‚Üí {'core_phrases': [...], 'negative_terms': [...]}

# 4. Construire description
tech_description = build_technology_focus_description(lai_keywords, vertical)
# ‚Üí "LAI TECHNOLOGY FOCUS:\nDetect these technologies:\n- long-acting injectable\n..."

# 5. Extraire exemples
companies = extract_companies_examples(watch_domains, canonical_scopes)
# ‚Üí "MedinCell, Camurus, DelSiTech, Nanexa, Peptron"

# 6. Substituer dans template
template = canonical_prompts['normalization']['generic_biotech']['user_template']
prompt = template.replace('{{technology_focus_description}}', tech_description)
prompt = prompt.replace('{{companies_examples}}', companies)
# etc.

# 7. Appeler Bedrock
response = bedrock.invoke_model(prompt)
```

### Fichiers Impliqu√©s

**Nouveau module**:
- `src_v2/vectora_core/shared/prompt_builder.py` (200-300 lignes)

**Modifications**:
- `src_v2/vectora_core/normalization/bedrock_client.py` (remplacer hardcoding)
- `canonical/prompts/global_prompts.yaml` (template g√©n√©rique avec variables)

**Aucune modification**:
- `client-config-examples/*.yaml` (d√©j√† bien con√ßus)
- `canonical/scopes/*.yaml` (d√©j√† bien con√ßus)

### Avantages

‚úÖ **Flexibilit√© Maximale**:
- Ajout d'une verticale = cr√©er scopes + client_config (10 minutes)
- Aucune modification de code Python
- Adaptation automatique aux changements de scopes

‚úÖ **DRY (Don't Repeat Yourself)**:
- Un seul template g√©n√©rique pour toutes les verticales
- Pas de duplication de prompts
- Maintenance centralis√©e

‚úÖ **√âvolutivit√©**:
- Ajout de nouvelles variables facilement
- Extension du syst√®me sans refactoring
- Support de cas complexes (multi-domaines, hybrides)

‚úÖ **Coh√©rence Garantie**:
- Prompts toujours synchronis√©s avec les scopes
- Pas de risque de d√©synchronisation
- Mise √† jour des scopes = mise √† jour automatique des prompts

‚úÖ **Debugging Facilit√©**:
- Prompt final visible dans les logs
- Tra√ßabilit√© compl√®te de la construction
- Possibilit√© de logger les prompts g√©n√©r√©s

### Inconv√©nients

‚ùå **Overhead de Construction**:
- Construction du prompt √† chaque appel Bedrock
- ~50-100ms par item (n√©gligeable vs temps Bedrock ~2-5s)
- Peut √™tre optimis√© avec cache

‚ùå **Complexit√© du Code**:
- Module prompt_builder.py √† maintenir
- Logique de d√©tection de verticale
- Gestion des cas edge (scopes manquants, etc.)

‚ùå **Debugging Plus Complexe**:
- Prompt final pas directement visible dans les fichiers
- N√©cessite de logger pour voir le prompt r√©el
- Erreurs de substitution possibles

‚ùå **Risque de Bugs**:
- Erreurs dans la logique de construction
- Variables mal substitu√©es
- Cas edge non g√©r√©s

### Performance

**Temps de construction d'un prompt**:
- Chargement config: ~5ms (cach√©)
- Analyse watch_domains: ~10ms
- Extraction exemples: ~20ms
- Construction description: ~15ms
- Substitution variables: ~10ms
- **Total: ~60ms par item**

**Pour un batch de 100 items**:
- Construction prompts: 6 secondes
- Appels Bedrock: 200-500 secondes
- **Overhead: ~1-3% du temps total**

**Optimisation possible**:
- Cacher les caract√©ristiques d√©tect√©es par client_id
- Construire une seule fois au d√©but du batch
- **Overhead r√©duit √† <1%**

---

## üìã APPROCHE B: PROMPTS PR√â-CONSTRUITS (CANONICAL)

### Principe

Les prompts sont **pr√©-√©crits en dur** dans des fichiers canonical, un par client ou par verticale, avec des **r√©f√©rences** aux scopes canonical pour les exemples.

### Architecture

```
Pr√©paration (une fois, par humain)
    ‚Üì
1. Cr√©er prompt LAI dans canonical/prompts/lai_normalization.yaml
2. Inclure r√©f√©rences aux scopes: {{ref:lai_companies_global}}
3. √âcrire le prompt complet avec toutes les instructions
    ‚Üì
Runtime (chaque appel Bedrock)
    ‚Üì
4. Charger prompt pr√©-construit
5. R√©soudre les r√©f√©rences ({{ref:...}})
6. Substituer uniquement {{item_text}}
7. Prompt final ‚Üí Bedrock
```

### Exemple de Structure

**Fichier**: `canonical/prompts/lai_normalization_prompt.yaml`

```yaml
# Prompt pr√©-construit pour la verticale LAI
lai_normalization:
  system_instructions: |
    You are a specialized AI assistant for biotech/pharma news analysis.
    Focus on Long-Acting Injectable (LAI) technologies and related entities.
    
  user_template: |
    Analyze this biotech/pharma news item and extract structured information.

    CRITICAL: Only extract entities that are EXPLICITLY mentioned in the text.

    TEXT TO ANALYZE:
    {{item_text}}

    LAI TECHNOLOGY FOCUS:
    Detect these Long-Acting Injectable technologies ONLY if explicitly mentioned:
    - long-acting injectable
    - extended-release injection
    - depot injection
    - once-monthly injection
    - three-month injectable
    - microspheres
    - PLGA
    - in-situ depot
    - hydrogel
    - subcutaneous injection
    - intramuscular injection

    EXAMPLES OF ENTITIES TO DETECT:
    - Companies: {{ref:lai_companies_global}}
    - Molecules: {{ref:lai_molecules_global}}
    - Technologies: {{ref:lai_keywords.core_phrases}}
    - Trademarks: {{ref:lai_trademarks_global}}

    EXCLUDE if these terms are present:
    - oral tablet
    - topical cream
    - transdermal patch

    TASK:
    1. Generate a concise summary (2-3 sentences)
    2. Classify the event type among: clinical_update, partnership, regulatory, ...
    3. Extract ALL pharmaceutical/biotech company names mentioned
    4. Extract ALL drug/molecule names mentioned
    5. Extract ALL technology keywords mentioned
    6. Extract ALL trademark names mentioned
    7. Extract ALL therapeutic indications mentioned
    8. Evaluate LAI relevance (0-10 score)
    9. Detect anti-LAI signals
    10. Assess pure player context

    RESPONSE FORMAT (JSON only):
    {
      "summary": "...",
      "event_type": "...",
      "companies_detected": ["...", "..."],
      "molecules_detected": ["...", "..."],
      "technologies_detected": ["...", "..."],
      "trademarks_detected": ["...", "..."],
      "indications_detected": ["...", "..."],
      "lai_relevance_score": 0,
      "anti_lai_detected": false,
      "pure_player_context": false
    }

    Respond with ONLY the JSON, no additional text.
```

**Fichier**: `canonical/prompts/gene_therapy_normalization_prompt.yaml`

```yaml
# Prompt pr√©-construit pour la verticale Gene Therapy
gene_therapy_normalization:
  system_instructions: |
    You are a specialized AI assistant for biotech/pharma news analysis.
    Focus on Gene Therapy technologies and related entities.
    
  user_template: |
    Analyze this biotech/pharma news item and extract structured information.

    CRITICAL: Only extract entities that are EXPLICITLY mentioned in the text.

    TEXT TO ANALYZE:
    {{item_text}}

    GENE THERAPY TECHNOLOGY FOCUS:
    Detect these Gene Therapy technologies ONLY if explicitly mentioned:
    - gene therapy
    - AAV vector
    - lentiviral vector
    - CRISPR-Cas9
    - gene editing
    - adeno-associated virus
    - viral vector
    - ex vivo gene therapy
    - in vivo gene therapy

    EXAMPLES OF ENTITIES TO DETECT:
    - Companies: {{ref:gene_therapy_companies_global}}
    - Molecules: {{ref:gene_therapy_molecules_global}}
    - Technologies: {{ref:gene_therapy_keywords.core_phrases}}

    EXCLUDE if these terms are present:
    - small molecule
    - traditional drug

    TASK:
    [... m√™me structure que LAI ...]

    Evaluate Gene Therapy relevance (0-10 score)
```

### Configuration Client

**Fichier**: `client-config-examples/lai_weekly_v5.yaml`

```yaml
# R√©f√©rence au prompt pr√©-construit
bedrock_config:
  normalization_prompt: "lai_normalization"  # Cl√© dans canonical/prompts/
  matching_prompt: "lai_matching"

watch_domains:
  - id: "tech_lai_ecosystem"
    technology_scope: "lai_keywords"
    company_scope: "lai_companies_global"
```

### Code de R√©solution

**Nouveau module**: `src_v2/vectora_core/shared/prompt_resolver.py`

```python
def resolve_prompt_references(
    prompt_template: str,
    canonical_scopes: Dict
) -> str:
    """
    R√©sout les r√©f√©rences {{ref:...}} dans un prompt pr√©-construit.
    
    Exemples:
        {{ref:lai_companies_global}} ‚Üí "MedinCell, Camurus, DelSiTech, ..."
        {{ref:lai_keywords.core_phrases}} ‚Üí "long-acting injectable, depot, ..."
    """
    import re
    
    # Pattern pour d√©tecter {{ref:scope_name}} ou {{ref:scope_name.field}}
    pattern = r'\{\{ref:([a-z_]+)(?:\.([a-z_]+))?\}\}'
    
    def replace_ref(match):
        scope_name = match.group(1)
        field_name = match.group(2)
        
        # Charger le scope
        scope_data = canonical_scopes.get(scope_name)
        if not scope_data:
            return f"[ERROR: scope '{scope_name}' not found]"
        
        # Si field sp√©cifi√©, extraire le champ
        if field_name:
            if isinstance(scope_data, dict):
                field_data = scope_data.get(field_name, [])
            else:
                return f"[ERROR: scope '{scope_name}' is not a dict]"
        else:
            field_data = scope_data
        
        # Formater en liste
        if isinstance(field_data, list):
            return ', '.join(field_data[:15])  # Max 15 exemples
        else:
            return str(field_data)
    
    # Remplacer toutes les r√©f√©rences
    resolved = re.sub(pattern, replace_ref, prompt_template)
    return resolved
```

**Utilisation dans bedrock_client.py**:

```python
def _build_normalization_prompt_prebuilt(
    self, item_text, client_config, canonical_scopes, canonical_prompts
):
    # 1. R√©cup√©rer le nom du prompt depuis client_config
    prompt_name = client_config.get('bedrock_config', {}).get('normalization_prompt', 'lai_normalization')
    
    # 2. Charger le prompt pr√©-construit
    prompt_config = canonical_prompts.get(prompt_name)
    if not prompt_config:
        raise ValueError(f"Prompt '{prompt_name}' not found in canonical/prompts/")
    
    # 3. R√©cup√©rer le template
    template = prompt_config['user_template']
    
    # 4. R√©soudre les r√©f√©rences {{ref:...}}
    from ..shared.prompt_resolver import resolve_prompt_references
    resolved = resolve_prompt_references(template, canonical_scopes)
    
    # 5. Substituer {{item_text}}
    final_prompt = resolved.replace('{{item_text}}', item_text)
    
    return final_prompt
```

### Fichiers Impliqu√©s

**Nouveaux fichiers**:
- `canonical/prompts/lai_normalization_prompt.yaml`
- `canonical/prompts/gene_therapy_normalization_prompt.yaml`
- `canonical/prompts/cell_therapy_normalization_prompt.yaml`
- `src_v2/vectora_core/shared/prompt_resolver.py` (50-100 lignes)

**Modifications**:
- `src_v2/vectora_core/normalization/bedrock_client.py` (utiliser prompt_resolver)
- `client-config-examples/*.yaml` (ajouter bedrock_config.normalization_prompt)

**Aucune modification**:
- `canonical/scopes/*.yaml` (d√©j√† bien con√ßus)

### Avantages

‚úÖ **Simplicit√© du Code**:
- Pas de logique complexe de construction
- Module prompt_resolver simple (~50 lignes)
- Moins de risques de bugs

‚úÖ **Visibilit√© Directe**:
- Prompt complet visible dans un fichier
- Facile √† lire et comprendre
- Debugging imm√©diat

‚úÖ **Performance Optimale**:
- Pas de construction dynamique
- R√©solution des r√©f√©rences rapide (~10ms)
- Overhead minimal (<1%)

‚úÖ **Contr√¥le Total**:
- Humain √©crit le prompt exact
- Pas de "magie" de construction
- Ajustements fins possibles

‚úÖ **Validation Facile**:
- Prompt peut √™tre test√© directement
- Copier-coller dans Bedrock Playground
- It√©ration rapide

### Inconv√©nients

‚ùå **Duplication de Contenu**:
- Un prompt par verticale
- Instructions r√©p√©t√©es (CRITICAL, TASK, RESPONSE FORMAT)
- Maintenance de plusieurs fichiers

‚ùå **Risque de D√©synchronisation**:
- Prompt peut devenir obsol√®te si scopes changent
- R√©f√©rences {{ref:...}} peuvent pointer vers scopes inexistants
- N√©cessite vigilance humaine

‚ùå **Moins Flexible**:
- Ajout d'une verticale = √©crire un nouveau prompt complet
- Changement de structure = modifier tous les prompts
- Pas d'adaptation automatique

‚ùå **Maintenance Plus Lourde**:
- Plusieurs prompts √† maintenir
- Risque d'incoh√©rences entre prompts
- Changement global = modifier N fichiers

‚ùå **Pas de G√©n√©ricit√©**:
- Chaque verticale a son prompt
- Pas de r√©utilisation de logique
- Duplication des r√®gles m√©tier

### Performance

**Temps de r√©solution d'un prompt**:
- Chargement prompt: ~5ms (cach√©)
- R√©solution r√©f√©rences: ~10ms
- Substitution {{item_text}}: ~1ms
- **Total: ~16ms par item**

**Pour un batch de 100 items**:
- R√©solution prompts: 1.6 secondes
- Appels Bedrock: 200-500 secondes
- **Overhead: <1% du temps total**

---

## ‚öñÔ∏è COMPARAISON D√âTAILL√âE

### 1. G√©n√©ricit√©

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Support multi-verticales | ‚úÖ Automatique | ‚ö†Ô∏è Manuel (un prompt par verticale) |
| Ajout nouvelle verticale | ‚úÖ 10 minutes (scopes + config) | ‚ö†Ô∏è 30-60 minutes (√©crire prompt complet) |
| Adaptation automatique | ‚úÖ Oui | ‚ùå Non |
| R√©utilisation de logique | ‚úÖ Template unique | ‚ùå Duplication |

**Gagnant**: Approche A (Dynamique)

### 2. Simplicit√©

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Complexit√© du code | ‚ö†Ô∏è Module prompt_builder (200-300 lignes) | ‚úÖ Module prompt_resolver (50-100 lignes) |
| Lisibilit√© | ‚ö†Ô∏è Prompt final pas directement visible | ‚úÖ Prompt complet visible dans fichier |
| Debugging | ‚ö†Ô∏è N√©cessite logs | ‚úÖ Imm√©diat |
| Risque de bugs | ‚ö†Ô∏è Logique de construction | ‚úÖ R√©solution simple |

**Gagnant**: Approche B (Pr√©-construit)

### 3. Maintenabilit√©

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Nombre de fichiers | ‚úÖ 1 template g√©n√©rique | ‚ùå N prompts (un par verticale) |
| Coh√©rence | ‚úÖ Garantie (m√™me template) | ‚ö†Ô∏è Risque d'incoh√©rences |
| Changement global | ‚úÖ Modifier 1 template | ‚ùå Modifier N prompts |
| Synchronisation scopes | ‚úÖ Automatique | ‚ö†Ô∏è Manuelle |

**Gagnant**: Approche A (Dynamique)

### 4. Performance

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Overhead par item | ‚ö†Ô∏è ~60ms (optimisable √† ~1ms) | ‚úÖ ~16ms |
| Overhead batch 100 items | ‚ö†Ô∏è 6s (optimisable √† 0.1s) | ‚úÖ 1.6s |
| % du temps total | ‚úÖ <3% (optimisable √† <1%) | ‚úÖ <1% |
| Optimisation possible | ‚úÖ Cache | ‚úÖ D√©j√† optimal |

**Gagnant**: Approche B (Pr√©-construit) - mais diff√©rence n√©gligeable

### 5. Flexibilit√©

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Ajout de variables | ‚úÖ Facile | ‚ö†Ô∏è Modifier tous les prompts |
| Cas complexes | ‚úÖ Logique programmable | ‚ö†Ô∏è Limit√© aux r√©f√©rences |
| Multi-domaines | ‚úÖ Support natif | ‚ö†Ô∏è Complexe |
| Hybrides | ‚úÖ Support natif | ‚ö†Ô∏è Complexe |

**Gagnant**: Approche A (Dynamique)

### 6. Contr√¥le Humain

| Crit√®re | Approche A (Dynamique) | Approche B (Pr√©-construit) |
|---------|------------------------|----------------------------|
| Visibilit√© du prompt | ‚ö†Ô∏è N√©cessite logs | ‚úÖ Fichier complet |
| Ajustements fins | ‚ö†Ô∏è Via template + logique | ‚úÖ Direct dans fichier |
| Test manuel | ‚ö†Ô∏è G√©n√©rer puis tester | ‚úÖ Copier-coller dans Playground |
| It√©ration | ‚ö†Ô∏è Modifier template + tester | ‚úÖ Modifier fichier + tester |

**Gagnant**: Approche B (Pr√©-construit)

---

## üé® APPROCHE HYBRIDE (RECOMMAND√âE)

### Principe

Combiner les avantages des deux approches:
- **Prompts pr√©-construits** pour les verticales √©tablies (LAI, Gene Therapy)
- **Construction dynamique** comme fallback pour nouveaux cas
- **R√©f√©rences canonical** pour √©viter la duplication

### Architecture

```
Runtime
    ‚Üì
1. Charger client_config
2. V√©rifier si prompt pr√©-construit existe
    ‚Üì
    OUI ‚Üí Approche B (r√©solution r√©f√©rences)
    NON ‚Üí Approche A (construction dynamique)
    ‚Üì
3. Prompt final ‚Üí Bedrock
```

### Exemple

**Pour LAI (verticale √©tablie)**:
- Utiliser `canonical/prompts/lai_normalization_prompt.yaml`
- R√©solution rapide des r√©f√©rences
- Prompt optimis√© et test√©

**Pour nouvelle verticale (ex: RNA Therapeutics)**:
- Pas de prompt pr√©-construit
- Construction dynamique depuis scopes
- Permet de d√©marrer rapidement

**Apr√®s validation**:
- Cr√©er prompt pr√©-construit pour RNA Therapeutics
- Optimiser et affiner
- Basculer sur approche B

### Avantages

‚úÖ **Meilleur des deux mondes**:
- Performance optimale pour verticales √©tablies
- Flexibilit√© pour nouveaux cas
- Migration progressive

‚úÖ **√âvolutivit√©**:
- D√©marrer avec dynamique
- Stabiliser avec pr√©-construit
- Pas de refactoring majeur

‚úÖ **Pragmatisme**:
- Investissement proportionnel √† la maturit√©
- Pas de sur-engineering
- Adaptation au besoin r√©el

### Impl√©mentation

```python
def build_normalization_prompt(
    item_text, client_config, watch_domains, 
    canonical_scopes, canonical_prompts
):
    # 1. V√©rifier si prompt pr√©-construit existe
    prompt_name = client_config.get('bedrock_config', {}).get('normalization_prompt')
    
    if prompt_name and prompt_name in canonical_prompts:
        # Approche B: Prompt pr√©-construit
        return build_prompt_prebuilt(
            item_text, prompt_name, canonical_scopes, canonical_prompts
        )
    else:
        # Approche A: Construction dynamique
        return build_prompt_dynamic(
            item_text, watch_domains, canonical_scopes, canonical_prompts
        )
```

---

## üìã RECOMMANDATION FINALE

### Pour Vectora Inbox Actuel (LAI)

**Recommandation**: **Approche B (Pr√©-construit)** avec migration progressive

**Justification**:

1. **LAI est une verticale √©tablie**:
   - Prompt bien d√©fini et test√©
   - Peu de changements attendus
   - Performance optimale importante

2. **Simplicit√© prioritaire**:
   - Solo founder doit maintenir le syst√®me
   - Debugging facile crucial
   - Moins de code = moins de bugs

3. **Visibilit√© n√©cessaire**:
   - Prompt visible pour ajustements
   - Tests manuels fr√©quents
   - It√©ration rapide

4. **Performance compte**:
   - 100-200 items par run
   - Overhead minimal souhaitable
   - Bedrock d√©j√† co√ªteux

### Plan de Migration

**Phase 1** (Imm√©diat):
- Cr√©er `canonical/prompts/lai_normalization_prompt.yaml`
- Impl√©menter `prompt_resolver.py` (50 lignes)
- Modifier `bedrock_client.py` pour utiliser prompt pr√©-construit
- Tester avec lai_weekly_v5

**Phase 2** (Si nouvelle verticale):
- Cr√©er prompt pr√©-construit pour la nouvelle verticale
- R√©utiliser la structure LAI
- Adapter les instructions sp√©cifiques

**Phase 3** (Si besoin de g√©n√©ricit√©):
- Impl√©menter `prompt_builder.py` comme fallback
- Utiliser pour prototypage rapide
- Migrer vers pr√©-construit apr√®s validation

### Crit√®res de D√©cision

**Utiliser Approche B (Pr√©-construit) si**:
- ‚úÖ Verticale √©tablie et stable
- ‚úÖ Prompt bien d√©fini
- ‚úÖ Performance critique
- ‚úÖ Debugging fr√©quent
- ‚úÖ Solo founder

**Utiliser Approche A (Dynamique) si**:
- ‚úÖ Nombreuses verticales (>5)
- ‚úÖ Changements fr√©quents de structure
- ‚úÖ Cas complexes (multi-domaines, hybrides)
- ‚úÖ √âquipe de d√©veloppement
- ‚úÖ G√©n√©ricit√© prioritaire

**Pour Vectora Inbox**: Approche B est plus adapt√©e au contexte actuel.

---

## üéØ CONCLUSION

### Synth√®se

| Aspect | Approche A (Dynamique) | Approche B (Pr√©-construit) | Hybride |
|--------|------------------------|----------------------------|---------|
| G√©n√©ricit√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Simplicit√© | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Maintenabilit√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Performance | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Flexibilit√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Contr√¥le | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **TOTAL** | **24/30** | **23/30** | **26/30** |

### D√©cision pour Vectora Inbox

**Approche Recommand√©e**: **Approche B (Pr√©-construit)** avec possibilit√© de fallback dynamique

**Raisons**:
1. Solo founder ‚Üí simplicit√© prioritaire
2. LAI verticale √©tablie ‚Üí prompt stable
3. Performance importante ‚Üí overhead minimal
4. Debugging fr√©quent ‚Üí visibilit√© n√©cessaire
5. Migration progressive possible ‚Üí pas de sur-engineering

**Prochaines √âtapes**:
1. Cr√©er `lai_normalization_prompt.yaml`
2. Impl√©menter `prompt_resolver.py`
3. Tester avec lai_weekly_v5
4. Documenter pour futures verticales

---

*Document de comparaison r√©alis√© le 2025-12-23*  
*Bas√© sur l'analyse compl√®te du code, des diagnostics et du contexte m√©tier*  
*Objectif: Choisir la meilleure approche pour Vectora Inbox*
