# Plan d'Ex√©cution - Vectora Inbox LLM Matching/Scoring

**Date** : 2025-12-12  
**Objectif** : Impl√©mentation progressive du LLM gating pour matching/scoring  
**Client cible** : lai_weekly_v3  
**Contrainte** : SANS casser le workflow existant (fallback d√©terministe obligatoire)  

---

## üéØ Objectif Global

Mettre en place un vrai "LLM gating" pour le matching/scoring, en s'appuyant sur Bedrock, avec :
- Un prompt d√©di√© LLM-matching/scoring d√©fini dans `canonical/prompts/global_prompts.yaml`
- Un pipeline hybride : r√®gles d√©terministes + signaux LLM
- Une impl√©mentation s√ªre, progressive, test√©e localement puis d√©ploy√©e sur AWS
- SANS casser le workflow existant (fallback d√©terministe obligatoire)

---

## üìã Phases d'Ex√©cution

### Phase A ‚Äì Quick Win : Exploiter les signaux LLM d√©j√† pr√©sents

**Objectif** : Utiliser ce que Bedrock produit d√©j√† (ex. `lai_relevance_score`) dans le scoring, SANS ajout d'un nouveau prompt.

#### A1. Diagnostic des signaux existants
**Type** : Diagnostic  
**Objectif** : Identifier les signaux LLM d√©j√† pr√©sents dans les items normalis√©s  

**Fichiers concern√©s** :
- Analyse des items S3 normalis√©s pour `lai_weekly_v3`
- `src/vectora_core/bedrock/bedrock_client.py` (prompt de normalisation actuel)

**Travail** :
- Examiner les r√©ponses Bedrock de normalisation existantes
- Identifier les champs de pertinence : `lai_relevance_score`, `domain_relevance`, etc.
- V√©rifier leur s√©rialisation dans les items S3 normalis√©s
- Analyser leur distribution et fiabilit√©

**Crit√®res de succ√®s** :
- Documentation compl√®te des signaux LLM existants
- Compr√©hension de leur format et distribution
- Identification des champs exploitables pour le scoring

**Livrables** :
- `docs/diagnostics/vectora_inbox_llm_matching_phaseA_current_signals.md`

**Condition pour passer √† A2** : Signaux LLM identifi√©s et document√©s

---

#### A2. Int√©gration minimale dans le scoring
**Type** : Code + Configuration  
**Objectif** : Utiliser les signaux LLM existants dans le calcul de score  

**Fichiers concern√©s** :
- `src/vectora_core/scoring/scorer.py`
- `canonical/scoring/scoring_rules.yaml`
- Variables d'environnement (feature flag)

**Travail** :
- Ajouter feature flag `USE_LLM_RELEVANCE` (d√©faut: false)
- Modifier `scorer.py` pour lire les champs LLM si pr√©sents
- Int√©grer comme multiplicateur/bonus dans le calcul de score
- Assurer que le comportement par d√©faut reste STRICTEMENT identique

**Crit√®res de succ√®s** :
- Scoring sans flag = comportement actuel inchang√©
- Scoring avec flag = int√©gration des signaux LLM
- Tests unitaires passent
- Pas de r√©gression sur le workflow existant

**Livrables** :
- Code modifi√© avec feature flag
- Tests unitaires mis √† jour

**Condition pour passer √† A3** : Code fonctionnel avec tests passants

---

#### A3. Tests locaux
**Type** : Tests  
**Objectif** : Valider le comportement avec/sans LLM relevance  

**Fichiers concern√©s** :
- `tests/unit/scoring/test_scorer.py`
- `tests/integration/`

**Travail** :
- Tests unitaires : scoring identique sans flag
- Tests unitaires : scoring modifi√© avec flag actif
- Tests d'int√©gration avec donn√©es r√©elles `lai_weekly_v3`
- Validation des calculs de score

**Crit√®res de succ√®s** :
- Tous les tests passent
- Comportement par d√©faut pr√©serv√©
- Impact LLM mesurable et coh√©rent

**Livrables** :
- `docs/diagnostics/vectora_inbox_llm_matching_phaseA_local_tests.md`

**Condition pour passer √† A4** : Tests locaux valid√©s et document√©s

---

#### A4. D√©ploiement AWS DEV
**Type** : D√©ploiement + Validation  
**Objectif** : Tester en conditions r√©elles sur AWS DEV  

**Fichiers concern√©s** :
- Lambda `engine` (d√©ploiement DEV)
- Configuration environnement DEV

**Travail** :
- D√©ployer les modifications sur AWS DEV
- Activer `USE_LLM_RELEVANCE=true` UNIQUEMENT pour `lai_weekly_v3`
- Lancer un run r√©el complet
- Collecter m√©triques avant/apr√®s
- Comparer distribution des scores et s√©lection finale

**Crit√®res de succ√®s** :
- Run complet r√©ussi sans erreur
- M√©triques collect√©es et analys√©es
- Impact LLM document√©
- Workflow end-to-end fonctionnel

**Livrables** :
- `docs/diagnostics/vectora_inbox_llm_matching_phaseA_aws_results.md`

**Condition pour passer √† Phase B** : Phase A stabilis√©e et document√©e avec r√©sultats AWS concluants

---

### Phase B ‚Äì Nouveau prompt d√©di√© LLM-matching

**Objectif** : Introduire un DEUXI√àME prompt Bedrock pour le "domain relevance / matching LLM" configurable dans canonical.

#### B1. Design d√©taill√© du prompt et de l'API interne
**Type** : Design + Configuration  
**Objectif** : D√©finir le prompt LLM-matching dans canonical  

**Fichiers concern√©s** :
- `canonical/prompts/global_prompts.yaml`
- Sp√©cifications API interne

**Travail** :
- Ajouter entr√©e `llm_matching_prompt` dans `global_prompts.yaml`
- D√©finir format d'input : texte, entit√©s, watch_domains
- D√©finir format d'output : relevance_score, is_relevant, reason par domaine
- Sp√©cifier configuration Bedrock (mod√®le, tokens, temp√©rature)

**Crit√®res de succ√®s** :
- Prompt clairement d√©fini et document√©
- Format input/output sp√©cifi√©
- Configuration Bedrock optimis√©e

**Livrables** :
- `docs/design/vectora_inbox_llm_matching_prompt_spec.md`
- `canonical/prompts/global_prompts.yaml` mis √† jour

**Condition pour passer √† B2** : Sp√©cifications compl√®tes et valid√©es

---

#### B2. Impl√©mentation du LLM matcher
**Type** : Code  
**Objectif** : Cr√©er le module LLM matcher autonome  

**Fichiers concern√©s** :
- `src/vectora_core/matching/llm_matcher.py` (nouveau)
- `tests/unit/matching/test_llm_matcher.py` (nouveau)

**Travail** :
- Cr√©er module `llm_matcher.py`
- Fonctions : construire input, appeler Bedrock, parser output
- Gestion d'erreurs et fallback
- Tests unitaires avec fixtures synth√©tiques

**Crit√®res de succ√®s** :
- Module autonome fonctionnel
- Tests unitaires passants
- Gestion d'erreurs robuste
- Pas d'appel Bedrock r√©el dans les tests unitaires

**Livrables** :
- Code du module LLM matcher
- Tests unitaires

**Condition pour passer √† B3** : Module test√© et fonctionnel

---

#### B3. Int√©gration dans la Lambda
**Type** : Code + Int√©gration  
**Objectif** : Int√©grer LLM matcher dans le pipeline  

**Fichiers concern√©s** :
- `src/vectora_core/bedrock/bedrock_client.py`
- Lambda `ingest-normalize` ou `engine` (√† d√©terminer)

**Travail** :
- Choisir point d'int√©gration optimal (apr√®s normalisation)
- Ajouter feature flag `USE_LLM_MATCHING`
- Int√©grer appel LLM matcher avec gestion d'erreurs
- Fallback automatique en cas d'erreur Bedrock

**Crit√®res de succ√®s** :
- Int√©gration transparente dans le pipeline
- Feature flag fonctionnel
- Fallback robuste en cas d'erreur
- Pas de r√©gression du workflow existant

**Livrables** :
- Code d'int√©gration
- Tests d'int√©gration

**Condition pour passer √† B4** : Int√©gration stable et test√©e

---

#### B4. Hybridation matching LLM + r√®gles d√©terministes
**Type** : Code  
**Objectif** : Combiner matching LLM et d√©terministe  

**Fichiers concern√©s** :
- `src/vectora_core/matching/domain_matcher.py`
- `canonical/matching/matching_rules.yaml`

**Travail** :
- Modifier `domain_matcher.py` pour consommer r√©sultats LLM
- Logique hybride : LLM_score + r√®gles d√©terministes
- Priorisation intelligente (LLM confiant vs r√®gles critiques)
- Pr√©servation du chemin 100% d√©terministe

**Crit√®res de succ√®s** :
- Logique hybride fonctionnelle
- √âquilibre LLM/d√©terministe configurable
- Chemin d√©terministe pr√©serv√©
- Tests de non-r√©gression passants

**Livrables** :
- Code de matching hybride
- Configuration des r√®gles

**Condition pour passer √† B5** : Matching hybride valid√©

---

#### B5. Ajustement du scoring
**Type** : Code  
**Objectif** : Int√©grer scores LLM dans le calcul final  

**Fichiers concern√©s** :
- `src/vectora_core/scoring/scorer.py`
- `canonical/scoring/scoring_rules.yaml`

**Travail** :
- Int√©grer `domain_relevance` LLM dans le scoring
- Pond√©ration configurable LLM vs autres signaux
- Maintenir compatibilit√© avec Phase A
- Documentation de la logique de scoring

**Crit√®res de succ√®s** :
- Scoring enrichi fonctionnel
- Pond√©ration configurable
- Compatibilit√© Phase A pr√©serv√©e
- Logique document√©e

**Livrables** :
- `docs/design/vectora_inbox_llm_matching_scoring_logic.md`
- Code de scoring mis √† jour

**Condition pour passer √† Phase C** : Scoring hybride complet et document√©

---

### Phase C ‚Äì Tests, m√©triques et d√©ploiement AWS

**Objectif** : Validation compl√®te et d√©ploiement en conditions r√©elles.

#### C1. Tests locaux
**Type** : Tests + Validation  
**Objectif** : Validation sur dataset de r√©f√©rence  

**Fichiers concern√©s** :
- `tests/integration/test_llm_matching_complete.py`
- Dataset de r√©f√©rence

**Travail** :
- Construire dataset de r√©f√©rence avec cas m√©tiers cl√©s
- Tester sc√©narios : d√©terministe seul, Phase A, Phase B compl√®te
- Mesurer taux de r√©cup√©ration, bruit, stabilit√©
- Validation des performances

**Crit√®res de succ√®s** :
- Dataset repr√©sentatif construit
- Tous les sc√©narios test√©s
- M√©triques de qualit√© mesur√©es
- Performance acceptable

**Livrables** :
- Dataset de r√©f√©rence
- R√©sultats de tests complets

**Condition pour passer √† C2** : Tests locaux concluants

---

#### C2. D√©ploiement AWS DEV
**Type** : D√©ploiement + Validation  
**Objectif** : Test en conditions r√©elles AWS  

**Fichiers concern√©s** :
- Lambdas `ingest-normalize` + `engine` (DEV)
- Configuration environnement

**Travail** :
- D√©ployer modifications compl√®tes sur AWS DEV
- Activer `USE_LLM_MATCHING=true` pour `lai_weekly_v3`
- Run complet r√©el avec m√©triques
- Collecte performance et co√ªt

**Crit√®res de succ√®s** :
- D√©ploiement r√©ussi sans erreur
- Run complet fonctionnel
- M√©triques collect√©es
- Co√ªt estim√© acceptable

**Livrables** :
- M√©triques de run r√©el
- Analyse performance/co√ªt

**Condition pour passer √† C3** : Run AWS r√©ussi avec m√©triques satisfaisantes

---

#### C3. Diagnostic & Synth√®se
**Type** : Documentation + Recommandations  
**Objectif** : Bilan complet et recommandations  

**Fichiers concern√©s** :
- Documentation finale

**Travail** :
- Diagnostic global des r√©sultats
- Analyse impact qualit√©/co√ªt
- Recommandations pour la suite
- Synth√®se ex√©cutive

**Crit√®res de succ√®s** :
- Diagnostic complet r√©dig√©
- Impact clairement quantifi√©
- Recommandations actionnables
- Architecture valid√©e ou ajustements propos√©s

**Livrables** :
- `docs/diagnostics/vectora_inbox_llm_matching_scoring_phaseC_results.md`
- `docs/diagnostics/vectora_inbox_llm_matching_scoring_phaseC_executive_summary.md`

**Condition de fin** : Documentation compl√®te et recommandations formul√©es

---

## üö® Contraintes et Garde-fous

### Feature Flags Obligatoires
- `USE_LLM_RELEVANCE` : Utilisation signaux LLM existants (Phase A)
- `USE_LLM_MATCHING` : Nouveau prompt LLM matching (Phase B)
- D√©faut : `false` pour tous les flags
- Activation : uniquement pour `lai_weekly_v3` en DEV

### Fallback Automatique
- En cas d'erreur Bedrock : fallback d√©terministe automatique
- Logging des erreurs sans casser le pipeline
- Workflow end-to-end toujours fonctionnel

### Validation Continue
- Chaque phase doit √™tre stabilis√©e avant passage √† la suivante
- Tests de non-r√©gression obligatoires
- Documentation des probl√®mes et corrections

### Donn√©es R√©elles Uniquement
- Pas de simulation ou donn√©es synth√©tiques pour la validation
- Utilisation des vraies Lambdas, S3, et runs `lai_weekly_v3`
- Correction des probl√®mes techniques avant continuation

---

## üìä M√©triques de Succ√®s

### Phase A
- Signaux LLM identifi√©s et exploitables
- Impact mesurable sur le scoring
- Workflow pr√©serv√©

### Phase B
- Prompt LLM-matching fonctionnel
- Matching hybride √©quilibr√©
- Performance acceptable

### Phase C
- Am√©lioration qualit√© mesur√©e
- Co√ªt acceptable
- Architecture stable

### Global
- Matching/scoring hybride fonctionnel en DEV pour `lai_weekly_v3`
- Prompt clairement d√©fini dans canonical
- M√©triques r√©elles impact qualit√©/co√ªt
- Recommandations pour la suite