# Plan Test E2E v15 - Validation Canonical v2.2 avec Donn√©es Fra√Æches

**Date**: 2026-02-03  
**Client**: lai_weekly_v15  
**Canonical**: v2.2  
**Objectif**: Valider am√©liorations plan v2.2 avec donn√©es fra√Æches et analyse item par item  
**Dur√©e estim√©e**: 2-3 heures

---

## üéØ OBJECTIFS DU TEST

### Objectif Principal

**Valider que le plan d'am√©lioration canonical v2.2 a am√©lior√© le moteur Vectora-Inbox**

### Objectifs Sp√©cifiques

1. **Tester avec donn√©es fra√Æches** (ingestion nouvelle)
2. **Analyser item par item** le workflow complet:
   - Pourquoi ing√©r√©?
   - Comment normalis√©?
   - Comment scor√©?
   - Pourquoi match√©/rejet√©?
3. **Identifier faux positifs/n√©gatifs** pour affiner canonical
4. **Fournir retour admin d√©taill√©** pour it√©ration suivante
5. **Mesurer am√©lioration vs v13/v14**

---

## üìã PR√â-REQUIS (10 min)

### Checklist Technique

- [ ] Token SSO valide: `aws sso login --profile rag-lai-prod`
- [ ] Canonical v2.2 d√©ploy√© sur dev (v√©rifi√© pr√©c√©demment ‚úÖ)
- [ ] Lambdas op√©rationnelles
- [ ] Python 3.11+ disponible
- [ ] Espace disque: ~100 MB pour donn√©es

### V√©rifications Pr√©alables

```bash
# 1. V√©rifier token SSO
aws sts get-caller-identity --profile rag-lai-prod

# 2. V√©rifier canonical v2.2 sur S3
aws s3 ls s3://vectora-inbox-config-dev/canonical/domains/ --profile rag-lai-prod --region eu-west-3

# 3. V√©rifier lambdas
aws lambda list-functions --region eu-west-3 --profile rag-lai-prod | findstr vectora-inbox

# 4. Cr√©er dossier temporaire
mkdir .tmp\e2e_v15
```

---

## üîÑ WORKFLOW COMPLET (2-3h)

### PHASE 1: Pr√©paration Client v15 (15 min)

#### √âtape 1.1: Cr√©er Config Client

```bash
# Copier base v14
cp client-config-examples/production/lai_weekly_v14.yaml \
   client-config-examples/production/lai_weekly_v15.yaml
```

**Modifications requises**:
```yaml
client_profile:
  name: "LAI Intelligence Weekly v15 (Test E2E Canonical v2.2 - Donn√©es Fra√Æches)"
  client_id: "lai_weekly_v15"

metadata:
  template_version: "15.0.0"
  created_date: "2026-02-03"
  canonical_version: "2.2"
  created_by: "Test E2E - Validation Canonical v2.2 avec donn√©es fra√Æches"
  
  creation_notes: |
    Test E2E v15 avec donn√©es fra√Æches pour valider:
    - Am√©lioration ingestion (max_content_length 2000)
    - D√©tection dosing_intervals
    - Exclusions corporate_move/manufacturing/financial
    - Hybrid_company boost conditionnel
    - CRITICAL RULES anti-hallucination
```

#### √âtape 1.2: Upload Config

```bash
# Upload vers S3 dev
aws s3 cp client-config-examples/production/lai_weekly_v15.yaml \
  s3://vectora-inbox-config-dev/clients/lai_weekly_v15.yaml \
  --profile rag-lai-prod --region eu-west-3

# V√©rifier
aws s3 ls s3://vectora-inbox-config-dev/clients/ --profile rag-lai-prod --region eu-west-3 | findstr lai_weekly_v15
```

**Validation**: ‚úÖ Fichier pr√©sent sur S3

---

### PHASE 2: Ingestion (30 min)

#### √âtape 2.1: Lancer Ingestion

```bash
# Cr√©er payload
echo {"client_id": "lai_weekly_v15"} > .tmp/e2e_v15/payload.json

# Invoquer lambda ingest
aws lambda invoke \
  --function-name vectora-inbox-ingest-v2-dev \
  --payload file://.tmp/e2e_v15/payload.json \
  --region eu-west-3 \
  --profile rag-lai-prod \
  .tmp/e2e_v15/ingest_response.json

# Lire r√©ponse
type .tmp\e2e_v15\ingest_response.json
```

**Validation**:
- StatusCode: 200 ‚úÖ
- Items ing√©r√©s: > 20 ‚úÖ

#### √âtape 2.2: T√©l√©charger Items Ing√©r√©s

```bash
# Trouver le chemin exact (date du jour)
aws s3 ls s3://vectora-inbox-data-dev/ingested/lai_weekly_v15/ \
  --recursive --profile rag-lai-prod --region eu-west-3

# T√©l√©charger (adapter date)
aws s3 cp s3://vectora-inbox-data-dev/ingested/lai_weekly_v15/2026/02/03/items.json \
  .tmp/e2e_v15/items_ingested.json \
  --profile rag-lai-prod --region eu-west-3
```

#### √âtape 2.3: Analyser Items Ing√©r√©s

```bash
# Statistiques globales
python -c "import json; items=json.load(open('.tmp/e2e_v15/items_ingested.json', encoding='utf-8')); print(f'Total items ing√©r√©s: {len(items)}'); sources={}; [sources.update({item.get('source_key', 'unknown'): sources.get(item.get('source_key', 'unknown'), 0) + 1}) for item in items]; print('\nR√©partition par source:'); [print(f'  {k}: {v}') for k,v in sorted(sources.items(), key=lambda x: -x[1])]"

# Sauvegarder liste items pour analyse
python -c "import json; items=json.load(open('.tmp/e2e_v15/items_ingested.json', encoding='utf-8')); with open('.tmp/e2e_v15/items_list.txt', 'w', encoding='utf-8') as f: [f.write(f'{i+1}. {item.get(\"title\", \"NO TITLE\")[:100]}... ({item.get(\"source_key\", \"unknown\")})\n') for i, item in enumerate(items)]"

# Afficher liste
type .tmp\e2e_v15\items_list.txt
```

**üìù ANALYSE ADMIN - Ingestion**:

Pour chaque source, noter:
- ‚úÖ / ‚ùå Source pertinente pour LAI?
- ‚úÖ / ‚ùå Items ing√©r√©s de qualit√©?
- ‚úÖ / ‚ùå Filtrage ingestion efficace?

**Observations**:
```
Source 1 (press_corporate__medincell): X items
- Qualit√©: ‚úÖ / ‚ö†Ô∏è / ‚ùå
- Commentaire: [...]

Source 2 (press_sector__fiercebiotech): X items
- Qualit√©: ‚úÖ / ‚ö†Ô∏è / ‚ùå
- Commentaire: [...]

[etc.]
```

---

### PHASE 3: Normalisation & Scoring (60-90 min)

#### √âtape 3.1: Lancer Normalisation

```bash
# Invoquer lambda (ASYNCHRONE - 5-10 min)
aws lambda invoke \
  --function-name vectora-inbox-normalize-score-v2-dev \
  --invocation-type Event \
  --payload file://.tmp/e2e_v15/payload.json \
  --region eu-west-3 \
  --profile rag-lai-prod \
  .tmp/e2e_v15/normalize_response.json

# V√©rifier acceptation
type .tmp\e2e_v15\normalize_response.json
```

**Validation**: StatusCode 202 (asynchrone accept√©) ‚úÖ

#### √âtape 3.2: Attendre et V√©rifier

```bash
# Attendre 10 minutes
echo Attente 10 minutes pour normalisation...
timeout /t 600

# V√©rifier pr√©sence fichier
aws s3 ls s3://vectora-inbox-data-dev/curated/lai_weekly_v15/ \
  --recursive --profile rag-lai-prod --region eu-west-3
```

#### √âtape 3.3: T√©l√©charger Items Normalis√©s

```bash
# T√©l√©charger (adapter date)
aws s3 cp s3://vectora-inbox-data-dev/curated/lai_weekly_v15/2026/02/03/items.json \
  .tmp/e2e_v15/items_normalized.json \
  --profile rag-lai-prod --region eu-west-3
```

#### √âtape 3.4: Analyser Statistiques Globales

```bash
# Statistiques normalization
python -c "import json; items=json.load(open('.tmp/e2e_v15/items_normalized.json', encoding='utf-8')); print(f'Total items: {len(items)}'); relevant=[i for i in items if i.get('domain_scoring', {}).get('is_relevant')]; print(f'Items relevant: {len(relevant)} ({len(relevant)/len(items)*100:.1f}%%)'); scores=[i['domain_scoring']['score'] for i in relevant]; print(f'Score moyen: {sum(scores)/len(scores) if scores else 0:.1f}'); print(f'Score min: {min(scores) if scores else 0}'); print(f'Score max: {max(scores) if scores else 0}')"

# R√©partition scores
python -c "import json; items=json.load(open('.tmp/e2e_v15/items_normalized.json', encoding='utf-8')); relevant=[i for i in items if i.get('domain_scoring', {}).get('is_relevant')]; high=sum(1 for i in relevant if i['domain_scoring']['score']>=70); med=sum(1 for i in relevant if 40<=i['domain_scoring']['score']<70); low=sum(1 for i in relevant if i['domain_scoring']['score']<40); print(f'Scores √©lev√©s (‚â•70): {high}'); print(f'Scores moyens (40-69): {med}'); print(f'Scores bas (<40): {low}')"
```

#### √âtape 3.5: Analyser Item par Item (CRITIQUE)

**Cr√©er fichier d'analyse d√©taill√©e**:

```bash
# G√©n√©rer rapport item par item
python scripts/analyze/analyze_items_detailed.py \
  --input .tmp/e2e_v15/items_normalized.json \
  --output .tmp/e2e_v15/items_analysis.md
```

**OU manuellement** (si script n'existe pas):

```python
import json

items = json.load(open('.tmp/e2e_v15/items_normalized.json', encoding='utf-8'))

with open('.tmp/e2e_v15/items_analysis.md', 'w', encoding='utf-8') as f:
    f.write("# Analyse D√©taill√©e Items v15\n\n")
    
    # Items relevant
    relevant = [i for i in items if i.get('domain_scoring', {}).get('is_relevant')]
    f.write(f"## Items Relevant ({len(relevant)})\n\n")
    
    for idx, item in enumerate(sorted(relevant, key=lambda x: x['domain_scoring']['score'], reverse=True), 1):
        ds = item.get('domain_scoring', {})
        f.write(f"### Item {idx}/{len(relevant)}: {item.get('title', 'NO TITLE')[:80]}...\n\n")
        f.write(f"- **Source**: {item.get('source_key', 'unknown')}\n")
        f.write(f"- **Event type**: {item.get('normalized_content', {}).get('event_type', 'unknown')}\n")
        f.write(f"- **Score**: {ds.get('score', 0)}/100\n")
        f.write(f"- **Confidence**: {ds.get('confidence', 'unknown')}\n\n")
        
        # Entit√©s
        entities = item.get('normalized_content', {}).get('entities', {})
        f.write(f"**Entit√©s d√©tect√©es**:\n")
        f.write(f"- Companies: {entities.get('companies', [])}\n")
        f.write(f"- Molecules: {entities.get('molecules', [])}\n")
        f.write(f"- Technologies: {entities.get('technologies', [])}\n")
        f.write(f"- Trademarks: {entities.get('trademarks', [])}\n")
        f.write(f"- Dosing intervals: {item.get('normalized_content', {}).get('dosing_intervals_detected', [])}\n\n")
        
        # Signaux
        signals = ds.get('signals_detected', {})
        f.write(f"**Signaux LAI**:\n")
        f.write(f"- Strong: {signals.get('strong', [])}\n")
        f.write(f"- Medium: {signals.get('medium', [])}\n")
        f.write(f"- Weak: {signals.get('weak', [])}\n\n")
        
        # Reasoning
        f.write(f"**Reasoning**: {ds.get('reasoning', 'N/A')}\n\n")
        
        # Template pour retour admin
        f.write(f"**üìù RETOUR ADMIN**:\n")
        f.write(f"- Devrait matcher? ‚úÖ OUI / ‚ùå NON\n")
        f.write(f"- Score coh√©rent? ‚úÖ OUI / ‚ùå NON\n")
        f.write(f"- Signaux corrects? ‚úÖ OUI / ‚ùå NON\n")
        f.write(f"- Commentaire: [...]\n\n")
        f.write("---\n\n")
    
    # Items non relevant
    non_relevant = [i for i in items if not i.get('domain_scoring', {}).get('is_relevant')]
    f.write(f"## Items Non Relevant ({len(non_relevant)})\n\n")
    
    for idx, item in enumerate(non_relevant[:10], 1):  # Top 10 seulement
        ds = item.get('domain_scoring', {})
        f.write(f"### Item {idx}/10: {item.get('title', 'NO TITLE')[:80]}...\n\n")
        f.write(f"- **Source**: {item.get('source_key', 'unknown')}\n")
        f.write(f"- **Event type**: {item.get('normalized_content', {}).get('event_type', 'unknown')}\n")
        f.write(f"- **Score**: {ds.get('score', 0)}\n")
        f.write(f"- **Reasoning**: {ds.get('reasoning', 'N/A')}\n\n")
        
        f.write(f"**üìù RETOUR ADMIN**:\n")
        f.write(f"- Rejet justifi√©? ‚úÖ OUI / ‚ùå NON (devrait matcher)\n")
        f.write(f"- Commentaire: [...]\n\n")
        f.write("---\n\n")

print("Analyse g√©n√©r√©e: .tmp/e2e_v15/items_analysis.md")
```

**Ex√©cuter**:
```bash
python .tmp\e2e_v15\generate_analysis.py
```

#### √âtape 3.6: Remplir Retours Admin

**Ouvrir fichier**: `.tmp/e2e_v15/items_analysis.md`

**Pour CHAQUE item relevant**, remplir:
- ‚úÖ / ‚ùå Devrait matcher?
- ‚úÖ / ‚ùå Score coh√©rent?
- ‚úÖ / ‚ùå Signaux corrects?
- Commentaire d√©taill√©

**Pour items non relevant (√©chantillon)**, remplir:
- ‚úÖ / ‚ùå Rejet justifi√©?
- Commentaire si faux n√©gatif

---

### PHASE 4: Newsletter (15 min)

#### √âtape 4.1: G√©n√©rer Newsletter

```bash
# Invoquer lambda
aws lambda invoke \
  --function-name vectora-inbox-newsletter-v2-dev \
  --payload file://.tmp/e2e_v15/payload.json \
  --region eu-west-3 \
  --profile rag-lai-prod \
  .tmp/e2e_v15/newsletter_response.json

# T√©l√©charger newsletter
aws s3 cp s3://vectora-inbox-newsletters-dev/lai_weekly_v15/2026/02/03/newsletter.md \
  .tmp/e2e_v15/newsletter.md \
  --profile rag-lai-prod --region eu-west-3

# Afficher
type .tmp\e2e_v15\newsletter.md
```

#### √âtape 4.2: √âvaluer Newsletter

**Checklist**:
- [ ] Items s√©lectionn√©s: 10-20
- [ ] Sections remplies: 4/4
- [ ] TLDR pr√©sent et pertinent
- [ ] Intro coh√©rente
- [ ] Items bien r√©partis par section
- [ ] Pas de doublons
- [ ] Qualit√© r√©dactionnelle

**üìù RETOUR ADMIN - Newsletter**:
```
Qualit√© globale: ‚úÖ Excellente / ‚ö†Ô∏è Acceptable / ‚ùå Insuffisante

Points forts:
- [...]

Points d'am√©lioration:
- [...]
```

---

### PHASE 5: Comparaison v13/v14/v15 (30 min)

#### √âtape 5.1: Compiler M√©triques

| M√©trique | V13 | V14 | V15 | √âvolution |
|----------|-----|-----|-----|-----------|
| **Items ing√©r√©s** | 29 | 29 | ? | ? |
| **Items relevant** | 14 (48%) | 12 (41%) | ? | ? |
| **Score moyen** | 38.3 | 80.0 | ? | ? |
| **Faux positifs** | 5 (36%) | 0 (0%) | ? | ? |
| **Faux n√©gatifs** | 1 (7%) | 1 (6%) | ? | ? |
| **Companies d√©tect√©es** | Oui | Non ‚ùå | ? | ? |
| **Dosing intervals d√©tect√©s** | Non | Oui ‚úÖ | ? | ? |

#### √âtape 5.2: Identifier Am√©liorations/R√©gressions

**Am√©liorations v15 vs v14**:
1. [...]
2. [...]

**R√©gressions v15 vs v14**:
1. [...]
2. [...]

**Probl√®mes persistants**:
1. [...]
2. [...]

---

## üìä RAPPORT FINAL (30 min)

### Structure Rapport

**Fichier**: `docs/reports/e2e/test_e2e_v15_rapport_complet_2026-02-03.md`

```markdown
# Rapport Test E2E v15 - Validation Canonical v2.2

**Date**: 2026-02-03
**Client**: lai_weekly_v15
**Canonical**: v2.2
**Type donn√©es**: Fra√Æches (ingestion nouvelle)

## üìä R√©sultats Globaux

| M√©trique | Valeur | Cible | Statut |
|----------|--------|-------|--------|
| Items ing√©r√©s | X | >20 | ‚úÖ/‚ùå |
| Items relevant | X (Y%) | >50% | ‚úÖ/‚ùå |
| Score moyen | X | 30-70 | ‚úÖ/‚ùå |
| Faux positifs | X | 0 | ‚úÖ/‚ùå |
| Faux n√©gatifs | X | 0 | ‚úÖ/‚ùå |

## üéØ Validation Objectifs Plan v2.2

### Objectif 1: Exclusion Corporate Move Sans Tech
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

### Objectif 2: Exclusion Manufacturing Sans Tech
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

### Objectif 3: D√©tection Dosing Intervals
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

### Objectif 4: Exclusion Financial Results
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

### Objectif 5: Anti-Hallucination
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

### Objectif 6: Hybrid Company Boost Conditionnel
**Statut**: ‚úÖ / ‚ö†Ô∏è / ‚ùå
**Preuve**: [...]

## üìù Retours Admin D√©taill√©s

[Copier depuis items_analysis.md]

## üîß Recommandations Am√©lioration

### Priorit√© 1 (Critique)
1. [...]

### Priorit√© 2 (Important)
1. [...]

### Priorit√© 3 (Nice to Have)
1. [...]

## üéØ Verdict Final

**Statut**: ‚úÖ SUCC√àS / ‚ö†Ô∏è SUCC√àS PARTIEL / ‚ùå √âCHEC

**Justification**: [...]

**Prochaines √©tapes**: [...]
```

---

## ‚úÖ CHECKLIST FINALE

### Validation Technique

- [ ] Toutes les phases ex√©cut√©es sans erreur
- [ ] Tous les fichiers t√©l√©charg√©s depuis S3
- [ ] Analyses g√©n√©r√©es et compl√®tes
- [ ] M√©triques calcul√©es
- [ ] Comparaison v13/v14/v15 faite

### Validation Qualit√©

- [ ] Tous les items relevant analys√©s
- [ ] √âchantillon items non relevant analys√©
- [ ] Faux positifs identifi√©s
- [ ] Faux n√©gatifs identifi√©s
- [ ] Retours admin remplis pour chaque item

### Livrables

- [ ] Rapport complet g√©n√©r√©
- [ ] Fichier items_analysis.md compl√©t√©
- [ ] Recommandations formul√©es
- [ ] Verdict final document√©

---

## üéØ CRIT√àRES DE SUCC√àS

### Succ√®s Complet ‚úÖ

- Items relevant: ‚â•50%
- Faux positifs: 0
- Faux n√©gatifs: ‚â§1
- Companies d√©tect√©es: >0
- Dosing intervals d√©tect√©s: >0
- Tous les objectifs plan v2.2 valid√©s

### Succ√®s Partiel ‚ö†Ô∏è

- Items relevant: 40-49%
- Faux positifs: 1-2
- Faux n√©gatifs: 2-3
- 4-5 objectifs plan v2.2 valid√©s

### √âchec ‚ùå

- Items relevant: <40%
- Faux positifs: >2
- Faux n√©gatifs: >3
- <4 objectifs plan v2.2 valid√©s

---

## üìù NOTES IMPORTANTES

1. **Donn√©es fra√Æches**: Ce test utilise une nouvelle ingestion, pas les donn√©es v13/v14
2. **Analyse item par item**: Critique pour identifier patterns et affiner canonical
3. **Retours admin d√©taill√©s**: Permettent it√©ration rapide sur canonical
4. **Comparaison versions**: Mesure progr√®s r√©el du moteur
5. **Temps requis**: 2-3h pour analyse compl√®te et qualitative

---

**Plan cr√©√©**: 2026-02-03  
**Dur√©e estim√©e**: 2-3 heures  
**Statut**: ‚è≥ PR√äT POUR EX√âCUTION
