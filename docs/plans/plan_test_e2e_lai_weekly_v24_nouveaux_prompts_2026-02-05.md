# Plan Test E2E - lai_weekly_v24 - Nouveaux Prompts Normalization & Domain Scoring

**Date**: 2026-02-05  
**Objectif**: Tester E2E complet avec les nouveaux prompts amÃ©liorÃ©s (normalization v2.0 + domain scoring v5.0)  
**Client**: lai_weekly_v24 (nouveau, copie de v23)  
**Environnement**: dev

---

## ğŸ¯ OBJECTIFS

1. **Valider les nouveaux prompts**:
   - `generic_normalization.yaml` v2.0 (summary 10-15 lignes + routes d'administration)
   - `lai_domain_scoring.yaml` v5.0 (dÃ©finition LAI riche + Ã©valuation naturelle)

2. **Tester avec donnÃ©es fraÃ®ches**: Ingestion de nouvelles news (30 derniers jours)

3. **GÃ©nÃ©rer rapport E2E complet**: Format `test-e2e-gold-standard.md`

4. **Garantir utilisation des nouveaux prompts**: Nettoyage S3 avant dÃ©ploiement

---

## ğŸ“‹ PLAN D'EXÃ‰CUTION

### PHASE 0: PrÃ©paration Client v24

**Objectif**: CrÃ©er lai_weekly_v24 comme copie exacte de v23

**Actions**:
```bash
# 1. Copier config v23 â†’ v24
cp client-config-examples/production/lai_weekly_v23.yaml \
   client-config-examples/production/lai_weekly_v24.yaml

# 2. Ã‰diter lai_weekly_v24.yaml
# - Remplacer "v23" par "v24" partout
# - Mettre Ã  jour metadata.created_date: "2026-02-05"
# - Mettre Ã  jour metadata.created_by: "Test E2E V24 - Nouveaux prompts normalization + domain scoring"
# - Mettre Ã  jour metadata.creation_notes avec description des nouveaux prompts
```

**Validation**:
- [ ] Fichier `lai_weekly_v24.yaml` crÃ©Ã©
- [ ] Tous les champs mis Ã  jour (client_id, name, metadata)
- [ ] Config identique Ã  v23 sauf version

**DurÃ©e estimÃ©e**: 5 min

---

### PHASE 1: Nettoyage S3 Prompts

**Objectif**: Supprimer les anciens prompts sur S3 pour forcer l'utilisation des nouveaux

**Actions**:
```bash
# 1. Lister les prompts actuels sur S3
aws s3 ls s3://rag-lai-canonical-dev/prompts/normalization/ --profile rag-lai-prod
aws s3 ls s3://rag-lai-canonical-dev/prompts/domain_scoring/ --profile rag-lai-prod

# 2. Supprimer les anciens prompts
aws s3 rm s3://rag-lai-canonical-dev/prompts/normalization/generic_normalization.yaml --profile rag-lai-prod
aws s3 rm s3://rag-lai-canonical-dev/prompts/domain_scoring/lai_domain_scoring.yaml --profile rag-lai-prod

# 3. VÃ©rifier suppression
aws s3 ls s3://rag-lai-canonical-dev/prompts/normalization/ --profile rag-lai-prod
aws s3 ls s3://rag-lai-canonical-dev/prompts/domain_scoring/ --profile rag-lai-prod
```

**Validation**:
- [ ] Anciens prompts supprimÃ©s de S3
- [ ] Buckets prompts vides ou ne contenant que d'autres fichiers

**DurÃ©e estimÃ©e**: 5 min

---

### PHASE 2: Upload Nouveaux Prompts

**Objectif**: Uploader les nouveaux prompts sur S3 dev

**Actions**:
```bash
# 1. Upload nouveau prompt normalization
aws s3 cp canonical/prompts/normalization/generic_normalization.yaml \
  s3://rag-lai-canonical-dev/prompts/normalization/generic_normalization.yaml \
  --profile rag-lai-prod

# 2. Upload nouveau prompt domain scoring
aws s3 cp canonical/prompts/domain_scoring/lai_domain_scoring.yaml \
  s3://rag-lai-canonical-dev/prompts/domain_scoring/lai_domain_scoring.yaml \
  --profile rag-lai-prod

# 3. VÃ©rifier upload
aws s3 ls s3://rag-lai-canonical-dev/prompts/normalization/ --profile rag-lai-prod
aws s3 ls s3://rag-lai-canonical-dev/prompts/domain_scoring/ --profile rag-lai-prod

# 4. TÃ©lÃ©charger et vÃ©rifier contenu
aws s3 cp s3://rag-lai-canonical-dev/prompts/normalization/generic_normalization.yaml \
  .tmp/verify_normalization.yaml --profile rag-lai-prod
aws s3 cp s3://rag-lai-canonical-dev/prompts/domain_scoring/lai_domain_scoring.yaml \
  .tmp/verify_domain_scoring.yaml --profile rag-lai-prod

# 5. Comparer avec fichiers locaux
diff canonical/prompts/normalization/generic_normalization.yaml .tmp/verify_normalization.yaml
diff canonical/prompts/domain_scoring/lai_domain_scoring.yaml .tmp/verify_domain_scoring.yaml
```

**Validation**:
- [ ] Nouveaux prompts uploadÃ©s sur S3
- [ ] Contenu vÃ©rifiÃ© (diff = 0 diffÃ©rences)
- [ ] Versions correctes (v2.0 normalization, v5.0 domain scoring)

**DurÃ©e estimÃ©e**: 10 min

---

### PHASE 3: Upload Config Client v24

**Objectif**: Uploader la config lai_weekly_v24 sur S3 dev

**Actions**:
```bash
# 1. Upload config client
aws s3 cp client-config-examples/production/lai_weekly_v24.yaml \
  s3://rag-lai-canonical-dev/clients/lai_weekly_v24.yaml \
  --profile rag-lai-prod

# 2. VÃ©rifier upload
aws s3 ls s3://rag-lai-canonical-dev/clients/ --profile rag-lai-prod | grep v24

# 3. TÃ©lÃ©charger et vÃ©rifier
aws s3 cp s3://rag-lai-canonical-dev/clients/lai_weekly_v24.yaml \
  .tmp/verify_client_v24.yaml --profile rag-lai-prod

diff client-config-examples/production/lai_weekly_v24.yaml .tmp/verify_client_v24.yaml
```

**Validation**:
- [ ] Config lai_weekly_v24.yaml uploadÃ©e sur S3
- [ ] Contenu vÃ©rifiÃ© (diff = 0)

**DurÃ©e estimÃ©e**: 5 min

---

### PHASE 4: Lancement Run E2E

**Objectif**: Lancer le workflow complet ingest â†’ normalize-score â†’ newsletter

**Actions**:
```bash
# 1. Lancer ingest-v2 (donnÃ©es fraÃ®ches 30 derniers jours)
python scripts/invoke/invoke_ingest_v2.py \
  --client-id lai_weekly_v24 \
  --env dev \
  --period-days 30

# 2. Attendre fin ingest (vÃ©rifier CloudWatch logs)
# Lambda: rag-lai-ingest-v2-dev
# Chercher: "Ingest completed" ou "ERROR"

# 3. Lancer normalize-score-v2
python scripts/invoke/invoke_normalize_score_v2.py \
  --client-id lai_weekly_v24 \
  --env dev

# 4. Attendre fin normalize-score (vÃ©rifier CloudWatch logs)
# Lambda: rag-lai-normalize-score-v2-dev
# Chercher: "Normalize-score completed" ou "ERROR"

# 5. Lancer newsletter-v2
python scripts/invoke/invoke_newsletter_v2.py \
  --client-id lai_weekly_v24 \
  --env dev

# 6. Attendre fin newsletter (vÃ©rifier CloudWatch logs)
# Lambda: rag-lai-newsletter-v2-dev
# Chercher: "Newsletter completed" ou "ERROR"
```

**Validation**:
- [ ] Ingest-v2 terminÃ© avec succÃ¨s
- [ ] Normalize-score-v2 terminÃ© avec succÃ¨s
- [ ] Newsletter-v2 terminÃ© avec succÃ¨s
- [ ] Aucune erreur dans CloudWatch logs

**DurÃ©e estimÃ©e**: 10-15 min (selon volume items)

---

### PHASE 5: RÃ©cupÃ©ration DonnÃ©es S3

**Objectif**: TÃ©lÃ©charger les rÃ©sultats du run pour analyse

**Actions**:
```bash
# 1. CrÃ©er dossier local pour v24
mkdir -p .tmp/e2e/lai_weekly_v24

# 2. TÃ©lÃ©charger items ingÃ©rÃ©s
aws s3 cp s3://rag-lai-data-dev/clients/lai_weekly_v24/ingested/ \
  .tmp/e2e/lai_weekly_v24/ingested/ --recursive --profile rag-lai-prod

# 3. TÃ©lÃ©charger items normalisÃ©s
aws s3 cp s3://rag-lai-data-dev/clients/lai_weekly_v24/normalized/ \
  .tmp/e2e/lai_weekly_v24/normalized/ --recursive --profile rag-lai-prod

# 4. TÃ©lÃ©charger items curated
aws s3 cp s3://rag-lai-data-dev/clients/lai_weekly_v24/curated/ \
  .tmp/e2e/lai_weekly_v24/curated/ --recursive --profile rag-lai-prod

# 5. TÃ©lÃ©charger newsletter
aws s3 cp s3://rag-lai-data-dev/clients/lai_weekly_v24/newsletters/ \
  .tmp/e2e/lai_weekly_v24/newsletters/ --recursive --profile rag-lai-prod

# 6. Identifier le dernier run (timestamp le plus rÃ©cent)
ls -lt .tmp/e2e/lai_weekly_v24/curated/
```

**Validation**:
- [ ] Fichiers ingested tÃ©lÃ©chargÃ©s
- [ ] Fichiers normalized tÃ©lÃ©chargÃ©s
- [ ] Fichiers curated tÃ©lÃ©chargÃ©s
- [ ] Newsletter tÃ©lÃ©chargÃ©e
- [ ] Dernier run identifiÃ©

**DurÃ©e estimÃ©e**: 5 min

---

### PHASE 6: GÃ©nÃ©ration Rapport E2E

**Objectif**: GÃ©nÃ©rer rapport complet format `test-e2e-gold-standard.md`

**Actions**:
```bash
# 1. Identifier fichier curated du dernier run
CURATED_FILE=".tmp/e2e/lai_weekly_v24/curated/curated_items_YYYYMMDD_HHMMSS.json"

# 2. GÃ©nÃ©rer rapport E2E avec Q Developer
# Prompt:
# "GÃ©nÃ¨re un rapport E2E complet pour lai_weekly_v24 en utilisant le format exact 
# de test-e2e-gold-standard.md. DonnÃ©es source: $CURATED_FILE
# 
# Le rapport doit inclure:
# - MÃ©triques de performance (temps, throughput)
# - MÃ©triques Bedrock (appels, tokens, coÃ»ts)
# - VolumÃ©trie dÃ©taillÃ©e
# - Projections coÃ»ts
# - KPIs pilotage
# - DÃ©tail de tous les items pertinents (avec summary complet, routes d'administration)
# - RÃ©sumÃ© des items non-pertinents
# - Analyse par catÃ©gorie
# 
# Utilise les mÃªmes sections, emojis, et structure que le golden standard."

# 3. Sauvegarder rapport
# Fichier: docs/reports/e2e/test_e2e_lai_weekly_v24_rapport_detaille_2026-02-05.md
```

**Validation**:
- [ ] Rapport gÃ©nÃ©rÃ© avec toutes les sections
- [ ] Format identique Ã  test-e2e-gold-standard.md
- [ ] MÃ©triques calculÃ©es (performance, Bedrock, coÃ»ts)
- [ ] Tous les items pertinents dÃ©taillÃ©s
- [ ] Items non-pertinents rÃ©sumÃ©s
- [ ] Analyse par catÃ©gorie prÃ©sente

**DurÃ©e estimÃ©e**: 20-30 min

---

### PHASE 7: Analyse Qualitative

**Objectif**: Valider la qualitÃ© des nouveaux prompts

**CritÃ¨res d'Ã©valuation**:

1. **Summary (normalization)**:
   - [ ] Longueur: 10-15 lignes minimum
   - [ ] Contenu: DÃ©taillÃ©, capture toutes les infos clÃ©s
   - [ ] Structure: Companies + Action + Technical details + Context
   - [ ] Routes d'administration: Extraites quand prÃ©sentes

2. **Domain Scoring**:
   - [ ] Taux pertinence: 50-70% attendu
   - [ ] Score moyen: 65-75 attendu
   - [ ] Reasoning: Clair, mentionne indicateurs LAI
   - [ ] Pas d'hallucination: Pas de catÃ©gories inventÃ©es
   - [ ] Trademarks LAI: Reconnus mÃªme sans autres mots-clÃ©s

3. **Comparaison v23 vs v24**:
   - [ ] Summary plus riches en v24
   - [ ] Routes d'administration prÃ©sentes en v24
   - [ ] Scoring plus cohÃ©rent en v24
   - [ ] Moins d'hallucinations en v24

**Actions**:
```bash
# 1. Comparer quelques items v23 vs v24
# SÃ©lectionner 5-10 items communs et comparer:
# - Longueur summary
# - Richesse informations
# - PrÃ©sence routes d'administration
# - CohÃ©rence scoring

# 2. VÃ©rifier cas edge:
# - "UZEDY strong sales" â†’ Doit Ãªtre dÃ©tectÃ© (trademark seul)
# - News avec dosing + route mais pas de trademark â†’ Doit scorer correctement
# - News avec technologies DDS/HLE â†’ Doit Ãªtre pertinent

# 3. Documenter observations dans rapport
```

**Validation**:
- [ ] Summary significativement plus riches
- [ ] Routes d'administration extraites
- [ ] Scoring cohÃ©rent et sans hallucination
- [ ] Cas edge validÃ©s

**DurÃ©e estimÃ©e**: 30 min

---

## ğŸ“Š LIVRABLES ATTENDUS

1. **Config client**: `client-config-examples/production/lai_weekly_v24.yaml`
2. **Rapport E2E**: `docs/reports/e2e/test_e2e_lai_weekly_v24_rapport_detaille_2026-02-05.md`
3. **DonnÃ©es run**: `.tmp/e2e/lai_weekly_v24/` (ingested, normalized, curated, newsletter)
4. **Analyse comparative**: Section dans rapport E2E comparant v23 vs v24

---

## âœ… CRITÃˆRES DE SUCCÃˆS

### CritÃ¨res techniques
- [ ] Run E2E complet sans erreur
- [ ] Nouveaux prompts utilisÃ©s (vÃ©rifiÃ© via S3)
- [ ] DonnÃ©es fraÃ®ches ingÃ©rÃ©es (30 derniers jours)

### CritÃ¨res qualitÃ©
- [ ] Summary 10-15 lignes minimum (vs 2-3 en v23)
- [ ] Routes d'administration extraites
- [ ] Taux pertinence 50-70%
- [ ] Score moyen 65-75
- [ ] Reasoning clair sans hallucination
- [ ] Trademarks LAI reconnus seuls

### CritÃ¨res documentation
- [ ] Rapport E2E complet format gold standard
- [ ] Analyse comparative v23 vs v24
- [ ] Recommandations pour amÃ©lioration continue

---

## ğŸš¨ POINTS D'ATTENTION

1. **Nettoyage S3**: CRITIQUE - Sans Ã§a, anciens prompts seront utilisÃ©s
2. **VÃ©rification upload**: Toujours diff local vs S3 pour confirmer
3. **CloudWatch logs**: Surveiller pour dÃ©tecter erreurs rapidement
4. **Volume items**: Si >50 items, temps normalize-score peut Ãªtre long (3-5 min/item)
5. **CoÃ»ts Bedrock**: Avec summary plus longs, tokens output augmentent (~30-40%)

---

## ğŸ“… TIMELINE ESTIMÃ‰E

| Phase | DurÃ©e | Cumul |
|-------|-------|-------|
| Phase 0: PrÃ©paration v24 | 5 min | 5 min |
| Phase 1: Nettoyage S3 | 5 min | 10 min |
| Phase 2: Upload prompts | 10 min | 20 min |
| Phase 3: Upload config | 5 min | 25 min |
| Phase 4: Run E2E | 15 min | 40 min |
| Phase 5: RÃ©cupÃ©ration S3 | 5 min | 45 min |
| Phase 6: GÃ©nÃ©ration rapport | 30 min | 75 min |
| Phase 7: Analyse qualitative | 30 min | 105 min |

**Total estimÃ©**: ~2 heures

---

## ğŸ”„ PROCHAINES Ã‰TAPES (POST-TEST)

Si test v24 rÃ©ussi:
1. Promouvoir prompts vers stage
2. Tester sur stage avec lai_weekly_v24
3. Valider avec donnÃ©es production
4. DÃ©ployer en prod si validÃ©

Si test v24 Ã©choue:
1. Analyser logs CloudWatch
2. Identifier problÃ¨me (prompt, config, Lambda)
3. Corriger et relancer
4. Documenter learnings

---

**PrÃªt pour exÃ©cution** âœ…
