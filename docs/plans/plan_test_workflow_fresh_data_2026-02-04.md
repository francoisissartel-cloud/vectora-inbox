# Plan Test Workflow Fresh Data - Vectora Inbox

**Date**: 2026-02-04  
**Objectif**: Valider workflow complet `ingest-v2 ‚Üí normalize-score-v2 ‚Üí newsletter-v2` en dev avec donn√©es RSS fra√Æches  
**Dur√©e estim√©e**: 40-45 minutes  
**Environnement**: dev  

---

## üéØ OBJECTIF

Valider le workflow complet avec des donn√©es RSS fra√Æches du jour pour confirmer que le syst√®me fonctionne correctement en conditions r√©elles.

---

## üìä BASELINE DE R√âF√âRENCE (V17)

| M√©trique | Valeur V17 | Seuil Min | Seuil Max |
|----------|------------|-----------|-----------|
| Items ing√©r√©s | 31 | 25 | 40 |
| Companies d√©tect√©es | 74% | 70% | 100% |
| Items relevant | 64% | 60% | 80% |
| Score moyen | 71.5 | 65 | 85 |
| Faux n√©gatifs | 0 | 0 | 1 |
| Domain scoring | 100% | 100% | 100% |

**Source**: `.q-context/GOLDEN_TEST_E2E.md`

---

## üìã √âTAPES DU PLAN

### √âTAPE 1: PR√âPARATION (5 min)

**Actions**:
- V√©rifier environnement AWS
- Cr√©er nouveau client_id pour test isol√©
- Backup √©tat actuel (optionnel)

**Commandes**:
```bash
# V√©rifier profil AWS
aws sts get-caller-identity --profile rag-lai-prod

# Cr√©er snapshot (optionnel)
python scripts/snapshot/create_snapshot.py --description "Avant test workflow fresh data"
```

**Client ID**: `lai_weekly_v18`

---

### √âTAPE 2: CONFIGURATION CLIENT (5 min)

**Actions**:
- Copier config lai_weekly_v17 ‚Üí lai_weekly_v18
- Upload vers S3

**Commandes**:
```bash
# Copier config de r√©f√©rence
cp client-config-examples/production/lai_weekly_v17.yaml \
   client-config-examples/production/lai_weekly_v18.yaml

# Upload vers S3
aws s3 cp client-config-examples/production/lai_weekly_v18.yaml \
  s3://vectora-inbox-config-dev/clients/lai_weekly_v18.yaml \
  --profile rag-lai-prod --region eu-west-3
```

**Param√®tres**:
- `period_days: 7` (derniers 7 jours)
- `temporal_mode: balanced`
- Sources: Config v17 (bouquets LAI valid√©s)

---

### √âTAPE 3: EX√âCUTION WORKFLOW E2E (15-20 min)

**Option A - Script automatis√© (RECOMMAND√â)**:
```bash
python scripts/invoke/invoke_e2e_workflow.py \
  --client-id lai_weekly_v18 \
  --env dev
```

**Option B - √âtape par √©tape**:
```bash
# 1. Ingest (2-3 min)
aws lambda invoke \
  --function-name vectora-inbox-ingest-v2-dev \
  --payload '{"client_id":"lai_weekly_v18"}' \
  .tmp/v18_ingest_response.json \
  --profile rag-lai-prod --region eu-west-3

# 2. Normalize-Score (10-15 min - ASYNCHRONE)
aws lambda invoke \
  --function-name vectora-inbox-normalize-score-v2-dev \
  --invocation-type Event \
  --payload '{"client_id":"lai_weekly_v18"}' \
  .tmp/v18_normalize_response.json \
  --profile rag-lai-prod --region eu-west-3

# Attendre 10-15 min puis v√©rifier
aws s3 ls s3://vectora-inbox-data-dev/curated/lai_weekly_v18/ \
  --recursive --profile rag-lai-prod

# 3. Newsletter (2-3 min)
aws lambda invoke \
  --function-name vectora-inbox-newsletter-v2-dev \
  --payload '{"client_id":"lai_weekly_v18"}' \
  .tmp/v18_newsletter_response.json \
  --profile rag-lai-prod --region eu-west-3
```

---

### √âTAPE 4: R√âCUP√âRATION R√âSULTATS (2 min)

**Commandes**:
```bash
# Date du jour
TODAY=$(date +%Y/%m/%d)

# T√©l√©charger items ing√©r√©s
aws s3 cp s3://vectora-inbox-data-dev/ingested/lai_weekly_v18/$TODAY/items.json \
  .tmp/v18_ingested.json --profile rag-lai-prod

# T√©l√©charger items cur√©s
aws s3 cp s3://vectora-inbox-data-dev/curated/lai_weekly_v18/$TODAY/items.json \
  .tmp/v18_curated.json --profile rag-lai-prod

# T√©l√©charger newsletter
aws s3 cp s3://vectora-inbox-newsletters-dev/lai_weekly_v18/$TODAY/newsletter.md \
  .tmp/v18_newsletter.md --profile rag-lai-prod
```

---

### √âTAPE 5: ANALYSE M√âTRIQUES (5 min)

**Script analyse rapide**:
```bash
python -c "
import json

items = json.load(open('.tmp/v18_curated.json', encoding='utf-8'))

total = len(items)
with_ds = sum(1 for i in items if i.get('has_domain_scoring'))
relevant = sum(1 for i in items if i.get('domain_scoring',{}).get('is_relevant'))
companies = sum(1 for i in items if i.get('normalized_content',{}).get('entities',{}).get('companies'))
scores = [i.get('domain_scoring',{}).get('score',0) for i in items if i.get('has_domain_scoring')]
avg_score = sum(scores)/len(scores) if scores else 0

print('='*60)
print('M√âTRIQUES V18 vs V17 (BASELINE)')
print('='*60)
print(f'Items ing√©r√©s:       {total:2d} (V17: 31)')
print(f'Domain scoring:      {with_ds}/{total} ({with_ds/total*100:.0f}%) (V17: 100%)')
print(f'Companies:           {companies}/{total} ({companies/total*100:.0f}%) (V17: 74%)')
print(f'Items relevant:      {relevant}/{with_ds} ({relevant/with_ds*100:.0f}%) (V17: 64%)')
print(f'Score moyen:         {avg_score:.1f} (V17: 71.5)')
print('='*60)

print('\nVERDICT:')
if companies/total >= 0.70 and relevant/with_ds >= 0.60 and avg_score >= 65:
    print('‚úÖ SUCC√àS - Toutes m√©triques >= seuils')
elif companies/total >= 0.65 and relevant/with_ds >= 0.55:
    print('‚ö†Ô∏è ATTENTION - M√©triques proches seuils')
else:
    print('‚ùå √âCHEC - M√©triques < seuils')
"
```

---

### √âTAPE 6: RAPPORT STRUCTUR√â (10 min)

**Cr√©er rapport selon format Golden Test**:
```bash
cat > docs/reports/e2e/test_e2e_v18_rapport_$(date +%Y-%m-%d).md << 'EOF'
# Test E2E V18 - Donn√©es Fra√Æches

## R√©sum√© Ex√©cutif

**Verdict**: [√Ä compl√©ter]

Test workflow complet avec donn√©es RSS fra√Æches.

R√©sultats cl√©s:
- Companies: X% (objectif 70%+) [Statut]
- Items relevant: X% (objectif 60%+) [Statut]
- Faux n√©gatifs: X (objectif 0) [Statut]

**D√©cision**: [MERGE / CORRIGER / ROLLBACK]

## M√©triques Comparatives

| M√©trique | V17 | V18 | Evolution | Cible | Statut |
|----------|-----|-----|-----------|-------|--------|
| Items ing√©r√©s | 31 | X | +X% | 25-35 | ‚úÖ/‚ùå |
| Companies | 74% | X% | +X% | ‚â•70% | ‚úÖ/‚ùå |
| Items relevant | 64% | X% | +X% | ‚â•60% | ‚úÖ/‚ùå |
| Score moyen | 71.5 | X | +X | 65-85 | ‚úÖ/‚ùå |

## Distribution Sources

[√Ä compl√©ter]

## Top 5 Items Relevant

[√Ä compl√©ter]

## Analyse Faux N√©gatifs

[√Ä compl√©ter]

## Annexes

### Fichiers G√©n√©r√©s
- `.tmp/v18_ingested.json`
- `.tmp/v18_curated.json`
- `.tmp/v18_newsletter.md`

### Versions
- vectora-core: [voir VERSION]
- canonical: [voir VERSION]
- client: lai_weekly_v18
- environnement: dev
EOF
```

---

### √âTAPE 7: D√âCISION (2 min)

**Crit√®res**:

‚úÖ **SUCC√àS** (workflow valid√©):
- Companies ‚â• 70%
- Items relevant ‚â• 60%
- Score moyen 65-85
- 0-1 faux n√©gatifs

‚ö†Ô∏è **ATTENTION** (√† surveiller):
- 1-2 m√©triques l√©g√®rement < seuils
- Justification claire n√©cessaire

‚ùå **√âCHEC** (investigation requise):
- 3+ m√©triques < seuils
- Faux n√©gatifs > 1
- R√©gression vs V17

---

## ‚úÖ CHECKLIST COMPL√àTE

**Avant ex√©cution**:
- [ ] Profil AWS configur√© (`rag-lai-prod`)
- [ ] Client ID choisi (`lai_weekly_v18`)
- [ ] Config client cr√©√©e et upload√©e S3
- [ ] Dossier `.tmp/` pr√™t

**Pendant ex√©cution**:
- [ ] Ingest compl√©t√© (2-3 min)
- [ ] Normalize-Score lanc√© (asynchrone)
- [ ] Attente 10-15 min
- [ ] Newsletter g√©n√©r√©e (2-3 min)

**Apr√®s ex√©cution**:
- [ ] R√©sultats t√©l√©charg√©s depuis S3
- [ ] M√©triques calcul√©es
- [ ] Comparaison vs V17 effectu√©e
- [ ] Rapport cr√©√© selon format Golden Test
- [ ] D√©cision prise

---

## ‚è±Ô∏è TEMPS TOTAL

- Pr√©paration: 5 min
- Configuration: 5 min
- Ex√©cution workflow: 15-20 min
- Analyse: 5 min
- Rapport: 10 min

**TOTAL: 40-45 minutes**

---

## üéØ PROCHAINES √âTAPES

**Si SUCC√àS**:
- Documenter dans rapport
- Archiver r√©sultats
- Workflow valid√©

**Si ATTENTION/√âCHEC**:
- Analyser logs Lambda (CloudWatch)
- Identifier items probl√©matiques
- Ajuster configuration (voir blueprint tuning_guide)
- Re-tester

---

## üìö R√âF√âRENCES

- Golden Test E2E: `.q-context/GOLDEN_TEST_E2E.md`
- Blueprint: `docs/architecture/blueprint-v2-ACTUAL-2026.yaml`
- Workflow: `.q-context/00-START-HERE.md`
- R√®gles critiques: `.q-context/CRITICAL_RULES.md`

---

**Plan cr√©√©**: 2026-02-04  
**Statut**: PR√äT √Ä EX√âCUTER
