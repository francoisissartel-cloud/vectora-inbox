# Plan Correctif - Matching LAI Weekly v12

**Date**: 2026-02-03  
**Objectif**: Corriger le probl√®me de matching (0% ‚Üí 60-80%) avec approche scalable  
**Bas√© sur**: diagnostic_matching_lai_weekly_v11_2026-02-03.md  
**Option valid√©e**: Option 1 - Cr√©er lai_domain_definition.yaml

---

## üéØ OBJECTIFS

### Objectifs Imm√©diats (Phase 1)
- ‚úÖ D√©bloquer le matching (0% ‚Üí >50%)
- ‚úÖ Newsletter fonctionnelle avec 10-15 items pertinents
- ‚úÖ Architecture scalable pour am√©lioration continue

### Objectifs Long Terme (Phases 2-3)
- ‚úÖ Syst√®me d'am√©lioration continue des prompts
- ‚úÖ M√©triques de qualit√© track√©es par version
- ‚úÖ Workflow d'ajustement sans red√©ploiement code
- ‚úÖ Documentation des learnings E2E

---

## üìã PHASE 1: CORRECTION IMM√âDIATE (Jour 1)

### √âtape 1.1: Cr√©er Domain Definition (2h)

**Fichier**: `canonical/scopes/domain_definitions.yaml`

**Action**: Cr√©er fichier avec structure scalable

```yaml
# Domain Definitions - Matching and Scoring Rules
# Version: 1.0.0
# Last Updated: 2026-02-03
# 
# √âVOLUTION: Ce fichier sera enrichi au fil des tests E2E
# - Ajouter signaux d√©tect√©s dans les faux n√©gatifs
# - Retirer signaux g√©n√©rant du bruit (faux positifs)
# - Ajuster scores bas√©s sur feedback utilisateur

lai_domain_definition:
  _metadata:
    version: "1.0.0"
    description: "LAI domain definition for matching and scoring"
    last_updated: "2026-02-03"
    changelog:
      - version: "1.0.0"
        date: "2026-02-03"
        changes: "Initial version - baseline from diagnostic"
        test_run: "lai_weekly_v12"
  
  # SIGNAUX FORTS (high confidence match)
  # Source: Scopes canonical existants via r√©f√©rences dynamiques
  core_technologies:
    - "{{ref:lai_keywords.core_phrases}}"
    - "{{ref:lai_keywords.technology_terms_high_precision}}"
  
  pure_player_companies:
    - "{{ref:lai_companies_mvp_core}}"
  
  trademarks:
    - "{{ref:lai_trademarks_global}}"
  
  # SIGNAUX MOYENS (medium confidence)
  technology_families:
    - "{{ref:lai_keywords.technology_use}}"
  
  dosing_intervals:
    - "{{ref:lai_keywords.interval_patterns}}"
  
  # SIGNAUX FAIBLES (low confidence)
  routes:
    - "{{ref:lai_keywords.route_admin_terms}}"
  
  molecules:
    - "{{ref:lai_molecules_global}}"
  
  # EXCLUSIONS (anti-LAI)
  exclusions:
    - "{{ref:lai_keywords.negative_terms}}"
  
  # R√àGLES DE MATCHING
  # √âVOLUTION: Ajuster seuils bas√©s sur m√©triques E2E
  matching_rules:
    high_confidence:
      description: "1+ strong signal ‚Üí high confidence match"
      conditions:
        - "1+ core_technology"
        - "1+ pure_player_company"
        - "1+ trademark"
      min_score: 70
    
    medium_confidence:
      description: "2+ medium signals ‚Üí medium confidence match"
      conditions:
        - "2+ technology_families"
        - "1+ dosing_interval + 1+ route"
      min_score: 40
    
    low_confidence:
      description: "3+ weak signals + 0 exclusions ‚Üí low confidence match"
      conditions:
        - "3+ weak signals"
        - "0 exclusions"
      min_score: 20
    
    reject:
      description: "1+ exclusion ‚Üí reject"
      conditions:
        - "1+ exclusion"
  
  # SCORES DE BASE PAR TYPE D'√âV√âNEMENT
  # √âVOLUTION: Ajuster bas√©s sur valeur business r√©elle
  event_type_base_scores:
    partnership: 60
    regulatory: 70
    clinical_update: 50
    financial_results: 40
    corporate_move: 45
    scientific_publication: 35
    other: 20
  
  # BOOSTS PAR TYPE D'ENTIT√â
  # √âVOLUTION: Ajuster bas√©s sur corr√©lation avec pertinence
  entity_boosts:
    pure_player_company: 25
    trademark: 20
    core_technology: 15
    technology_family: 10
    molecule: 8
    dosing_interval: 5
    route: 3
  
  # BOOST DE R√âCENCE
  recency_boost:
    max_boost: 10
    decay_days: 30
  
  # P√âNALIT√â DE CONFIANCE
  confidence_penalty:
    low_confidence: -5
    medium_confidence: 0
    high_confidence: 0
```

**Validation**:
```bash
# Valider syntaxe YAML
python -c "import yaml; yaml.safe_load(open('canonical/scopes/domain_definitions.yaml'))"
```

---

### √âtape 1.2: Sync vers S3 (15min)

**Actions**:
```bash
# Sync domain_definitions.yaml
aws s3 cp canonical/scopes/domain_definitions.yaml \
  s3://vectora-inbox-config-dev/canonical/scopes/domain_definitions.yaml \
  --profile rag-lai-prod --region eu-west-3

# V√©rifier upload
aws s3 ls s3://vectora-inbox-config-dev/canonical/scopes/ --recursive \
  --profile rag-lai-prod --region eu-west-3 | grep domain_definitions
```

**Validation**:
```bash
# T√©l√©charger et v√©rifier
aws s3 cp s3://vectora-inbox-config-dev/canonical/scopes/domain_definitions.yaml \
  /tmp/domain_definitions_s3.yaml \
  --profile rag-lai-prod --region eu-west-3

diff canonical/scopes/domain_definitions.yaml /tmp/domain_definitions_s3.yaml
```

---

### √âtape 1.3: Cr√©er Client Config v12 (30min)

**Fichier**: `client-config-examples/production/lai_weekly_v12.yaml`

**Action**: Copier v11 et modifier

```bash
# Copier v11 ‚Üí v12
cp client-config-examples/production/lai_weekly_v11.yaml \
   client-config-examples/production/lai_weekly_v12.yaml
```

**Modifications**:
```yaml
client_profile:
  name: "LAI Intelligence Weekly v12 (Test Domain Definition Fix)"
  client_id: "lai_weekly_v12"
  
metadata:
  template_version: "12.0.0"
  created_date: "2026-02-03"
  created_by: "Correctif Matching - Domain Definition Fix"
  
  creation_notes: |
    OBJECTIF v12 (Correctif Matching):
    üéØ Corriger 0% matching via lai_domain_definition.yaml
    üéØ Valider architecture 2 appels Bedrock
    üéØ Baseline pour am√©lioration continue
    
    MODIFICATIONS v11 ‚Üí v12:
    ‚úÖ client_id: "lai_weekly_v11" ‚Üí "lai_weekly_v12"
    ‚úÖ Ajout domain_definitions.yaml sur S3
    ‚úÖ Config identique pour comparaison
    
    M√âTRIQUES ATTENDUES:
    - Taux matching: 0% ‚Üí >50%
    - Items match√©s: 0/29 ‚Üí 15+/29
    - Score UZEDY¬Æ: 0 ‚Üí >90
    - Score MedinCell: 0 ‚Üí >85
```

**Sync vers S3**:
```bash
aws s3 cp client-config-examples/production/lai_weekly_v12.yaml \
  s3://vectora-inbox-config-dev/clients/lai_weekly_v12.yaml \
  --profile rag-lai-prod --region eu-west-3
```

---

### √âtape 1.4: Test E2E lai_weekly_v12 (1h)

**Actions**:
```bash
# Test complet
python scripts/invoke/invoke_ingest_v2.py --client-id lai_weekly_v12
python scripts/invoke/invoke_normalize_score_v2.py --client-id lai_weekly_v12
```

**T√©l√©charger r√©sultats**:
```bash
# Cr√©er dossier temporaire
mkdir -p .tmp/e2e/lai_weekly_v12

# T√©l√©charger items cur√©s
aws s3 cp s3://vectora-inbox-data-dev/curated/lai_weekly_v12/2026/02/03/items.json \
  .tmp/e2e/lai_weekly_v12/curated_items.json \
  --profile rag-lai-prod --region eu-west-3
```

---

### √âtape 1.5: Analyse R√©sultats (1h)

**Script d'analyse**: `scripts/analysis/analyze_matching_v12.py`

```python
import json

with open('.tmp/e2e/lai_weekly_v12/curated_items.json') as f:
    items = json.load(f)

# M√©triques matching
total = len(items)
matched = sum(1 for item in items if item.get('domain_scoring', {}).get('is_relevant'))
match_rate = (matched / total * 100) if total > 0 else 0

print(f"Taux matching: {match_rate:.1f}% ({matched}/{total})")

# Analyse par score
scores = [item.get('domain_scoring', {}).get('score', 0) for item in items if item.get('domain_scoring', {}).get('is_relevant')]
if scores:
    print(f"Score moyen: {sum(scores)/len(scores):.1f}")
    print(f"Score min: {min(scores)}")
    print(f"Score max: {max(scores)}")

# Items cl√©s
for item in items:
    title = item.get('title', '')
    if 'UZEDY' in title or 'MedinCell' in title or 'Extended-Release Injectable' in title:
        score = item.get('domain_scoring', {}).get('score', 0)
        is_relevant = item.get('domain_scoring', {}).get('is_relevant', False)
        print(f"\n{title[:80]}")
        print(f"  Relevant: {is_relevant}, Score: {score}")
```

**Ex√©cution**:
```bash
python scripts/analysis/analyze_matching_v12.py
```

---

### √âtape 1.6: Rapport Phase 1 (30min)

**Fichier**: `docs/reports/e2e/test_e2e_v12_phase1_correction_2026-02-03.md`

**Contenu**:
```markdown
# Test E2E v12 - Phase 1 Correction Matching

## R√©sultats

### M√©triques Matching
- Taux matching: X% (objectif: >50%)
- Items match√©s: X/29 (objectif: 15+)
- Score UZEDY¬Æ: X (objectif: >90)
- Score MedinCell: X (objectif: >85)

### Statut
- ‚úÖ Succ√®s si >50% matching
- ‚ö†Ô∏è Ajustements requis si 30-50%
- ‚ùå √âchec si <30%

### Prochaines Actions
- Si succ√®s: Phase 2 (ajustements fins)
- Si ajustements: Modifier domain_definition
- Si √©chec: Investiguer logs Bedrock
```

**Crit√®res de succ√®s Phase 1**:
- ‚úÖ Taux matching >50%
- ‚úÖ Items LAI √©vidents match√©s (UZEDY¬Æ, MedinCell, Extended-Release)
- ‚úÖ Pas d'erreurs Bedrock

---

## üìã PHASE 2: AM√âLIORATION CONTINUE (Jour 2-3)

### √âtape 2.1: Syst√®me de Versioning Prompts

**Objectif**: Tracker √©volution des prompts et domain definitions

**Fichier**: `canonical/scopes/domain_definitions.yaml`

**Structure de changelog**:
```yaml
lai_domain_definition:
  _metadata:
    version: "1.1.0"
    changelog:
      - version: "1.1.0"
        date: "2026-02-04"
        changes: "Ajout signaux d√©tect√©s dans faux n√©gatifs v12"
        test_run: "lai_weekly_v13"
        metrics:
          match_rate_before: "52%"
          match_rate_after: "68%"
          precision_before: "75%"
          precision_after: "82%"
      
      - version: "1.0.0"
        date: "2026-02-03"
        changes: "Initial version - baseline"
        test_run: "lai_weekly_v12"
        metrics:
          match_rate: "52%"
          precision: "75%"
```

---

### √âtape 2.2: Analyse Faux Positifs/N√©gatifs

**Script**: `scripts/analysis/analyze_false_positives_negatives.py`

```python
"""
Analyse des faux positifs et faux n√©gatifs pour am√©lioration continue.
"""

def analyze_false_positives(items, human_labels):
    """Items match√©s √† tort."""
    false_positives = []
    for item in items:
        if item['domain_scoring']['is_relevant'] and not human_labels.get(item['item_id']):
            false_positives.append({
                'title': item['title'],
                'score': item['domain_scoring']['score'],
                'signals': item['domain_scoring']['signals_detected'],
                'reasoning': item['domain_scoring']['reasoning']
            })
    return false_positives

def analyze_false_negatives(items, human_labels):
    """Items LAI manqu√©s."""
    false_negatives = []
    for item in items:
        if not item['domain_scoring']['is_relevant'] and human_labels.get(item['item_id']):
            false_negatives.append({
                'title': item['title'],
                'entities': item['normalized_content']['entities'],
                'missing_signals': analyze_missing_signals(item)
            })
    return false_negatives

def generate_recommendations(false_positives, false_negatives):
    """G√©n√®re recommandations d'ajustement."""
    recommendations = []
    
    # Faux positifs ‚Üí signaux trop permissifs
    for fp in false_positives:
        if 'weak' in fp['signals']:
            recommendations.append({
                'action': 'increase_threshold',
                'target': 'weak_signals',
                'reason': f"Faux positif: {fp['title'][:50]}"
            })
    
    # Faux n√©gatifs ‚Üí signaux manquants
    for fn in false_negatives:
        for entity_type, entities in fn['entities'].items():
            for entity in entities:
                if entity not in get_current_scopes(entity_type):
                    recommendations.append({
                        'action': 'add_to_scope',
                        'target': f'{entity_type}_scope',
                        'value': entity,
                        'reason': f"Faux n√©gatif: {fn['title'][:50]}"
                    })
    
    return recommendations
```

---

### √âtape 2.3: Workflow d'Ajustement

**Processus**:

1. **Analyser r√©sultats E2E**
   ```bash
   python scripts/analysis/analyze_false_positives_negatives.py \
     --items .tmp/e2e/lai_weekly_v12/curated_items.json \
     --human-labels .tmp/e2e/lai_weekly_v12/human_labels.json \
     --output .tmp/e2e/lai_weekly_v12/recommendations.json
   ```

2. **Appliquer recommandations**
   - Modifier `canonical/scopes/domain_definitions.yaml`
   - Incr√©menter version (1.0.0 ‚Üí 1.1.0)
   - Ajouter changelog entry

3. **Sync vers S3**
   ```bash
   aws s3 cp canonical/scopes/domain_definitions.yaml \
     s3://vectora-inbox-config-dev/canonical/scopes/domain_definitions.yaml \
     --profile rag-lai-prod --region eu-west-3
   ```

4. **Test E2E v13**
   ```bash
   # Nouveau client_id pour donn√©es fra√Æches
   python scripts/invoke/invoke_normalize_score_v2.py --client-id lai_weekly_v13
   ```

5. **Comparer m√©triques**
   ```bash
   python scripts/analysis/compare_versions.py \
     --v1 lai_weekly_v12 \
     --v2 lai_weekly_v13
   ```

---

### √âtape 2.4: Dashboard M√©triques

**Fichier**: `scripts/monitoring/matching_dashboard.py`

```python
"""
Dashboard de monitoring des m√©triques de matching.
G√©n√®re rapport HTML avec √©volution des m√©triques.
"""

def generate_dashboard(versions):
    """G√©n√®re dashboard HTML."""
    metrics_history = []
    
    for version in versions:
        items = load_items(version)
        metrics = calculate_metrics(items)
        metrics_history.append({
            'version': version,
            'date': get_test_date(version),
            'match_rate': metrics['match_rate'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'avg_score': metrics['avg_score']
        })
    
    # G√©n√©rer graphiques
    plot_match_rate_evolution(metrics_history)
    plot_precision_recall(metrics_history)
    plot_score_distribution(metrics_history)
    
    # G√©n√©rer HTML
    html = generate_html_report(metrics_history)
    with open('docs/reports/matching_dashboard.html', 'w') as f:
        f.write(html)
```

**Usage**:
```bash
python scripts/monitoring/matching_dashboard.py \
  --versions lai_weekly_v12,lai_weekly_v13,lai_weekly_v14
```

---

## üìã PHASE 3: INDUSTRIALISATION (Jour 4-5)

### √âtape 3.1: Tests Automatis√©s

**Fichier**: `tests/integration/test_domain_scoring.py`

```python
"""
Tests d'int√©gration pour domain scoring.
Valide que les items LAI √©vidents sont toujours match√©s.
"""

import pytest

GOLDEN_ITEMS = [
    {
        'title': 'MedinCell UZEDY¬Æ Sales',
        'entities': {'companies': ['MedinCell'], 'trademarks': ['UZEDY¬Æ']},
        'expected_score': 90,
        'expected_confidence': 'high'
    },
    {
        'title': 'Nanexa PharmaShell¬Æ Partnership',
        'entities': {'companies': ['Nanexa'], 'technologies': ['PharmaShell¬Æ']},
        'expected_score': 85,
        'expected_confidence': 'high'
    }
]

@pytest.mark.parametrize('golden_item', GOLDEN_ITEMS)
def test_golden_items_matched(golden_item):
    """Items LAI √©vidents doivent toujours √™tre match√©s."""
    result = score_item_for_domain(golden_item, domain_definition, canonical_scopes)
    
    assert result['is_relevant'] == True
    assert result['score'] >= golden_item['expected_score']
    assert result['confidence'] == golden_item['expected_confidence']
```

**Ex√©cution**:
```bash
pytest tests/integration/test_domain_scoring.py -v
```

---

### √âtape 3.2: Script de Validation Prompts

**Fichier**: `scripts/maintenance/validate_prompts.py`

```python
"""
Valide que tous les prompts ont leurs r√©f√©rences r√©solues.
"""

def validate_prompt_references(prompt_path, canonical_scopes):
    """Valide r√©f√©rences {{ref:}}."""
    with open(prompt_path) as f:
        content = f.read()
    
    refs = re.findall(r'\{\{ref:([^}]+)\}\}', content)
    missing = []
    
    for ref in refs:
        if not resolve_scope_path(ref, canonical_scopes):
            missing.append(ref)
    
    if missing:
        print(f"‚ùå {prompt_path}: Missing references:")
        for ref in missing:
            print(f"   - {{{{ref:{ref}}}}}")
        return False
    
    print(f"‚úÖ {prompt_path}: All references valid")
    return True

if __name__ == '__main__':
    canonical_scopes = load_canonical_scopes()
    
    prompts = [
        'canonical/prompts/normalization/generic_normalization.yaml',
        'canonical/prompts/domain_scoring/lai_domain_scoring.yaml',
        'canonical/prompts/editorial/lai_editorial.yaml'
    ]
    
    all_valid = all(validate_prompt_references(p, canonical_scopes) for p in prompts)
    sys.exit(0 if all_valid else 1)
```

**Int√©gration CI/CD**:
```bash
# Ajouter dans .github/workflows/validate.yml
- name: Validate Prompts
  run: python scripts/maintenance/validate_prompts.py
```

---

### √âtape 3.3: Documentation Am√©lioration Continue

**Fichier**: `docs/guides/amelioration_continue_prompts.md`

```markdown
# Guide d'Am√©lioration Continue des Prompts

## Workflow Standard

### 1. Test E2E
- Lancer test avec client_id incr√©ment√©
- T√©l√©charger r√©sultats depuis S3

### 2. Analyse Humaine
- Labelliser 20-30 items (pertinent/non pertinent)
- Identifier faux positifs et faux n√©gatifs

### 3. G√©n√©rer Recommandations
```bash
python scripts/analysis/analyze_false_positives_negatives.py
```

### 4. Appliquer Ajustements
- Modifier `canonical/scopes/domain_definitions.yaml`
- Incr√©menter version
- Ajouter changelog

### 5. Sync et Test
```bash
aws s3 sync canonical/ s3://vectora-inbox-config-dev/canonical/
python scripts/invoke/invoke_normalize_score_v2.py --client-id lai_weekly_vXX
```

### 6. Comparer M√©triques
```bash
python scripts/analysis/compare_versions.py --v1 vXX --v2 vYY
```

### 7. Commit si Am√©lioration
```bash
git add canonical/scopes/domain_definitions.yaml
git commit -m "feat: improve matching v1.X.0 (+5% match rate)"
```

## M√©triques √† Tracker

- **Match Rate**: % items match√©s
- **Precision**: % items match√©s pertinents
- **Recall**: % items pertinents match√©s
- **Avg Score**: Score moyen des items match√©s
- **False Positive Rate**: % faux positifs
- **False Negative Rate**: % faux n√©gatifs

## Seuils de Qualit√©

- Match Rate: 60-80%
- Precision: >80%
- Recall: >70%
- Avg Score: >60
```

---

## üìä M√âTRIQUES DE SUCC√àS

### Phase 1 (Jour 1)

| M√©trique | Avant | Objectif | Critique |
|----------|-------|----------|----------|
| Taux matching | 0% | >50% | ‚úÖ |
| Items match√©s | 0/29 | 15+/29 | ‚úÖ |
| Score UZEDY¬Æ | 0 | >90 | ‚úÖ |
| Score MedinCell | 0 | >85 | ‚úÖ |
| Newsletter g√©n√©r√©e | ‚ùå | ‚úÖ | ‚úÖ |

### Phase 2 (Jour 2-3)

| M√©trique | Objectif Phase 1 | Objectif Phase 2 |
|----------|------------------|------------------|
| Taux matching | >50% | 60-80% |
| Precision | >70% | >80% |
| Recall | >60% | >70% |
| Faux positifs | <30% | <20% |
| Faux n√©gatifs | <40% | <30% |

### Phase 3 (Jour 4-5)

| Livrable | Statut |
|----------|--------|
| Tests automatis√©s | ‚úÖ |
| Script validation prompts | ‚úÖ |
| Dashboard m√©triques | ‚úÖ |
| Documentation compl√®te | ‚úÖ |
| Code merg√© develop | ‚úÖ |

---

## üöÄ COMMANDES RAPIDES

### Test E2E Complet
```bash
# Version courte
python scripts/invoke/invoke_normalize_score_v2.py --client-id lai_weekly_v12

# Version compl√®te avec analyse
python scripts/invoke/invoke_ingest_v2.py --client-id lai_weekly_v12
python scripts/invoke/invoke_normalize_score_v2.py --client-id lai_weekly_v12
python scripts/analysis/analyze_matching_v12.py
```

### Sync Canonical vers S3
```bash
aws s3 sync canonical/ s3://vectora-inbox-config-dev/canonical/ \
  --profile rag-lai-prod --region eu-west-3 --exclude "*.md"
```

### Comparer Versions
```bash
python scripts/analysis/compare_versions.py \
  --v1 lai_weekly_v12 --v2 lai_weekly_v13 \
  --output docs/reports/comparison_v12_v13.md
```

### G√©n√©rer Dashboard
```bash
python scripts/monitoring/matching_dashboard.py \
  --versions lai_weekly_v12,lai_weekly_v13,lai_weekly_v14 \
  --output docs/reports/matching_dashboard.html
```

---

## üìù CHECKLIST EX√âCUTION

### Phase 1: Correction Imm√©diate
- [ ] Cr√©er `canonical/scopes/domain_definitions.yaml`
- [ ] Valider syntaxe YAML
- [ ] Sync vers S3
- [ ] Cr√©er `lai_weekly_v12.yaml`
- [ ] Sync client config vers S3
- [ ] Test E2E lai_weekly_v12
- [ ] T√©l√©charger r√©sultats S3
- [ ] Analyser m√©triques matching
- [ ] Rapport Phase 1
- [ ] Validation crit√®res succ√®s (>50% matching)

### Phase 2: Am√©lioration Continue
- [ ] Analyser faux positifs/n√©gatifs
- [ ] G√©n√©rer recommandations
- [ ] Ajuster domain_definitions.yaml
- [ ] Incr√©menter version (1.0.0 ‚Üí 1.1.0)
- [ ] Sync vers S3
- [ ] Test E2E lai_weekly_v13
- [ ] Comparer v12 vs v13
- [ ] G√©n√©rer dashboard m√©triques
- [ ] Validation crit√®res succ√®s (60-80% matching, >80% precision)

### Phase 3: Industrialisation
- [ ] Cr√©er tests automatis√©s
- [ ] Cr√©er script validation prompts
- [ ] Cr√©er dashboard monitoring
- [ ] Documenter workflow am√©lioration continue
- [ ] Commit et tag version
- [ ] Merge dans develop
- [ ] Mettre √† jour blueprint

---

## üéØ PROCHAINES ACTIONS IMM√âDIATES

1. **Cr√©er domain_definitions.yaml** (maintenant)
2. **Sync vers S3** (dans 15min)
3. **Test E2E v12** (dans 30min)
4. **Analyser r√©sultats** (dans 2h)
5. **Rapport Phase 1** (dans 3h)

**Timeline totale Phase 1**: 4-5 heures  
**Confiance succ√®s**: 95%

---

**Plan cr√©√© le**: 2026-02-03  
**Bas√© sur**: diagnostic_matching_lai_weekly_v11_2026-02-03.md  
**Statut**: ‚úÖ Pr√™t pour ex√©cution imm√©diate
