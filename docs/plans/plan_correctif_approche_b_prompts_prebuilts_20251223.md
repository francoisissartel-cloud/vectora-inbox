# Plan Correctif: Impl√©mentation Approche B - Prompts Pr√©-construits

**Date**: 2025-12-23  
**Objectif**: Impl√©menter l'Approche B (Prompts Pr√©-construits) sur Vectora Inbox  
**POC**: lai_weekly_v5  
**Principe**: Configuration > Code

---

## üéØ OBJECTIF ET VISION

### Probl√®me Actuel

**Hardcoding LAI dans bedrock_client.py** (lignes 200-250):
```python
lai_section = "\n\nLAI TECHNOLOGY FOCUS:\n"
lai_section += "Detect these LAI (Long-Acting Injectable) technologies:\n"
lai_section += "- Extended-Release Injectable\n"
lai_section += "- Three-Month Injectable\n"      # Hardcod√©
lai_section += "- Extended Protection\n"         # Hardcod√© pour malaria
```

**Cons√©quences**:
- Impossible d'adapter √† Gene Therapy sans modifier le code
- Bidouillages successifs
- Viole "Configuration > Code"

### Solution Approche B

**Prompts pr√©-construits dans canonical/prompts/** avec r√©f√©rences aux scopes:
- `lai_normalization_prompt.yaml` - Prompt normalisation LAI complet
- `lai_matching_prompt.yaml` - Prompt matching LAI complet
- R√©f√©rences dynamiques: `{{ref:lai_companies_global}}`
- Module `prompt_resolver.py` (50 lignes) pour r√©solution

### B√©n√©fices

‚úÖ **Simplicit√©**: Code minimal (50 lignes vs 300)  
‚úÖ **Visibilit√©**: Prompt complet visible dans fichier  
‚úÖ **Performance**: Overhead <1% du temps total  
‚úÖ **Contr√¥le**: Humain ajuste prompts sans toucher au code  
‚úÖ **Debugging**: Copier-coller dans Bedrock Playground  

---

## üìä PHASE 0: DIAGNOSTIC EXISTANT

### 0.1 Analyse Architecture Actuelle

**Lambdas appelant Bedrock**:

1. **normalize-score-v2**:
   - Appel 1: Normalisation (extraction entit√©s)
   - Appel 2: Matching (√©valuation domaines)

2. **newsletter-v2**:
   - Appel 3: G√©n√©ration √©ditoriale (TL;DR, intro)

**Flux Normalisation**:
```
normalize_score/__init__.py::run_normalize_score_for_client()
  ‚Üì
normalizer.normalize_items_batch()
  ‚Üì
BedrockNormalizationClient.normalize_item()
  ‚Üì
_build_normalization_prompt_v2() OU _build_normalization_prompt_v1()
  ‚Üì HARDCODING LAI ICI
call_bedrock_with_retry()
```

**Flux Matching**:
```
normalizer.normalize_items_batch()
  ‚Üì
bedrock_matcher.match_item_to_domains_bedrock()
  ‚Üì
_call_bedrock_matching()
  ‚Üì
call_bedrock_with_retry()
```

### 0.2 Fichiers Canonical Existants

**Structure actuelle**:
```
canonical/
‚îú‚îÄ‚îÄ scopes/
‚îÇ   ‚îú‚îÄ‚îÄ company_scopes.yaml          # lai_companies_global (‚úÖ bien con√ßu)
‚îÇ   ‚îú‚îÄ‚îÄ technology_scopes.yaml       # lai_keywords (‚úÖ structure riche)
‚îÇ   ‚îú‚îÄ‚îÄ molecule_scopes.yaml         # lai_molecules_global
‚îÇ   ‚îú‚îÄ‚îÄ trademark_scopes.yaml        # lai_trademarks_global
‚îÇ   ‚îî‚îÄ‚îÄ indication_scopes.yaml
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ global_prompts.yaml          # ‚ùå Hardcod√© LAI actuellement
‚îî‚îÄ‚îÄ events/
    ‚îî‚îÄ‚îÄ event_type_patterns.yaml     # ‚úÖ Patterns event_type
```

**Qualit√©**: Scopes excellents, prompts √† refactorer

### 0.3 Client Config Existant

**lai_weekly_v5.yaml** (extrait):
```yaml
watch_domains:
  - id: "tech_lai_ecosystem"
    technology_scope: "lai_keywords"
    company_scope: "lai_companies_global"
    molecule_scope: "lai_molecules_global"
    trademark_scope: "lai_trademarks_global"
```

**Qualit√©**: ‚úÖ Excellent, pr√™t pour Approche B

### 0.4 Points de Vigilance Identifi√©s

‚ö†Ô∏è **Question 1**: Faut-il un prompt par client ou par verticale?
- **Recommandation**: Par verticale (lai, gene_therapy, etc.)
- **Raison**: Plusieurs clients peuvent partager la m√™me verticale

‚ö†Ô∏è **Question 2**: Comment organiser canonical/prompts/?
- **Recommandation**: Structure par type + verticale
- **Exemple**: `canonical/prompts/normalization/lai_prompt.yaml`

‚ö†Ô∏è **Question 3**: Compatibilit√© avec prompts existants?
- **Recommandation**: Garder fallback sur global_prompts.yaml
- **Migration progressive**: Nouveau syst√®me en priorit√©, ancien en fallback

---

## üìã PHASE 1: CR√âATION FICHIERS CANONICAL PROMPTS

### 1.1 Structure Propos√©e

```
canonical/prompts/
‚îú‚îÄ‚îÄ normalization/
‚îÇ   ‚îú‚îÄ‚îÄ lai_prompt.yaml              # NOUVEAU
‚îÇ   ‚îî‚îÄ‚îÄ gene_therapy_prompt.yaml     # Futur
‚îú‚îÄ‚îÄ matching/
‚îÇ   ‚îú‚îÄ‚îÄ lai_prompt.yaml              # NOUVEAU
‚îÇ   ‚îî‚îÄ‚îÄ gene_therapy_prompt.yaml     # Futur
‚îî‚îÄ‚îÄ global_prompts.yaml              # EXISTANT (fallback)
```

### 1.2 Cr√©ation lai_normalization_prompt.yaml

**Fichier**: `canonical/prompts/normalization/lai_prompt.yaml`

**Contenu** (structure compl√®te avec r√©f√©rences):

```yaml
# Prompt de normalisation LAI pr√©-construit
# Utilise des r√©f√©rences aux scopes canonical: {{ref:scope_name}}

metadata:
  vertical: "LAI"
  version: "1.0"
  created_date: "2025-12-23"
  description: "Prompt normalisation pour Long-Acting Injectables"

system_instructions: |
  You are a specialized AI assistant for biotech/pharma news analysis.
  Focus on Long-Acting Injectable (LAI) technologies and related entities.
  Extract structured information with high precision.

user_template: |
  Analyze this biotech/pharma news item and extract structured information.

  CRITICAL: Only extract entities that are EXPLICITLY mentioned in the text.
  FORBIDDEN: Do not invent, infer, or hallucinate entities not present.

  TEXT TO ANALYZE:
  {{item_text}}

  LAI TECHNOLOGY FOCUS:
  Detect these Long-Acting Injectable technologies ONLY if explicitly mentioned:
  {{ref:lai_keywords.core_phrases}}

  High-precision technology terms:
  {{ref:lai_keywords.technology_terms_high_precision}}

  EXAMPLES OF ENTITIES TO DETECT:
  - Companies: {{ref:lai_companies_global}}
  - Molecules: {{ref:lai_molecules_global}}
  - Trademarks: {{ref:lai_trademarks_global}}

  EXCLUDE if these terms are present:
  {{ref:lai_keywords.negative_terms}}

  TASK:
  1. Generate a concise summary (2-3 sentences)
  2. Classify event type: clinical_update, partnership, regulatory, corporate_move, financial_results, other
  3. Extract ALL pharmaceutical/biotech company names mentioned
  4. Extract ALL drug/molecule names mentioned
  5. Extract ALL technology keywords mentioned
  6. Extract ALL trademark names mentioned
  7. Extract ALL therapeutic indications mentioned
  8. Evaluate LAI relevance (0-10 score)
  9. Detect anti-LAI signals
  10. Assess pure player context

  RESPONSE FORMAT (JSON only):
  {
    "summary": "...",
    "event_type": "...",
    "companies_detected": ["..."],
    "molecules_detected": ["..."],
    "technologies_detected": ["..."],
    "trademarks_detected": ["..."],
    "indications_detected": ["..."],
    "lai_relevance_score": 0,
    "anti_lai_detected": false,
    "pure_player_context": false
  }

  Respond with ONLY the JSON, no additional text.

bedrock_config:
  max_tokens: 1000
  temperature: 0.0
  anthropic_version: "bedrock-2023-05-31"
```

**Taille estim√©e**: ~1.5 KB (compact)

### 1.3 Cr√©ation lai_matching_prompt.yaml

**Fichier**: `canonical/prompts/matching/lai_prompt.yaml`

**Contenu**:

```yaml
# Prompt de matching LAI pr√©-construit

metadata:
  vertical: "LAI"
  version: "1.0"
  created_date: "2025-12-23"
  description: "Prompt matching pour Long-Acting Injectables"

system_instructions: |
  You are a domain relevance expert for biotech/pharma intelligence.
  Evaluate how relevant a normalized news item is to LAI watch domains.
  Be precise and conservative in your evaluations.

user_template: |
  Evaluate the relevance of this normalized item to the LAI watch domains:

  ITEM TO EVALUATE:
  Title: {{item_title}}
  Summary: {{item_summary}}
  Entities: {{item_entities}}
  Event Type: {{item_event_type}}

  WATCH DOMAINS TO EVALUATE:
  {{domains_context}}

  For each domain, evaluate:
  1. Is this item relevant to LAI technologies?
  2. Relevance score (0.0 to 1.0)?
  3. Confidence level (high/medium/low)?
  4. Which entities contributed to the match?
  5. Brief reasoning

  EVALUATION CRITERIA:
  - LAI technology signals required
  - Company relevance to LAI ecosystem
  - Be conservative: prefer false negatives over false positives

  RESPONSE FORMAT (JSON only):
  {
    "domain_evaluations": [
      {
        "domain_id": "...",
        "is_relevant": true/false,
        "relevance_score": 0.0-1.0,
        "confidence": "high/medium/low",
        "reasoning": "...",
        "matched_entities": {...}
      }
    ]
  }

  Respond with ONLY the JSON, no additional text.

bedrock_config:
  max_tokens: 1500
  temperature: 0.1
  anthropic_version: "bedrock-2023-05-31"
```

### 1.4 Modification client_config

**Fichier**: `client-config-examples/lai_weekly_v5.yaml`

**Ajout section bedrock_config**:

```yaml
# NOUVEAU: Configuration des prompts Bedrock
bedrock_config:
  normalization_prompt: "lai"      # R√©f√©rence √† canonical/prompts/normalization/lai_prompt.yaml
  matching_prompt: "lai"           # R√©f√©rence √† canonical/prompts/matching/lai_prompt.yaml

# EXISTANT (inchang√©)
watch_domains:
  - id: "tech_lai_ecosystem"
    technology_scope: "lai_keywords"
    company_scope: "lai_companies_global"
```

---

## üîß PHASE 2: CR√âATION MODULE PROMPT_RESOLVER

### 2.1 Nouveau Module

**Fichier**: `src_v2/vectora_core/shared/prompt_resolver.py`

**Taille**: ~80 lignes (minimaliste)

**Fonctions**:

```python
def resolve_prompt_references(
    prompt_template: str,
    canonical_scopes: Dict
) -> str:
    """
    R√©sout les r√©f√©rences {{ref:...}} dans un prompt.
    
    Exemples:
        {{ref:lai_companies_global}} ‚Üí "MedinCell, Camurus, ..."
        {{ref:lai_keywords.core_phrases}} ‚Üí "long-acting injectable, ..."
    """

def load_prompt_for_client(
    client_config: Dict,
    prompt_type: str,  # "normalization" ou "matching"
    config_bucket: str
) -> Dict:
    """
    Charge le prompt pr√©-construit pour un client.
    
    Process:
    1. Lire bedrock_config.normalization_prompt depuis client_config
    2. Charger canonical/prompts/{prompt_type}/{vertical}_prompt.yaml
    3. Retourner prompt config
    """
```

### 2.2 Impl√©mentation Minimale

**Code complet** (~80 lignes):

```python
import re
import logging
from typing import Dict, Any
from . import s3_io

logger = logging.getLogger(__name__)

def resolve_prompt_references(
    prompt_template: str,
    canonical_scopes: Dict[str, Any]
) -> str:
    """R√©sout {{ref:scope}} et {{ref:scope.field}}"""
    
    pattern = r'\{\{ref:([a-z_]+)(?:\.([a-z_]+))?\}\}'
    
    def replace_ref(match):
        scope_name = match.group(1)
        field_name = match.group(2)
        
        scope_data = canonical_scopes.get(scope_name)
        if not scope_data:
            logger.warning(f"Scope '{scope_name}' not found")
            return f"[SCOPE_NOT_FOUND:{scope_name}]"
        
        if field_name:
            if isinstance(scope_data, dict):
                field_data = scope_data.get(field_name, [])
            else:
                return f"[INVALID_SCOPE_STRUCTURE:{scope_name}]"
        else:
            field_data = scope_data
        
        if isinstance(field_data, list):
            return ', '.join(str(item) for item in field_data[:15])
        else:
            return str(field_data)
    
    resolved = re.sub(pattern, replace_ref, prompt_template)
    return resolved


def load_prompt_for_client(
    client_config: Dict[str, Any],
    prompt_type: str,
    config_bucket: str
) -> Dict[str, Any]:
    """Charge prompt pr√©-construit depuis canonical"""
    
    bedrock_config = client_config.get('bedrock_config', {})
    prompt_key = f"{prompt_type}_prompt"
    vertical = bedrock_config.get(prompt_key)
    
    if not vertical:
        logger.warning(f"No {prompt_key} in client bedrock_config")
        return None
    
    prompt_path = f"canonical/prompts/{prompt_type}/{vertical}_prompt.yaml"
    
    try:
        prompt_config = s3_io.read_yaml_from_s3(config_bucket, prompt_path)
        logger.info(f"Loaded prompt: {prompt_path}")
        return prompt_config
    except Exception as e:
        logger.error(f"Failed to load prompt {prompt_path}: {e}")
        return None
```

---

## üî® PHASE 3: MODIFICATION BEDROCK_CLIENT.PY

### 3.1 Modifications Minimales

**Fichier**: `src_v2/vectora_core/normalization/bedrock_client.py`

**Changements**:

1. **Import prompt_resolver**:
```python
from ..shared import prompt_resolver
```

2. **Nouvelle m√©thode** (ajouter apr√®s ligne 150):
```python
def _build_normalization_prompt_prebuilt(
    self, item_text, client_config, canonical_scopes, canonical_prompts, config_bucket
):
    """Construit prompt depuis fichier pr√©-construit"""
    
    # Charger prompt pr√©-construit
    prompt_config = prompt_resolver.load_prompt_for_client(
        client_config, "normalization", config_bucket
    )
    
    if not prompt_config:
        # Fallback sur m√©thode existante
        logger.warning("Prompt pr√©-construit non trouv√©, fallback sur v1")
        return self._build_normalization_prompt_v1(
            item_text, {}, None, None
        )
    
    # R√©soudre r√©f√©rences
    template = prompt_config['user_template']
    resolved = prompt_resolver.resolve_prompt_references(template, canonical_scopes)
    
    # Substituer {{item_text}}
    final_prompt = resolved.replace('{{item_text}}', item_text)
    
    return final_prompt
```

3. **Modifier normalize_item()** (ligne ~120):
```python
def normalize_item(self, item_text, canonical_examples, 
                  domain_contexts=None, canonical_prompts=None,
                  item_source_key=None, client_config=None, config_bucket=None):
    
    # NOUVEAU: Essayer prompt pr√©-construit d'abord
    if client_config and config_bucket:
        prompt = self._build_normalization_prompt_prebuilt(
            item_text, client_config, canonical_examples, 
            canonical_prompts, config_bucket
        )
    else:
        # Fallback sur m√©thode existante
        prompt = self._build_normalization_prompt_v1(
            item_text, canonical_examples, domain_contexts, item_source_key
        )
```

**Lignes modifi√©es**: ~30 lignes ajout√©es, 5 lignes modifi√©es

### 3.2 Modification Normalizer.py

**Fichier**: `src_v2/vectora_core/normalization/normalizer.py`

**Changement**: Passer client_config et config_bucket √† bedrock_client

**Ligne ~80** dans `_normalize_sequential()`:
```python
# AVANT
normalization_result = bedrock_client.normalize_item(
    item_text, examples, canonical_prompts=canonical_prompts,
    item_source_key=item.get('source_key')
)

# APR√àS
normalization_result = bedrock_client.normalize_item(
    item_text, examples, canonical_prompts=canonical_prompts,
    item_source_key=item.get('source_key'),
    client_config=client_config,  # NOUVEAU
    config_bucket=config_bucket   # NOUVEAU
)
```

**Ligne ~50** dans `normalize_items_batch()`:
```python
# Ajouter param√®tres
def normalize_items_batch(
    raw_items, canonical_scopes, canonical_prompts,
    bedrock_model, bedrock_region, max_workers=1,
    watch_domains=None, matching_config=None,
    client_config=None, config_bucket=None  # NOUVEAU
):
```

**Lignes modifi√©es**: ~10 lignes

### 3.3 Modification __init__.py

**Fichier**: `src_v2/vectora_core/normalization/__init__.py`

**Ligne ~70** dans `run_normalize_score_for_client()`:
```python
# APR√àS chargement config (ligne 40)
config_bucket = env_vars["CONFIG_BUCKET"]  # Stocker pour passage

# Ligne ~70
normalized_items = normalizer.normalize_items_batch(
    raw_items, canonical_scopes, canonical_prompts,
    bedrock_model, env_vars["BEDROCK_REGION"],
    max_workers=max_workers,
    watch_domains=watch_domains,
    matching_config=matching_config,
    client_config=client_config,  # NOUVEAU
    config_bucket=config_bucket   # NOUVEAU
)
```

**Lignes modifi√©es**: ~5 lignes

---

## üß™ PHASE 4: TESTS LOCAUX

### 4.1 Test Unitaire prompt_resolver

**Fichier**: `tests/unit/test_prompt_resolver.py` (NOUVEAU)

**Tests**:
```python
def test_resolve_simple_reference():
    """Test {{ref:lai_companies_global}}"""

def test_resolve_nested_reference():
    """Test {{ref:lai_keywords.core_phrases}}"""

def test_missing_scope():
    """Test scope inexistant"""

def test_load_prompt_for_client():
    """Test chargement prompt depuis S3"""
```

### 4.2 Test Int√©gration Normalisation

**Script**: `scripts/test_normalization_prebuilt_local.py` (NOUVEAU)

**Process**:
1. Charger lai_weekly_v5.yaml
2. Charger canonical scopes
3. Charger prompt pr√©-construit
4. Tester sur 5 items r√©els
5. Comparer r√©sultats avec v1

**Validation**:
- Prompt final g√©n√©r√© correctement
- R√©f√©rences r√©solues
- Entit√©s extraites identiques √† v1

---

## üöÄ PHASE 5: D√âPLOIEMENT AWS

### 5.1 Upload Fichiers Canonical

**Commandes**:
```bash
# Upload prompts LAI
aws s3 cp canonical/prompts/normalization/lai_prompt.yaml \
  s3://vectora-inbox-config-dev/canonical/prompts/normalization/ \
  --profile rag-lai-prod

aws s3 cp canonical/prompts/matching/lai_prompt.yaml \
  s3://vectora-inbox-config-dev/canonical/prompts/matching/ \
  --profile rag-lai-prod

# Upload client_config modifi√©
aws s3 cp client-config-examples/lai_weekly_v5.yaml \
  s3://vectora-inbox-config-dev/clients/ \
  --profile rag-lai-prod
```

### 5.2 Build et Deploy Lambda

**Script**: `scripts/deploy/deploy_normalize_score_v2_prebuilt.py` (NOUVEAU)

**Process**:
1. Build package avec prompt_resolver.py
2. Upload vers S3
3. Update Lambda normalize-score-v2

**Commande**:
```bash
python scripts/deploy/deploy_normalize_score_v2_prebuilt.py
```

### 5.3 Validation D√©ploiement

**Checks**:
- [ ] Fichiers canonical upload√©s
- [ ] Lambda mise √† jour
- [ ] Variables d'environnement OK
- [ ] Logs CloudWatch accessibles

---

## ‚úÖ PHASE 6: TESTS E2E POC

### 6.1 Test lai_weekly_v5

**Payload**:
```json
{
  "client_id": "lai_weekly_v5",
  "force_reprocess": false
}
```

**Invocation**:
```bash
aws lambda invoke \
  --function-name vectora-inbox-normalize-score-v2-dev \
  --payload file://payload_lai_v5.json \
  --profile rag-lai-prod \
  response.json
```

### 6.2 Validation R√©sultats

**M√©triques attendues**:
- ‚úÖ Items normalis√©s: 100%
- ‚úÖ Prompt pr√©-construit utilis√© (check logs)
- ‚úÖ R√©f√©rences r√©solues correctement
- ‚úÖ Entit√©s extraites coh√©rentes avec v1
- ‚úÖ Temps d'ex√©cution similaire (<5% diff√©rence)

**Logs √† v√©rifier**:
```
"Loaded prompt: canonical/prompts/normalization/lai_prompt.yaml"
"Resolved 5 references in prompt"
"Using prebuilt prompt for normalization"
```

### 6.3 Comparaison v1 vs Approche B

**Script**: `scripts/analysis/compare_v1_vs_prebuilt.py` (NOUVEAU)

**Comparaison**:
- Nombre d'entit√©s extraites
- Event types classifi√©s
- Scores LAI
- Temps d'ex√©cution

**Seuils acceptables**:
- Diff√©rence entit√©s: <5%
- Diff√©rence scores: <10%
- Temps ex√©cution: <5%

---

## üìä PHASE 7: RETOUR UTILISATEUR

### 7.1 Documentation Utilisateur

**Fichier**: `docs/guides/guide_ajustement_prompts_approche_b.md` (NOUVEAU)

**Contenu**:
- Comment ajuster un prompt LAI
- Comment cr√©er un prompt pour nouvelle verticale
- Syntaxe des r√©f√©rences {{ref:...}}
- Tests dans Bedrock Playground

### 7.2 Checklist Ajustements

**Pour ajuster la s√©lectivit√©**:
1. Modifier `canonical/prompts/normalization/lai_prompt.yaml`
2. Ajuster instructions CRITICAL/FORBIDDEN
3. Modifier r√©f√©rences aux scopes
4. Upload vers S3
5. Tester avec lai_weekly_v5

**Pas de modification de code Python n√©cessaire**

### 7.3 Monitoring

**M√©triques CloudWatch**:
- Temps r√©solution prompts
- Taux succ√®s chargement prompts
- Fallback sur v1 (doit √™tre 0%)

---

## üìã R√âCAPITULATIF MODIFICATIONS

### Fichiers Cr√©√©s (6)

1. `canonical/prompts/normalization/lai_prompt.yaml` (~1.5 KB)
2. `canonical/prompts/matching/lai_prompt.yaml` (~1 KB)
3. `src_v2/vectora_core/shared/prompt_resolver.py` (~80 lignes)
4. `tests/unit/test_prompt_resolver.py` (~100 lignes)
5. `scripts/test_normalization_prebuilt_local.py` (~150 lignes)
6. `docs/guides/guide_ajustement_prompts_approche_b.md` (doc)

### Fichiers Modifi√©s (4)

1. `client-config-examples/lai_weekly_v5.yaml` (+5 lignes)
2. `src_v2/vectora_core/normalization/bedrock_client.py` (+35 lignes)
3. `src_v2/vectora_core/normalization/normalizer.py` (+10 lignes)
4. `src_v2/vectora_core/normalization/__init__.py` (+5 lignes)

**Total code ajout√©**: ~280 lignes  
**Total code modifi√©**: ~55 lignes  
**Ratio**: Minimaliste et cibl√©

---

## ‚ö†Ô∏è POINTS DE VIGILANCE

### Vigilance 1: Compatibilit√© Ascendante

**Risque**: Casser le comportement existant

**Mitigation**:
- Fallback sur v1 si prompt pr√©-construit absent
- Tests comparatifs v1 vs Approche B
- D√©ploiement progressif (POC lai_weekly_v5 d'abord)

### Vigilance 2: R√©solution R√©f√©rences

**Risque**: R√©f√©rences mal r√©solues (scope inexistant)

**Mitigation**:
- Validation au chargement
- Logs explicites si scope manquant
- Tests unitaires exhaustifs

### Vigilance 3: Performance

**Risque**: Overhead r√©solution r√©f√©rences

**Mitigation**:
- Mesure temps r√©solution (<20ms attendu)
- Cache possible si n√©cessaire
- Monitoring CloudWatch

### Vigilance 4: Synchronisation S3

**Risque**: Prompts S3 d√©synchronis√©s avec code

**Mitigation**:
- Versioning des prompts (metadata.version)
- Upload syst√©matique lors d√©ploiement
- Validation au d√©marrage Lambda

---

## üéØ CRIT√àRES DE SUCC√àS

### Succ√®s Technique

‚úÖ Prompt pr√©-construit charg√© et utilis√©  
‚úÖ R√©f√©rences r√©solues correctement  
‚úÖ R√©sultats identiques √† v1 (¬±5%)  
‚úÖ Performance maintenue (<5% overhead)  
‚úÖ Aucun fallback sur v1  

### Succ√®s M√©tier

‚úÖ Humain peut ajuster prompts sans code  
‚úÖ Debugging facilit√© (prompt visible)  
‚úÖ Tests manuels possibles (Playground)  
‚úÖ Documentation claire  
‚úÖ G√©n√©rique (pr√™t pour Gene Therapy)  

### Succ√®s Op√©rationnel

‚úÖ D√©ploiement sans incident  
‚úÖ Logs exploitables  
‚úÖ Monitoring en place  
‚úÖ Rollback possible  
‚úÖ Documentation √† jour  

---

## üìÖ PLANNING ESTIM√â

**Phase 0 (Diagnostic)**: 2h - Analyse existant  
**Phase 1 (Canonical)**: 3h - Cr√©ation prompts LAI  
**Phase 2 (Resolver)**: 2h - Module prompt_resolver  
**Phase 3 (Bedrock)**: 3h - Modifications bedrock_client  
**Phase 4 (Tests locaux)**: 2h - Tests unitaires + int√©gration  
**Phase 5 (D√©ploiement)**: 1h - Upload S3 + deploy Lambda  
**Phase 6 (Tests E2E)**: 2h - POC lai_weekly_v5  
**Phase 7 (Documentation)**: 1h - Guide utilisateur  

**Total estim√©**: 16h (2 jours)

---

## üö¶ PROCHAINES √âTAPES

1. **Validation du plan** avec product owner
2. **Phase 1**: Cr√©ation prompts LAI dans canonical
3. **Phase 2**: Impl√©mentation prompt_resolver
4. **Phase 3**: Modifications bedrock_client
5. **Phase 4**: Tests locaux
6. **Phase 5**: D√©ploiement AWS
7. **Phase 6**: POC lai_weekly_v5
8. **Phase 7**: Documentation et retour

**Pr√™t √† d√©marrer**: Toutes les informations n√©cessaires sont disponibles

---

*Plan correctif r√©alis√© le 2025-12-23*  
*Bas√© sur analyse compl√®te du code et des diagnostics*  
*Objectif: Approche B op√©rationnelle sur lai_weekly_v5*
