# Rapport d'√âvaluation Architecturale
## Syst√®me de Matching, Scoring et S√©lection - Vectora Inbox

**Date**: 2026-01-31  
**Version**: 1.0  
**Client de r√©f√©rence**: lai_weekly_v7  
**√âvaluateur**: Architecte Cloud AWS

---

## üéØ R√©sum√© Ex√©cutif

### Vision du Moteur
**Ambition**: Moteur g√©n√©rique de veille sectorielle capable de s'adapter √† diff√©rentes verticales (LAI, siRNA, cell therapy, gene therapy) via des configurations canonical pilotables par un humain.

### Verdict Global
**üü° ARCHITECTURE SOLIDE AVEC OPTIMISATIONS N√âCESSAIRES**

**Points forts**:
- ‚úÖ S√©paration claire des responsabilit√©s (matching ‚Üí scoring ‚Üí s√©lection)
- ‚úÖ Configuration pilot√©e par canonical (scopes, prompts)
- ‚úÖ Moteur g√©n√©rique avec sp√©cialisation LAI r√©ussie
- ‚úÖ Tra√ßabilit√© compl√®te des d√©cisions

**Points d'am√©lioration**:
- ‚ö†Ô∏è Complexit√© excessive dans le matching (2 syst√®mes parall√®les)
- ‚ö†Ô∏è Scoring avec trop de r√®gles imbriqu√©es
- ‚ö†Ô∏è Manque de coh√©rence entre matching Bedrock et scoring d√©terministe
- ‚ö†Ô∏è S√©lection avec logique de distribution fragile

---

## ü§ñ Cartographie des Appels Bedrock

### Vue d'Ensemble du Workflow

```
Workflow E2E: ingest-v2 ‚Üí normalize-score-v2 ‚Üí newsletter-v2
                 ‚Üì              ‚Üì                    ‚Üì
            Bedrock: 0      Bedrock: 2N          Bedrock: M
                            (N items)            (M sections)
```

### Lambda 1: ingest-v2

**Appels Bedrock**: **AUCUN**

**R√¥le**: Ingestion brute
- R√©cup√©ration contenus externes (RSS, APIs)
- Parsing HTML/XML
- Stockage S3 `ingested/`

**Fichiers impliqu√©s**:
- `src_v2/vectora_core/ingest/source_fetcher.py`
- `src_v2/vectora_core/ingest/content_parser.py`

---

### Lambda 2: normalize-score-v2

**Appels Bedrock**: **2 appels par item** (normalisation + matching)

#### Appel 1: Normalisation (1 par item)

**Fichier**: `src_v2/vectora_core/normalization/bedrock_client.py`

**Fonction**: `BedrockNormalizationClient.normalize_item()`

**Prompt**: `canonical/prompts/normalization/lai_normalization.yaml`

**R√¥le**:
- Extraction entit√©s (companies, molecules, technologies, trademarks)
- Classification √©v√©nement (partnership, regulatory, clinical_update, etc.)
- G√©n√©ration r√©sum√© (2-3 phrases)
- Extraction date publication
- √âvaluation pertinence LAI (score 0-10)
- D√©tection anti-LAI
- D√©tection contexte pure player

**Input**: Texte brut (title + content)

**Output**:
```json
{
  "summary": "...",
  "extracted_date": "2025-12-09",
  "date_confidence": 0.95,
  "event_type": "partnership",
  "companies_detected": ["MedinCell", "Teva"],
  "molecules_detected": ["Olanzapine"],
  "technologies_detected": ["Extended-Release Injectable"],
  "trademarks_detected": ["UZEDY¬Æ"],
  "indications_detected": ["Schizophrenia"],
  "lai_relevance_score": 8,
  "anti_lai_detected": false,
  "pure_player_context": true
}
```

**Co√ªt moyen**: ~$0.003 par appel

---

#### Appel 2: Matching (1 par item)

**Fichier**: `src_v2/vectora_core/normalization/bedrock_matcher.py`

**Fonction**: `match_item_to_domains_bedrock()`

**Prompt**: `canonical/prompts/matching/lai_matching.yaml`

**R√¥le**:
- √âvaluation pertinence pour chaque domaine de veille
- Matching s√©mantique (comprend nuances)
- Scoring de pertinence (0.0-1.0)
- Niveau de confiance (high/medium/low)
- Justification du matching

**Input**: Item normalis√© + contexte domaines

**Output**:
```json
{
  "domain_evaluations": [
    {
      "domain_id": "tech_lai_ecosystem",
      "is_relevant": true,
      "relevance_score": 0.85,
      "confidence": "high",
      "reasoning": "Extended-release injectable formulation highly relevant to LAI domain",
      "matched_entities": {
        "companies": ["MedinCell"],
        "technologies": ["Extended-Release Injectable"]
      }
    }
  ]
}
```

**Co√ªt moyen**: ~$0.004 par appel

---

#### Scoring: AUCUN Appel Bedrock

**Fichier**: `src_v2/vectora_core/normalization/scorer.py`

**R√¥le**: Scoring 100% d√©terministe
- Utilise r√©sultats normalisation + matching
- Applique r√®gles m√©tier (15+ r√®gles)
- Calcule bonus/p√©nalit√©s
- G√©n√®re score final (0-50)

**Pas d'appel Bedrock** - Tout est calcul√© localement

---

### Lambda 3: newsletter-v2

**Appels Bedrock**: **Variable selon sections** (g√©n√©ration √©ditoriale)

#### Appel 3: G√©n√©ration √âditoriale (1 par section ou global)

**Fichier**: `src_v2/vectora_core/newsletter/editorial.py` (√† impl√©menter)

**Prompt**: `canonical/prompts/editorial/lai_editorial.yaml`

**R√¥le**:
- G√©n√©ration TL;DR
- G√©n√©ration introduction
- Synth√®se par section (optionnel)
- Ton √©ditorial adapt√©

**Input**: Items s√©lectionn√©s par section

**Output**:
```json
{
  "tldr": "This week: 2 major regulatory approvals...",
  "introduction": "The LAI sector continues its momentum...",
  "section_summaries": {
    "regulatory_updates": "Key developments include..."
  }
}
```

**Co√ªt moyen**: ~$0.005 par appel

**Note**: Actuellement non impl√©ment√© - Newsletter g√©n√©r√©e sans Bedrock

---

### S√©lection: AUCUN Appel Bedrock

**Fichier**: `src_v2/vectora_core/newsletter/selector.py`

**R√¥le**: S√©lection 100% d√©terministe
- Filtrage par matching
- D√©duplication
- Distribution en sections
- Trimming intelligent

**Pas d'appel Bedrock** - Tout est calcul√© localement

---

## üìä Synth√®se des Appels Bedrock

### Par Lambda

| Lambda | Appels Bedrock | R√¥le |
|--------|----------------|------|
| **ingest-v2** | 0 | Ingestion brute uniquement |
| **normalize-score-v2** | 2N (N items) | Normalisation + Matching |
| **newsletter-v2** | M (sections) | G√©n√©ration √©ditoriale (optionnel) |

### Workflow Complet (Exemple: 15 items)

**Sc√©nario actuel (lai_weekly_v7)**:
- Ingest: 0 appels
- Normalize-Score: 30 appels (15 items √ó 2)
  - 15 appels normalisation
  - 15 appels matching
- Newsletter: 0 appels (g√©n√©ration √©ditoriale non impl√©ment√©e)
- **Total: 30 appels Bedrock**

**Co√ªt estim√©**:
- Normalisation: 15 √ó $0.003 = $0.045
- Matching: 15 √ó $0.004 = $0.060
- **Total: ~$0.105 par run**

**Temps estim√©**:
- Normalisation: 15 √ó 5s = 75s
- Matching: 15 √ó 5s = 75s
- **Total: ~150s (2.5 min) pour Bedrock**

---

### Scalabilit√© des Appels

**Formule**: `Total Bedrock Calls = 2 √ó N items + M sections`

**Limites identifi√©es**:
- **50 items**: 100 appels ‚Üí ~8 min ‚Üí OK
- **100 items**: 200 appels ‚Üí ~17 min ‚Üí Timeout Lambda (15 min)
- **Solution**: Parall√©lisation (max_workers=3-5)

**Avec parall√©lisation (max_workers=5)**:
- 100 items: 200 appels ‚Üí ~4 min ‚Üí OK
- 200 items: 400 appels ‚Üí ~8 min ‚Üí OK

---

### Points Cl√©s

1. ‚úÖ **Bedrock concentr√© dans normalize-score-v2** (100% des appels actuels)
2. ‚úÖ **Scoring et s√©lection 100% d√©terministes** (pas de Bedrock)
3. ‚úÖ **2 appels par item** (normalisation + matching)
4. ‚ö†Ô∏è **S√©quentiel actuellement** (max_workers=1)
5. ‚ö†Ô∏è **G√©n√©ration √©ditoriale non impl√©ment√©e** (newsletter-v2)

---

## üìä Analyse D√©taill√©e par Composant

### 1. MATCHING - D√©termination de la Pertinence

#### 1.1 Architecture Actuelle

**Fichiers impliqu√©s**:
- `normalizer.py` (orchestration)
- `bedrock_matcher.py` (matching s√©mantique Bedrock)
- `matcher.py` (matching d√©terministe - LEGACY)

**Flux actuel**:
```
Item normalis√© ‚Üí Bedrock Matching ‚Üí Seuils configur√©s ‚Üí Domaines match√©s
```

#### 1.2 Fonctionnement

**Appels Bedrock**:
- **1 appel par item** pour matching s√©mantique
- Prompt: `canonical/prompts/matching/lai_matching.yaml`
- √âvalue la pertinence pour chaque domaine de veille
- Retourne: `domain_evaluations` avec scores 0.0-1.0

**Configuration pilot√©e**:
```yaml
# Dans lai_weekly_v7.yaml
matching_config:
  min_domain_score: 0.25  # Seuil global
  domain_type_thresholds:
    technology: 0.30      # Plus strict pour tech
```

**R√©sultat**:
```json
{
  "matched_domains": ["tech_lai_ecosystem"],
  "domain_relevance": {
    "tech_lai_ecosystem": {
      "score": 0.85,
      "confidence": "high",
      "reasoning": "Extended-release injectable...",
      "matched_entities": {...}
    }
  }
}
```

#### 1.3 Principes Directeurs

‚úÖ **Points forts**:
1. **Matching s√©mantique Bedrock** - Comprend le contexte au-del√† des mots-cl√©s
2. **Seuils configurables** - Ajustables sans red√©ploiement
3. **Tra√ßabilit√©** - Reasoning explicite pour chaque d√©cision
4. **G√©n√©ricit√©** - Prompts adaptables √† d'autres verticales

‚ö†Ô∏è **Probl√®mes identifi√©s**:
1. **Double syst√®me** - `bedrock_matcher.py` ET `matcher.py` coexistent (confusion)
2. **Manque de validation** - Pas de v√©rification anti-hallucination post-matching
3. **Seuils arbitraires** - min_domain_score=0.25 sans justification m√©tier
4. **Pas de fallback** - Si Bedrock √©choue, item perdu

#### 1.4 Partis Pris Architecturaux

**Choix 1: Bedrock pour matching s√©mantique**
- ‚úÖ Avantage: Comprend nuances ("pure player context")
- ‚ùå Inconv√©nient: Co√ªt, latence, d√©pendance externe

**Choix 2: Matching par domaine (vs matching binaire)**
- ‚úÖ Avantage: Granularit√©, multi-domaines possibles
- ‚ùå Inconv√©nient: Complexit√© si 10+ domaines

**Choix 3: Seuils configurables**
- ‚úÖ Avantage: Ajustable par client
- ‚ùå Inconv√©nient: N√©cessite expertise pour calibrer

---

### 2. SCORING - Calcul de la Pertinence

#### 2.1 Architecture Actuelle

**Fichier impliqu√©**:
- `scorer.py` (logique compl√®te de scoring)

**Flux actuel**:
```
Item match√© ‚Üí Score de base (event_type) ‚Üí Facteurs multiplicatifs ‚Üí Bonus ‚Üí P√©nalit√©s ‚Üí Score final
```

#### 2.2 Fonctionnement

**Formule de scoring**:
```python
weighted_base = base_score * domain_relevance_factor * recency_factor
raw_score = weighted_base + total_bonus + total_penalty
final_score = max(0, min(50, raw_score * scoring_mode_factor))
```

**Appels Bedrock**: **AUCUN** (scoring 100% d√©terministe)

**Configuration pilot√©e**:
```yaml
# Dans lai_weekly_v7.yaml
scoring_config:
  event_type_weight_overrides:
    partnership: 8
    clinical_update: 6
    regulatory: 7
  
  client_specific_bonuses:
    pure_player_companies:
      scope: "lai_companies_mvp_core"
      bonus: 5.0
    trademark_mentions:
      bonus: 4.0
```

#### 2.3 Composants du Score

**1. Score de base (event_type)**:
- Partnership: 8.0
- Regulatory: 7.0
- Clinical: 6.0
- Other: 2.0

**2. Facteur de pertinence domaine** (0.05-1.0):
```python
# Utilise les r√©sultats du matching Bedrock
avg_relevance = 0.6 * score + 0.3 * confidence + trademark_boost
```

**3. Facteur de recency** (0.5-1.0):
- <24h: 1.0
- 1 semaine: 0.95
- 1 mois: 0.88
- 3 mois: 0.75
- 6+ mois: 0.5

**4. Bonus LAI** (0-10 points):
- Pure player: +5.0
- Trademark: +4.0
- Mol√©cule cl√©: +2.5
- Technologie LAI: +1.0-2.0
- LAI relevance score √©lev√©: +2.5

**5. P√©nalit√©s** (-5 √† 0):
- Anti-LAI d√©tect√©: -5.0
- LAI score faible: -3.0
- √Çge >6 mois: -2.0
- Pas d'entit√©s: -2.0

#### 2.4 Principes Directeurs

‚úÖ **Points forts**:
1. **D√©terministe** - Reproductible, testable, debuggable
2. **Transparent** - score_breakdown d√©taill√©
3. **Configurable** - Bonus/p√©nalit√©s ajustables
4. **M√©tier-driven** - Refl√®te l'expertise pharma (pure players, trademarks)

‚ö†Ô∏è **Probl√®mes identifi√©s**:
1. **Complexit√© excessive** - 15+ r√®gles imbriqu√©es difficiles √† maintenir
2. **Incoh√©rence avec matching** - Utilise `domain_relevance_factor` mais recalcule tout
3. **Calibration manuelle** - Bonus/p√©nalit√©s sans validation empirique
4. **Pas de machine learning** - Impossible d'apprendre des feedbacks humains
5. **Dates probl√©matiques** - Extraction dates Bedrock pas fiable (v7 en test)

#### 2.5 Partis Pris Architecturaux

**Choix 1: Scoring d√©terministe (vs ML)**
- ‚úÖ Avantage: Explicable, contr√¥lable, pas de training
- ‚ùå Inconv√©nient: Pas d'am√©lioration automatique

**Choix 2: Bonus additifs (vs multiplicatifs)**
- ‚úÖ Avantage: Pr√©visible, lin√©aire
- ‚ùå Inconv√©nient: Peut cr√©er des scores aberrants (cumul de bonus)

**Choix 3: Plafonnement √† 50**
- ‚úÖ Avantage: √âvite les outliers
- ‚ùå Inconv√©nient: Arbitraire, peut masquer des signaux exceptionnels

---

### 3. S√âLECTION - Choix des Items Newsletter

#### 3.1 Architecture Actuelle

**Fichiers impliqu√©s**:
- `selector.py` (logique compl√®te de s√©lection)
- `assembler.py` (formatage Markdown/JSON)

**Flux actuel**:
```
Items scor√©s ‚Üí Filtrage (matched only) ‚Üí D√©duplication ‚Üí Distribution sections ‚Üí Trimming ‚Üí Newsletter
```

#### 3.2 Fonctionnement

**√âtapes de s√©lection**:

**1. Filtrage par matching**:
```python
matched_items = [item for item in items 
                 if item['matching_results']['matched_domains']]
```

**2. D√©duplication**:
- Signature: `(companies, molecules, indications, event_type, title_hash)`
- Strat√©gie: Garder meilleur score ou √©v√©nement critique

**3. Distribution en sections**:
```yaml
# Strat√©gie: specialized_with_fallback
sections:
  - id: regulatory_updates
    filter_event_types: [regulatory]
    max_items: 6
    priority: 1
  
  - id: partnerships_deals
    filter_event_types: [partnership, corporate_move]
    max_items: 4
    priority: 2
  
  - id: others
    filter_event_types: ["*"]
    max_items: 8
    priority: 999  # Filet de s√©curit√©
```

**4. Trimming intelligent**:
- Pr√©server √©v√©nements critiques
- Compl√©ter avec meilleurs scores
- Respecter `max_items_total: 20`

#### 3.3 Principes Directeurs

‚úÖ **Points forts**:
1. **D√©duplication intelligente** - √âvite les doublons
2. **Sections sp√©cialis√©es** - Structure √©ditoriale claire
3. **Filet de s√©curit√©** - Section "others" pour items orphelins
4. **Pr√©servation √©v√©nements critiques** - Logique m√©tier

‚ö†Ô∏è **Probl√®mes identifi√©s**:
1. **Distribution fragile** - Tous les items finissent en "others" (bug v4)
2. **Logique event_type complexe** - Filtres pas toujours respect√©s
3. **Pas de diversit√© forc√©e** - Peut avoir 10 items d'une seule source
4. **Trimming brutal** - Peut perdre des signaux importants

#### 3.4 Partis Pris Architecturaux

**Choix 1: Distribution par event_type (vs par score)**
- ‚úÖ Avantage: Structure √©ditoriale coh√©rente
- ‚ùå Inconv√©nient: Peut cr√©er des sections vides

**Choix 2: D√©duplication par signature (vs ML similarity)**
- ‚úÖ Avantage: Rapide, d√©terministe
- ‚ùå Inconv√©nient: Peut manquer des doublons subtils

**Choix 3: Trimming avec pr√©servation critiques**
- ‚úÖ Avantage: Garantit les signaux forts
- ‚ùå Inconv√©nient: Peut sacrifier la diversit√©

---

## üîç Analyse Transversale

### Coh√©rence du Syst√®me

#### ‚úÖ Points de Coh√©rence

1. **Configuration centralis√©e** - Tout dans `lai_weekly_v7.yaml`
2. **Canonical comme source de v√©rit√©** - Scopes r√©utilis√©s partout
3. **Tra√ßabilit√© E2E** - Chaque d√©cision document√©e
4. **G√©n√©ricit√© valid√©e** - Architecture LAI transposable √† d'autres verticales

#### ‚ö†Ô∏è Incoh√©rences Identifi√©es

1. **Matching vs Scoring**:
   - Matching Bedrock retourne `confidence: "high"` (string)
   - Scorer attend un float ‚Üí Mapping hardcod√© n√©cessaire
   - **Impact**: Fragilit√©, risque d'erreur

2. **Dates**:
   - Bedrock extrait `extracted_date` (v7)
   - Scorer utilise `effective_date` (fallback sur `published_at`)
   - Assembler utilise `effective_date` pour affichage
   - **Impact**: 3 logiques diff√©rentes, confusion

3. **Scores multiples**:
   - `lai_relevance_score` (Bedrock, 0-10)
   - `final_score` (Scorer, 0-50)
   - `effective_score` (Selector, calcul√© √† la vol√©e)
   - **Impact**: Quelle m√©trique fait foi ?

4. **Event types**:
   - Bedrock classifie en `event_type`
   - Selector filtre par `filter_event_types`
   - Pas de validation que les types matchent
   - **Impact**: Sections vides si types divergent

### Scalabilit√©

#### ‚úÖ Scalable

1. **Ajout de clients** - Copier `lai_weekly_v7.yaml`, ajuster scopes
2. **Ajout de domaines** - Ajouter dans `watch_domains`
3. **Ajout de sources** - Modifier `source_bouquets_enabled`

#### ‚ö†Ô∏è Limites de Scalabilit√©

1. **Nombre de domaines** - Matching Bedrock lin√©aire (1 appel √ó N domaines)
   - **Limite**: ~10 domaines max avant timeout
   
2. **Volume d'items** - Scoring s√©quentiel
   - **Limite**: ~100 items max en <15min
   
3. **Complexit√© des r√®gles** - Scorer avec 15+ r√®gles
   - **Limite**: Maintenance difficile au-del√† de 20 r√®gles

### Pilotabilit√© Humaine

#### ‚úÖ Facilement Ajustable

1. **Seuils de matching** - `min_domain_score: 0.25` ‚Üí 0.30
2. **Bonus scoring** - `pure_player_bonus: 5.0` ‚Üí 6.0
3. **Structure newsletter** - `max_items: 6` ‚Üí 8
4. **Prompts Bedrock** - √âditer YAML, sync S3

#### ‚ö†Ô∏è Difficile √† Ajuster

1. **Formule de scoring** - N√©cessite comprendre 15+ r√®gles imbriqu√©es
2. **Logique de d√©duplication** - Signature hardcod√©e
3. **Distribution sections** - Logique `specialized_with_fallback` complexe
4. **Calibration empirique** - Pas d'outil pour tester impact des changements

---

## üéØ Recommandations Strat√©giques

### Priorit√© 1: SIMPLIFIER LE SCORING (Semaine 1-2)

**Probl√®me**: 15+ r√®gles imbriqu√©es, difficile √† maintenir et calibrer

**Solution propos√©e**: **Scoring en 3 niveaux**

```python
# Niveau 1: Score de base (event_type + matching)
base_score = event_type_weight * domain_relevance_score

# Niveau 2: Multiplicateurs m√©tier (pure player, trademark)
business_multiplier = 1.0
if is_pure_player: business_multiplier *= 1.5
if has_trademark: business_multiplier *= 1.3

# Niveau 3: Ajustements temporels
temporal_factor = recency_factor * (1 - age_penalty)

# Score final
final_score = base_score * business_multiplier * temporal_factor
```

**Avantages**:
- ‚úÖ 3 niveaux vs 15 r√®gles
- ‚úÖ Multiplicatif (effets compos√©s naturels)
- ‚úÖ Facile √† expliquer et ajuster
- ‚úÖ Pas de plafonnement arbitraire

**Effort**: 2-3 jours de refactoring + tests

---

### Priorit√© 2: UNIFIER MATCHING (Semaine 2-3)

**Probl√®me**: 2 syst√®mes de matching coexistent (`bedrock_matcher.py` + `matcher.py`)

**Solution propos√©e**: **Supprimer `matcher.py` (legacy)**

```python
# Garder uniquement bedrock_matcher.py
# Ajouter fallback d√©terministe si Bedrock √©choue

def match_item_to_domains(item, domains, config):
    try:
        # Matching Bedrock (prioritaire)
        return bedrock_matcher.match(item, domains, config)
    except BedrockError:
        # Fallback: matching par entit√©s
        return deterministic_fallback_match(item, domains)
```

**Avantages**:
- ‚úÖ 1 seul syst√®me, pas de confusion
- ‚úÖ Fallback pour r√©silience
- ‚úÖ Code plus simple (-500 lignes)

**Effort**: 1-2 jours de refactoring

---

### Priorit√© 3: COH√âRENCE DES DATES (Semaine 3)

**Probl√®me**: 3 logiques diff√©rentes pour les dates

**Solution propos√©e**: **Date unique `effective_date`**

```python
# Dans normalizer.py (apr√®s Bedrock)
effective_date = (
    bedrock_result['extracted_date'] if confidence > 0.7
    else item['published_at']
)
item['effective_date'] = effective_date  # Champ unique

# Partout ailleurs: utiliser item['effective_date']
```

**Avantages**:
- ‚úÖ 1 seule source de v√©rit√©
- ‚úÖ Logique centralis√©e
- ‚úÖ Pas de confusion

**Effort**: 1 jour de refactoring

---

### Priorit√© 4: OUTIL DE CALIBRATION (Mois 1)

**Probl√®me**: Ajuster les param√®tres n√©cessite tests E2E manuels

**Solution propos√©e**: **Script de simulation**

```bash
# Simuler l'impact d'un changement de param√®tre
python scripts/tools/simulate_scoring.py \
  --config lai_weekly_v7.yaml \
  --param "pure_player_bonus" \
  --values "3.0,4.0,5.0,6.0" \
  --input .tmp/curated_items.json \
  --output .tmp/simulation_results.json
```

**Fonctionnalit√©s**:
- Tester plusieurs valeurs de param√®tres
- Comparer distributions de scores
- Identifier items impact√©s
- G√©n√©rer rapport visuel

**Avantages**:
- ‚úÖ Calibration data-driven
- ‚úÖ Pas de d√©ploiement pour tester
- ‚úÖ Feedback rapide

**Effort**: 3-5 jours de d√©veloppement

---

### Priorit√© 5: VALIDATION ANTI-HALLUCINATION (Mois 1)

**Probl√®me**: Bedrock peut inventer des entit√©s (cas Drug Delivery Conference v4)

**Solution propos√©e**: **Validation post-Bedrock**

```python
def validate_bedrock_entities(bedrock_result, original_text):
    validated = {}
    
    for entity_type, entities in bedrock_result['entities'].items():
        validated[entity_type] = [
            entity for entity in entities
            if entity_appears_in_text(entity, original_text)
        ]
    
    # Log des hallucinations d√©tect√©es
    hallucinations = set(entities) - set(validated[entity_type])
    if hallucinations:
        logger.warning(f"Hallucinations: {hallucinations}")
    
    return validated
```

**Avantages**:
- ‚úÖ Filtre les faux positifs
- ‚úÖ Am√©liore la pr√©cision
- ‚úÖ Tra√ßabilit√© des hallucinations

**Effort**: 1-2 jours (d√©j√† partiellement impl√©ment√© dans `normalizer.py`)

---

## üìã Choix Strat√©giques √† Faire

### Choix 1: Scoring D√©terministe vs ML

**Option A: Garder d√©terministe (recommand√© court terme)**
- ‚úÖ Explicable, contr√¥lable
- ‚úÖ Pas de training data n√©cessaire
- ‚ùå Pas d'am√©lioration automatique

**Option B: Introduire ML (moyen terme)**
- ‚úÖ Apprend des feedbacks humains
- ‚úÖ S'am√©liore avec le temps
- ‚ùå N√©cessite 100+ exemples labellis√©s
- ‚ùå Moins explicable

**Recommandation**: **Option A** pour 6-12 mois, puis √©valuer Option B si volume suffisant

---

### Choix 2: Matching Multi-Domaines vs Domaine Unique

**Option A: Multi-domaines (actuel)**
- ‚úÖ Flexibilit√©
- ‚ùå Complexit√© (item peut matcher 3+ domaines)

**Option B: Domaine unique (simplifi√©)**
- ‚úÖ Simplicit√©
- ‚ùå Perte de granularit√©

**Recommandation**: **Option A** mais limiter √† 3 domaines max par client

---

### Choix 3: Bedrock pour Tout vs Hybride

**Option A: Bedrock pour matching + normalisation (actuel)**
- ‚úÖ Coh√©rence
- ‚ùå Co√ªt, latence

**Option B: Bedrock normalisation only, matching d√©terministe**
- ‚úÖ Co√ªt r√©duit (-50%)
- ‚ùå Perte de nuance s√©mantique

**Recommandation**: **Option A** pour LAI (haute valeur), Option B pour verticales √† plus gros volume

---

## üéØ Plan d'Action Recommand√©

### Phase 1: Stabilisation (Semaines 1-3)

**Objectif**: Corriger les incoh√©rences critiques

1. ‚úÖ Unifier matching (supprimer `matcher.py`)
2. ‚úÖ Simplifier scoring (3 niveaux)
3. ‚úÖ Coh√©rence dates (`effective_date`)
4. ‚úÖ Validation anti-hallucination

**Livrable**: Architecture V2.1 stable et coh√©rente

---

### Phase 2: Pilotabilit√© (Mois 1)

**Objectif**: Faciliter l'ajustement des param√®tres

1. ‚úÖ Outil de simulation scoring
2. ‚úÖ Dashboard de m√©triques (Grafana/CloudWatch)
3. ‚úÖ Documentation des param√®tres ajustables
4. ‚úÖ Tests E2E automatis√©s

**Livrable**: Syst√®me ajustable sans expertise technique

---

### Phase 3: Scalabilit√© (Mois 2-3)

**Objectif**: Pr√©parer l'ajout de nouvelles verticales

1. ‚úÖ Parall√©lisation Bedrock (max_workers=3)
2. ‚úÖ Cache Bedrock pour items similaires
3. ‚úÖ Optimisation prompts (tokens r√©duits)
4. ‚úÖ Tests de charge (100+ items)

**Livrable**: Syst√®me capable de g√©rer 3-5 clients simultan√©s

---

## üìä M√©triques de Succ√®s

### M√©triques Techniques

1. **Coh√©rence**: 0 incoh√©rences entre composants
2. **Performance**: <10min pour 50 items
3. **Co√ªt**: <$0.50 par run
4. **Fiabilit√©**: >95% succ√®s Bedrock

### M√©triques Qualit√©

1. **Pr√©cision matching**: >90% (validation humaine)
2. **Pertinence scores**: Corr√©lation >0.8 avec jugement humain
3. **Distribution sections**: <30% items en "others"
4. **Hallucinations**: <5% des entit√©s

### M√©triques Pilotabilit√©

1. **Temps ajustement param√®tre**: <5min (sans red√©ploiement)
2. **Feedback loop**: <1h (changement ‚Üí test ‚Üí validation)
3. **Documentation**: 100% param√®tres document√©s
4. **Simulation**: Tester 10 valeurs en <2min

---

## üéì Conclusion

### Ce qui Fonctionne Bien

1. ‚úÖ **Architecture modulaire** - S√©paration claire matching/scoring/s√©lection
2. ‚úÖ **Configuration pilot√©e** - Canonical comme source de v√©rit√©
3. ‚úÖ **G√©n√©ricit√© valid√©e** - LAI transposable √† d'autres verticales
4. ‚úÖ **Tra√ßabilit√©** - Chaque d√©cision document√©e

### Ce qui N√©cessite Am√©lioration

1. ‚ö†Ô∏è **Complexit√© scoring** - 15+ r√®gles ‚Üí 3 niveaux
2. ‚ö†Ô∏è **Incoh√©rences** - Dates, scores multiples, confidence mapping
3. ‚ö†Ô∏è **Pilotabilit√©** - Manque d'outils de simulation
4. ‚ö†Ô∏è **Scalabilit√©** - Limites √† 10 domaines, 100 items

### Recommandation Finale

**Le syst√®me est BIEN CONSTRUIT dans ses fondations mais TROP COMPLEXE dans son ex√©cution.**

**Action recommand√©e**: Simplifier avant d'√©tendre √† d'autres verticales.

**Timeline**: 3 semaines de refactoring pour atteindre l'√©tat optimal.

---

**Prochaine √©tape**: Valider les priorit√©s avec vous et cr√©er un plan d'ex√©cution d√©taill√©.
