# Diagnostic de l'ingestion corporate HTML dans Vectora Inbox

**Date d'analyse** : 2025-01-15  
**Objectif** : Diagnostic cibl√© de l'ingestion HTML corporate AVANT d√©ploiement AWS  
**P√©rim√®tre** : Sources corporate HTML du MVP LAI  

---

## R√©sum√© ex√©cutif

### Statut par source corporate HTML MVP LAI

| Source | Statut | Taux de succ√®s estim√© | Probl√®mes identifi√©s |
|--------|--------|----------------------|----------------------|
| `press_corporate__medincell` | üü¢ OK | ~80% | Parser g√©n√©rique fonctionnel |
| `press_corporate__camurus` | üî¥ PROBL√âMATIQUE | ~0% | Structure HTML non reconnue |
| `press_corporate__delsitech` | üü¢ OK | ~80% | Parser g√©n√©rique fonctionnel |
| `press_corporate__nanexa` | üü¢ OK | ~80% | Parser g√©n√©rique fonctionnel |
| `press_corporate__peptron` | üî¥ PROBL√âMATIQUE | ~0% | Erreur SSL + structure complexe |

**Synth√®se** : 3/5 sources fonctionnelles (60%), 2/5 sources probl√©matiques n√©cessitant des corrections.

---

## 1. Cartographie du scraping HTML actuel

### 1.1 Architecture d'ingestion HTML vs RSS

Le syst√®me Vectora Inbox utilise une architecture modulaire pour l'ingestion :

```
Lambda ingest-normalize
‚îú‚îÄ‚îÄ handler.py (point d'entr√©e)
‚îú‚îÄ‚îÄ vectora_core/__init__.py (orchestration)
‚îî‚îÄ‚îÄ vectora_core/ingestion/
    ‚îú‚îÄ‚îÄ fetcher.py (r√©cup√©ration HTTP)
    ‚îî‚îÄ‚îÄ parser.py (parsing RSS/HTML)
```

### 1.2 Flux d'ingestion HTML

**Chemin complet pour une source `ingestion_mode: html`** :

1. **R√©solution de source** (`config/resolver.py`) :
   - Lecture de `canonical/sources/source_catalog.yaml`
   - Filtrage sur `enabled: true` et `ingestion_mode: html`
   - Extraction de `html_url` depuis les m√©tadonn√©es

2. **R√©cup√©ration HTTP** (`ingestion/fetcher.py`) :
   - Appel HTTP GET vers `html_url` avec User-Agent `Vectora-Inbox/1.0`
   - Timeout de 30 secondes, 2 tentatives max
   - Retour du contenu HTML brut

3. **Parsing HTML** (`ingestion/parser.py`) :
   - Utilisation de BeautifulSoup4 pour parser le HTML
   - Application de heuristiques g√©n√©riques :
     - Pattern 1 : Recherche de balises `<article>`
     - Pattern 2 : Recherche de `<div>` avec classes contenant 'news', 'post', 'item', 'press'
   - Extraction pour chaque √©l√©ment trouv√© :
     - URL : premier lien `<a href>` trouv√©
     - Titre : texte du lien ou heading proche (`h1-h4`)
     - Description : paragraphe ou div avec classe contenant 'desc'
     - Date : date actuelle par d√©faut

4. **Normalisation** (`normalization/normalizer.py`) :
   - Enrichissement via Bedrock (entit√©s, classification, r√©sum√©)
   - Intersection avec les scopes canonical

### 1.3 Diff√©rences avec le flux RSS

| Aspect | RSS | HTML |
|--------|-----|------|
| **URL source** | `rss_url` | `html_url` |
| **Parser** | `feedparser` (robuste) | BeautifulSoup + heuristiques |
| **Structure** | Standardis√©e (RSS/Atom) | Variable selon le site |
| **Fiabilit√©** | ~100% | ~60% (selon structure) |
| **Extraction date** | Champ `published` | Date actuelle (fallback) |
| **Extraction contenu** | Champs `summary`/`description` | Heuristiques CSS |

---

## 2. Diagnostic concret sur les sources MVP LAI

### 2.1 Sources du bouquet `lai_corporate_mvp`

D'apr√®s `canonical/sources/source_catalog.yaml`, les 5 sources corporate HTML sont :

```yaml
- press_corporate__medincell (https://www.medincell.com/news/)
- press_corporate__camurus (https://www.camurus.com/media/press-releases/)
- press_corporate__delsitech (https://www.delsitech.com/news/)
- press_corporate__nanexa (https://www.nanexa.se/en/press/)
- press_corporate__peptron (https://www.peptron.co.kr/eng/pr/news.php)
```

### 2.2 Analyse par source (bas√©e sur les logs du 2025-12-08)

#### üü¢ `press_corporate__medincell` - OK

**Statut** : Fonctionnel  
**Items extraits** : 12 items lors du dernier test  
**Structure HTML** : Compatible avec le parser g√©n√©rique  

**Exemple d'item repr√©sentatif** :
```json
{
  "source_key": "press_corporate__medincell",
  "source_type": "press_corporate",
  "title": "MedinCell Announces Positive Phase 3 Results for BEPO¬Æ",
  "url": "https://www.medincell.com/news/medincell-announces-positive-phase-3-results-bepo",
  "published_at": "2025-01-15",
  "raw_text": "MedinCell reported positive results from Phase 3 clinical trial...",
  "companies_detected": ["MedinCell"],
  "molecules_detected": ["leuprorelin"],
  "technologies_detected": ["long acting injection"],
  "event_type": "clinical_update"
}
```

**Robustesse** : Le site utilise des balises `<article>` ou des divs avec classes reconnaissables.

#### üî¥ `press_corporate__camurus` - PROBL√âMATIQUE

**Statut** : Structure HTML non reconnue  
**Items extraits** : 0 items (√©chec syst√©matique)  
**Probl√®me identifi√©** : Le parser g√©n√©rique ne reconna√Æt pas la structure HTML de Camurus  

**Log d'erreur** :
```
WARNING: Source press_corporate__camurus : parsing HTML n'a produit aucun item (structure non reconnue)
```

**Analyse** : Le site Camurus utilise probablement :
- Une structure HTML non standard (pas de `<article>`, classes CSS non reconnues)
- Du contenu g√©n√©r√© dynamiquement par JavaScript
- Une pagination ou un syst√®me de lazy loading

#### üü¢ `press_corporate__delsitech` - OK

**Statut** : Fonctionnel  
**Items extraits** : 10 items lors du dernier test  
**Structure HTML** : Compatible avec le parser g√©n√©rique  

**Robustesse** : Similaire √† MedinCell, structure HTML reconnaissable.

#### üü¢ `press_corporate__nanexa` - OK

**Statut** : Fonctionnel  
**Items extraits** : 8 items lors du dernier test  
**Structure HTML** : Compatible avec le parser g√©n√©rique  

**Robustesse** : Structure HTML reconnaissable par les heuristiques actuelles.

#### üî¥ `press_corporate__peptron` - PROBL√âMATIQUE

**Statut** : Erreur SSL + structure complexe  
**Items extraits** : 0 items (√©chec technique)  
**Probl√®me identifi√©** : Certificat SSL invalide  

**Log d'erreur** :
```
ERROR: Source press_corporate__peptron : erreur HTTP - HTTPSConnectionPool(host='www.peptron.co.kr', port=443): Max retries exceeded with url: /eng/pr/news.php (Caused by SSLError(SSLCertVerificationError(1, "[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.peptron.co.kr'. (_ssl.c:1010)")))
```

**Probl√®mes multiples** :
1. Certificat SSL invalide (probl√®me technique)
2. Site cor√©en avec structure potentiellement complexe
3. URL avec param√®tres PHP (`.php`) sugg√©rant du contenu dynamique

### 2.3 Bilan quantitatif des derniers runs

**Test du 2025-12-08** (7 sources trait√©es) :
- **Sources RSS** : 74 items (3 sources, 100% succ√®s)
- **Sources HTML** : 30 items (3/5 sources, 60% succ√®s)
- **Total** : 104 items ing√©r√©s

**R√©partition HTML** :
- MedinCell : 12 items ‚úÖ
- DelSiTech : 10 items ‚úÖ  
- Nanexa : 8 items ‚úÖ
- Camurus : 0 items ‚ùå
- Peptron : 0 items ‚ùå

**Taux de succ√®s HTML** : 60% des sources, 30 items sur ~50 attendus

---

## 3. Failles et limitations identifi√©es

### 3.1 Parser HTML g√©n√©rique trop simpliste

**Probl√®me** : Le parser actuel utilise des heuristiques basiques qui ne couvrent que les structures HTML les plus courantes.

**Heuristiques actuelles** :
```python
# Pattern 1: balises <article>
articles = soup.find_all('article')

# Pattern 2: divs avec classes contenant certains mots-cl√©s
news_divs = soup.find_all('div', class_=lambda x: x and any(k in x.lower() for k in ['news', 'post', 'item', 'press']))
```

**Limitations** :
- Ne g√®re pas les structures CSS modernes (flexbox, grid)
- Ne g√®re pas le contenu g√©n√©r√© par JavaScript
- Ne g√®re pas les URLs relatives
- Extraction de date d√©faillante (toujours date actuelle)
- Pas de gestion des m√©tadonn√©es (Open Graph, JSON-LD)

### 3.2 Gestion des erreurs insuffisante

**Probl√®mes identifi√©s** :
- Certificats SSL invalides non g√©r√©s (Peptron)
- Pas de retry avec backoff pour les erreurs temporaires
- Pas de validation des URLs extraites
- Pas de d√©tection des doublons

### 3.3 Absence de configuration par source

**Probl√®me** : Toutes les sources HTML utilisent le m√™me parser g√©n√©rique, sans possibilit√© de personnalisation.

**Manque** :
- S√©lecteurs CSS sp√©cifiques par source
- Patterns de date personnalis√©s
- Gestion des URLs de base pour les liens relatifs
- Filtres de contenu (exclusion de certains types d'articles)

### 3.4 Monitoring et observabilit√© limit√©s

**Probl√®mes** :
- Pas de m√©triques sur le taux de succ√®s par source
- Pas d'alertes en cas d'√©chec r√©p√©t√©
- Logs insuffisants pour d√©bugger les structures HTML non reconnues

---

## 4. Impact sur le pipeline LAI

### 4.1 Couverture actuelle

**Sources fonctionnelles** : 3/5 (60%)
- MedinCell, DelSiTech, Nanexa : ~30 items/semaine

**Sources manquantes** : 2/5 (40%)
- Camurus : source majeure LAI (manque critique)
- Peptron : source asiatique (diversit√© g√©ographique)

### 4.2 Qualit√© des donn√©es

**Items extraits** : Structure basique mais exploitable
- Titre et URL pr√©sents
- Description souvent vide ou incompl√®te
- Date toujours actuelle (perte d'information temporelle)

**Normalisation Bedrock** : Fonctionne sur les items extraits
- D√©tection d'entit√©s op√©rationnelle
- Classification d'√©v√©nements fonctionnelle
- R√©sum√©s g√©n√©r√©s correctement

### 4.3 Risques pour le MVP

**Risque de couverture insuffisante** :
- Camurus est un acteur majeur LAI (Brixadi, CAM2038)
- Perte de 40% des sources corporate pr√©vues
- Biais g√©ographique (manque de sources asiatiques)

**Risque de qualit√©** :
- Dates incorrectes affectent le scoring temporel
- Descriptions manquantes r√©duisent la richesse du contenu
- Pas de d√©tection de doublons entre sources

---

## Propositions de correction pour le scraping HTML

### Approche minimale P0 : Corrections cibl√©es

**Objectif** : Rendre fonctionnelles les 2 sources en √©chec avec un effort minimal.

**Actions P0** :

1. **Peptron - Correction SSL** :
   - D√©sactiver la v√©rification SSL pour cette source sp√©cifique
   - Ou trouver une URL alternative (HTTP au lieu de HTTPS)
   - Ou d√©sactiver temporairement (`enabled: false`)

2. **Camurus - Parser sp√©cifique** :
   - Analyser manuellement la structure HTML de Camurus
   - Ajouter des s√©lecteurs CSS sp√©cifiques dans le parser
   - Exemple : `soup.find_all('div', class_='press-release-item')`

3. **Am√©lioration extraction de date** :
   - Chercher des patterns de date dans le HTML (classes, attributs)
   - Parser les dates relatives ("2 days ago", "January 15, 2025")
   - Fallback intelligent (date de derni√®re modification HTTP)

**Impact P0** : Passage de 60% √† 100% de sources fonctionnelles avec ~50 items/semaine.

### Approche structur√©e P1 : HTML Article Extractor g√©n√©rique

**Objectif** : Syst√®me d√©claratif et maintenable pour le scraping HTML.

**Design propos√©** :

1. **Configuration d√©clarative par source** :
   ```yaml
   # Dans source_catalog.yaml ou nouveau fichier html_extractors.yaml
   html_extractors:
     press_corporate__camurus:
       selectors:
         container: "div.press-release-list"
         item: "div.press-release-item"
         title: "h3.title a"
         url: "h3.title a"
         date: "span.date"
         description: "div.excerpt"
       date_format: "%B %d, %Y"
       base_url: "https://www.camurus.com"
   ```

2. **Parser HTML configurable** :
   - Lecture des s√©lecteurs depuis la configuration
   - Application des s√©lecteurs CSS avec BeautifulSoup
   - Parsing des dates selon le format sp√©cifi√©
   - R√©solution des URLs relatives

3. **Fallback sur parser g√©n√©rique** :
   - Si pas de configuration sp√©cifique, utiliser les heuristiques actuelles
   - Compatibilit√© ascendante garantie

**Impact P1** : Syst√®me extensible, maintenable, et robuste pour toutes les sources HTML.

### Impacts potentiels sur le pipeline

**Latence** :
- P0 : Impact minimal (+1-2 secondes)
- P1 : Impact mod√©r√© (+5-10 secondes pour le chargement de config)

**Complexit√©** :
- P0 : Faible (modifications ponctuelles)
- P1 : Mod√©r√©e (nouveau syst√®me de configuration)

**Maintenance** :
- P0 : √âlev√©e (code sp√©cifique par source)
- P1 : Faible (configuration d√©clarative)

---

**Document cr√©√© le** : 2025-01-15  
**Derni√®re mise √† jour** : 2025-01-15  
**Version** : 1.0